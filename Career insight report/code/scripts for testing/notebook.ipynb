{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f16f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/lang-uk/recruitment-dataset-job-descriptions-english/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a134f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Long Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Company Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Exp Years",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Primary Keyword",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "English Level",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Published",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Long Description_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "__index_level_0__",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d26ff65-2847-4b69-a564-a24b6c818fe2",
       "rows": [
        [
         "0",
         "10 + Blockchain Nodes / Masternodes to set up",
         "*Requirements*\r\n\r\nWe're looking for a long term collaboration with someone that has an experience in crypto, masternodes, nodes, validators etc. We need to set up:\r\n\r\nKyber Network\r\nNebulas\r\nSecretNetwork\r\nTron\r\nAion\r\nDeFiChain\r\nEOS\r\nTomoChain\r\nElrond\r\nIRISnet\r\nIoTeX\r\nTerra\r\nChainX\r\nThorchain\r\n\r\nSuccesful candidates will have an opportunity to get more jobs and long term collaboration.",
         "MyCointainer",
         "2y",
         "Sysadmin",
         "intermediate",
         "2020-10-01T00:00:00+03:00",
         "en",
         "c0ca96e7-85df-50df-a64e-d934cd02a170",
         "27461"
        ],
        [
         "1",
         "10 .NET Developers (Middle and Senior level)",
         "Greetings! My name is Maria, I am in urgent need to find a team of 10 .NET Developers (Middle and Senior level) to join the product company - my customer from Sweden. \r\n\r\n6+ years project (monolith with some microservices). The platform lets distributors, sellers, MSPs and vendors build, sell, deliver, and operate multi-cloud, SaaS, and managed services catalog. The user-friendly self-service platform allows customers to buy and manage services and subscriptions while enabling account managers to administer prices, issue quotes and publish cloud offerings. It supports multi-tier contract relationships as well as multi-tier billing and invoicing, comprehensive consumption and subscription reports and more.\r\n\r\n\r\n\r\nConditions:\r\n\r\nRemote\r\nSalary: 3000-5000 USD gross\r\nFull time (40 hours per week)\r\nDirect contract \r\n\r\n\r\n\r\nTech stack:\r\n\r\nASP NET Web API (.NET 4.7), .Net Core, ASP.NET (http://asp.net/) Core API, MS SQL Server, Entity Framework, Angular 9, React, Azure\r\n\r\n\r\n\r\nRequirements:\r\n\r\n\r\n\r\n- 2+ years of hands-on experience of .Net development (C#);\r\n\r\n- Strong skills in .Net Framework (.Net Core would be a plus);\r\n\r\n- Database skills, SQL knowledge;\r\n\r\n- English: intermediate or higher.\r\n\r\n- Entity Framework; Web API.\r\n\r\n\r\n\r\nYou‚Äôre welcome to ask me additional questions. Please, send your CV and salary expectations if you are interested! Thank you in advance!",
         "TechScout.tech",
         "2y",
         ".NET",
         "intermediate",
         "2022-03-01T00:00:00+02:00",
         "en",
         "64f4b7ea-36e4-5bdd-a8b1-185f32f7dc7f",
         "27462"
        ],
        [
         "2",
         "10X Engineer (co-founder, #4 employee, USD 11-12k, 1-4% equity)",
         "**Product**\r\nThe product is a live video chat and co-browsing with website visitors. It helps companies generate more customers with instant video meetings directly on visitor‚Äôs website while they‚Äôre browsing a company‚Äôs page. It‚Äôs like a virtual web attendant that greets you on the web and guides through company‚Äôs products, much like they do in real-world stores.\r\n\r\nIt‚Äôs been in development for 5 months, sales started 2 months ago, already has 7 paid enterprise customers.\r\n\r\nIt already received $3mln funding, incl. from Google and couple of US tech billionaries.\r\n\r\n**Team**\r\n- Daniel ‚Äî Founder, previously Co-founder / CTO at couple other companies, incl. CTO at myetherwallet.com, winner of Peter Thiel Foundation scholarship\r\n- Will ‚Äî founding engineer, 11 yrs experience, previously VP Engineering at coder.com and Senior Engineer at OkCupid.com\r\n- Aaron ‚Äî founding engineer, 15 yrs experience\r\n- You ‚Äî founding engineer, with 1-4% equity\r\n\r\n**Stage**\r\n- 5 months in development, e.g. almost from scratch\r\n- You will be a co-founder and #4 on the team with 1-4% equity\r\n- Already has 7 paying enterprise customers\r\n- Received $3mln funding, incl. from Google\r\n- New features development only; no legacy\r\n\r\n**Tech stack**\r\n- React, Typescript, Redux, Python, Flask, SQLAlchemy, Celery, WebRTC, WebSockets, Heroku\r\n- Expert-level with frontend is a must, but you have to be comfortable working across the stack\r\n- Highly preferred if you‚Äôre experienced with a broader range of technologies (Python, Java, Go, C#, PHP etc)\r\n\r\n**What will you do**\r\n- Build prototypes and features from start to finish: plan, build, test, deploy, iterate\r\n- Work in a small, very experienced, high performing, self-managed team\r\n- Have a lot of remote collaboration and getting feedback directly from users\r\n\r\n**Nearest features**\r\n- Scaling the system (WebSockets is a challenge here)\r\n- Session replay\r\n- Mobile app\r\n- Analytics\r\n- Video voicemails\r\n\r\n**Your profile**\r\n- Have an ownership mindset, value low process, high impact and real ownership in the company\r\n- Expert-level with the browser, incl. for example knowing Chrome RFCs\r\n- Experience developing products from scratch and in a ‚Äúmove fast and break things‚Äù environment\r\n- Have strong opinions on tech decisions, but happy to continuously challenge it\r\n- Thoughtful about creating and mantaining a world-class engineering culture in the company\r\n\r\n**What‚Äôs offered**\r\n- $11-12k/m compensation + 1-4% equity\r\n- Fully remote work, important are results\r\n- Move fast and break things approach\r\n- Low process, high impact environment\r\n- Direct contract with client (after 1-2 months of outstaffing)",
         "Innoteka",
         "5y",
         "JavaScript",
         "fluent",
         "2021-07-01T00:00:00+03:00",
         "en",
         "b9a1303e-dd0c-5ed1-8f62-be2bc4c7da4f",
         "27463"
        ],
        [
         "3",
         "16 - Amazon Brand Manager",
         "Currently, TCM expanding its activities to Ukraine and we are hiring staff for our** offices in Kiev**. All the positions are offered on an equal opportunity to all races, religious, gender, nationalities, and color.\r\n\r\n**The Role**\r\nThis role is for self-starter to manage products portfolio, ensuring their success day-to-day including content and creative, marketing, financial health of the business, customer service, risk mitigation and compliance, inventory, and growth strategies. Brand success will be based on your intimate knowledge of the brand you manage, ability to diagnose issues and develop action plans.\r\n\r\n**Responsibilities:**\r\n- Analyze Amazon product sales, conversation rate, page views, costs, etc. to determine why certain products are trending up or down, clearly articulate observations and propose strategies to troubleshoot problems.\r\n- Maintaining product success on Amazon and strive to become best seller, monitoring metrics shifts, follow market trends, adding customer profiles, daily reporting, pricing changes, manage remote teams, inventory management spread among several locations and warehouses.\r\n- Develop strategies to increase sales, reduce costs, improve conversion rate, price optimization, PPC optimization, packaging/inserts including dimensions, coupons and deals, customer communications, subscribe and save, removing unprofitable products, etc.\r\n- Analyze reports, coordinating with finance department cashflow and accurate PandL.\r\n- Identify potential issues before they convert to problems and understand the operating environment in which your products are selling (e.g., competitors, BSR, categories, Amazon TOS changes).\r\n- Research programs and tools on Amazon and other marketplaces to expand the brand and ensure protecting it (e.g., Amazon Project Zero, Transparency).\r\n- Prepare, monitor, and understand the migration process during acquisition process of a new brand. This includes doing a deep dive of all information provided during due diligence, migrating the prior seller‚Äôs accounts (social media, emails, customer service management, warehouses, inventory, etc.), developing good relationship with the seller get his full cooperation during and after the migration.\r\n- Interface with legal team regarding an intellectual property or legal issues, such as product suspension or identifying ‚Äúhijackers‚Äù.\r\n- Coordinate with customer satisfaction team to ensure we prove best experience for your product portfolio.\r\n- Manage product pre-launches, launches and expansion.\r\n- Coordinate with the supply chain to ensure products always in stock with best quality, have the right labeling, and have all the required documentations.\r\n\r\n**OUR PERFECT CANDIDATE:**\r\n- **2+ years of proven e-commerce experience**, preferably with **Amazon **product management, marketing, or an analytical function, preferably at a startup or other fast-paced environment.\r\n- Good understanding of **SEO, PPC** and tools used inside and outside of Amazon.\r\n- Ability to dig through data, analyze and provide recommendations from your insights.\r\n- **Excellent English** written and verbal communication skills, a high level of organization, and impeccable attention to detail.\r\n- Ability to handle aggressive deadlines and prioritize work in a fast-paced, often ambiguous environment daily.\r\n- A highly analytical person who can manage multiple projects and figure out complex problems.\r\n- Demonstrated ability to create engaging content, come up with creative ideas, and think outside the box.\r\n- Positive attitude, reliable, transparent and enjoy working with different types of people.\r\n- Familiar with other platforms such as **Walmart, eBay, Shopify**, etc. ‚Äì advantage.\r\n- Strong proficiency in **Excel/Google Sheets**.\r\n\r\nWe offer:\r\n* An interesting and challenging work\r\n* A friendly work environment, with a good work-life balance\r\n* office in the center of Kyiv.\r\n* Lunches in office and full fridge all the time.\r\n* Paid vocations and sick leaves\r\n* Taxes compensation\r\n* Medical insurance.\r\n* Joining GIFT\r\n\r\nWe are waiting for your CV)))",
         "FirstFive",
         "2y",
         "Marketing",
         "upper",
         "2022-01-01T00:00:00+02:00",
         "en",
         "99cb3f4a-9b4b-53d9-9a3b-bab2c22da346",
         "27464"
        ],
        [
         "4",
         "16 - Amazon Brand Manager",
         "Hello,\r\nWe, MIMIRB2B, are an outstaff company and now We are looking for an experienced and responsible Amazon Brand Manager to become a part of our expert team.\r\n\r\nThe Role\r\nThis role is for self-starter to manage products portfolio, ensuring their success day-to-day including content and creative, marketing, financial health of the business, customer service, risk mitigation and compliance, inventory, and growth strategies. Brand success will be based on your intimate knowledge of the brand you manage, ability to diagnose issues and develop action plans.\r\n\r\nResponsibilities:\r\n- Analyze Amazon product sales, conversation rate, page views, costs, etc. to determine why certain products are trending up or down, clearly articulate observations and propose strategies to troubleshoot problems.\r\n- Maintaining product success on Amazon and strive to become best seller, monitoring metrics shifts, follow market trends, adding customer profiles, daily reporting, pricing changes, manage remote teams, inventory management spread among several locations and warehouses.\r\n- Develop strategies to increase sales, reduce costs, improve conversion rate, price optimization, PPC optimization, packaging/inserts including dimensions, coupons and deals, customer communications, subscribe and save, removing unprofitable products, etc.\r\n- Analyze reports, coordinating with finance department cashflow and accurate PandL.\r\n- Identify potential issues before they convert to problems and understand the operating environment in which your products are selling (e.g., competitors, BSR, categories, Amazon TOS changes).\r\n- Research programs and tools on Amazon and other marketplaces to expand the brand and ensure protecting it (e.g., Amazon Project Zero, Transparency).\r\n- Prepare, monitor, and understand the migration process during acquisition process of a new brand. This includes doing a deep dive of all information provided during due diligence, migrating the prior seller‚Äôs accounts (social media, emails, customer service management, warehouses, inventory, etc.), developing good relationship with the seller get his full cooperation during and after the migration.\r\n- Interface with legal team regarding an intellectual property or legal issues, such as product suspension or identifying ‚Äúhijackers‚Äù.\r\n- Coordinate with customer satisfaction team to ensure we prove best experience for your product portfolio.\r\n- Manage product pre-launches, launches and expansion.\r\n- Coordinate with the supply chain to ensure products always in stock with best quality, have the right labeling, and have all the required documentations.\r\n\r\nOUR PERFECT CANDIDATE:\r\n- 2+ years of proven e-commerce experience, preferably with Amazon product management, marketing, or an analytical function, preferably at a startup or other fast-paced environment.\r\n- Good understanding of SEO, PPC and tools used inside and outside of Amazon.\r\n- Ability to dig through data, analyze and provide recommendations from your insights.\r\n- Excellent English written and verbal communication skills, a high level of organization, and impeccable attention to detail.\r\n- Ability to handle aggressive deadlines and prioritize work in a fast-paced, often ambiguous environment daily.\r\n- A highly analytical person who can manage multiple projects and figure out complex problems.\r\n- Demonstrated ability to create engaging content, come up with creative ideas, and think outside the box.\r\n- Positive attitude, reliable, transparent and enjoy working with different types of people.\r\n- Familiar with other platforms such as Walmart, eBay, Shopify, etc. ‚Äì advantage.\r\n- Strong proficiency in Excel/Google Sheets.\r\n\r\nWe are waiting for your CV)))",
         "MimirB2B",
         "1y",
         "Marketing",
         "upper",
         "2021-12-01T00:00:00+02:00",
         "en",
         "bc1419f7-28e2-582b-8d53-22e28b2f0210",
         "27465"
        ],
        [
         "5",
         "1806/01 PHP Developer",
         "**Requirements:**\r\n‚Ä¢ Experience with PHP 2+ years;\r\n‚Ä¢ Strong knowledge and work experience with Laravel;\r\n‚Ä¢ Experience with JavaScript (Vue.js);\r\n‚Ä¢ Excellent knowledge of databases (MySQL);\r\n‚Ä¢ Experience working with GIT;\r\n‚Ä¢ Good problem-solving abilities;\r\n‚Ä¢ English - Intermediate.\r\n\r\n**Will be plus:**\r\n‚Ä¢ Server management.\r\n\r\n**We offer:**\r\n‚Ä¢ Friendly teams, experienced colleagues, and perfect work equipment;\r\n‚Ä¢ Opportunities for career growth and raising professional skills;\r\n‚Ä¢ Competitive compensation and regular results-based salary review;\r\n‚Ä¢ Your bookkeeping will be maintained by a professional accountant;\r\n‚Ä¢ 21 paid vacation days;\r\n‚Ä¢ Flexible work schedules;\r\n‚Ä¢ Comfortable office in the city center;\r\n‚Ä¢ Compensation of English courses.\r\n\r\n**Responsibilities**:\r\n‚Ä¢ Develop new user-facing features;\r\n‚Ä¢ Translate designs and wireframes into high quality code;\r\n‚Ä¢ Join forces with product and design teams to define, iterate and implement new features;\r\n‚Ä¢ Maintain the existing project in the same stack.",
         "Argument",
         "2y",
         "PHP",
         null,
         "2021-06-01T00:00:00+03:00",
         "en",
         "30fa3946-0a8c-52c4-b1e7-3e5bfd80647c",
         "27466"
        ],
        [
         "6",
         "1806/03 Sales Manager",
         "**Requirements:**\r\n‚Ä¢‚†ÄExperience in IT sales 1+ year\r\n‚Ä¢‚†ÄGeneric understanding of IT technologies and Software Development process\r\n‚Ä¢‚†ÄKnowledge of sales techniques, sales markets\r\n‚Ä¢‚†ÄGood communication and negotiation skills\r\n‚Ä¢‚†ÄFluent written and good spoken English\r\n\r\n**We offer:**\r\n‚Ä¢‚†ÄFriendly teams, experienced colleagues, and perfect work equipment\r\n‚Ä¢‚†ÄOpportunities for career growth and raising professional skills\r\n‚Ä¢‚†ÄCompetitive compensation and regular results-based salary review\r\n‚Ä¢‚†ÄYour bookkeeping will be maintained by a professional accountant\r\n‚Ä¢‚†ÄFlexible work schedules\r\n‚Ä¢‚†ÄComfortable office in the city center\r\n‚Ä¢‚†ÄCompensation of English courses\r\n\r\n**Responsibilities:**\r\n‚Ä¢‚†ÄSearching for new and potential clients via different channels\r\n‚Ä¢‚†ÄPrepare and submit proposals\r\n‚Ä¢‚†ÄSuccessful overcome of objections\r\n‚Ä¢‚†ÄCommunicate with potential customers",
         "Argument",
         "1y",
         "Sales",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "b6f85c03-a633-5429-9172-821c43d23dfc",
         "27467"
        ],
        [
         "7",
         "1807/01 Middle+ / Senior marketing specialist",
         "Ideal candidate profile:\r\n- At least 2 years of experience in digital marketing (B2B).\r\n- At least 2 years of experience in IT outsourcing as a must\r\n- English level both verbal and written: Upper Intermediate/B2+.\r\n- Experience in conducting marketing research.\r\n- Experience in creating technical tasks for generation landing pages, blog posts, white papers, case studies, and other marketing collateral.\r\n- A strong understanding of digital marketing channels.\r\n- Experience with customer segmentation, profiling, and targeting.\r\n- Proficiency with analytics tools and web traffic reporting.\r\n\r\nMajor Challenges:\r\n- Target markets/audiences/niches research.\r\n- Generating of marketing materials in close coordination with designer, copywriter, SEO specialist.\r\n- Participating in planning and implementation of marketing strategy.\r\n- Working on corporate website as for new landing pages generating, conversion optimization and brand positioning in close coordination with designer, copywriter, SEO specialist and web developer.\r\n- Crowd marketing and content distribution on off site placements.\r\n- Ongoing experiments and hypothesis tests.\r\n- Collection and analysis of marketing metrics.\r\n\r\nWe offer:\r\n- Comfortable working space (not openspace) in the city centre.\r\n- Flexible working hours, no micromanagement.\r\n- Paid vacation.\r\n- Salary in USD corresponding to your skills.\r\n- Team with flat management structure where your opinion matters.\r\n\r\nWould be a plus:\r\n- Experience in content distribution via different channels such as Quora, Reddit, LinkedIn, Facebook etc.\r\n- Experience with SEO.\r\n- Excel and Google spreadsheet skills for data analysis.\r\n- Experience in building and optimizing Facebook campaigns.",
         "Argument",
         "2y",
         "Marketing",
         "upper",
         "2021-04-01T00:00:00+03:00",
         "en",
         "5ce407f2-4243-5eef-a3da-8450ae29d3b5",
         "27468"
        ],
        [
         "8",
         "1807/04 Business Development Manager",
         "**Requirements:**\r\n- 2+ years of experience and proven track records in sales;\r\n- Excellent communication skills (both verbal and written);\r\n- Advanced level of English;\r\n- Software development process understanding and IT industry knowledge;\r\n- Good understanding of the US and European markets and ability to manage operations there.\r\n\r\n**What to do:**\r\n- Opportunities qualification;\r\n- Customer negotiations, proposals development and closing;\r\n- Creation of customized messages;\r\n- Creation of sales presentations;\r\n- Cooperation with the sales team (leadgen, pre-sales, marketing) ;\r\n- Collaboration with delivery experts during the sales process;\r\n- RFIs/RFPs Management;\r\n- Achieving growth and hitting sales quota;\r\n- Management and maintenance of opportunities in CRM;\r\n- Build and evolve strong customer relationships by nurturing them and understanding their needs;\r\n- Identifying new sales opportunities.\r\n\r\n**What we offer:**\r\n- Work with english-speaking customers in well organized agile environment;\r\n- Participating in decision-making and business management processes;\r\n- Minimal bureaucracy and proximate contact with CEO and CTO;\r\n- Build your own work schedule without a need to be in the office all day long and owertimes.\r\n\r\n**About You**\r\n- In this role, you should be able to work independently with little supervision;\r\n- You should have excellent organization and problem-solving skills;\r\n- You have an eye for the details.",
         "Argument",
         "2y",
         "Sales",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "1dbc90e3-bc38-53b7-af46-bda5e1775c56",
         "27469"
        ],
        [
         "9",
         "1812/35 Middle DataBase developer",
         "Job responsibilities:\r\nMonitor incoming/outgoing data as well as create/modify code for processes relating to incoming/outgoing data feeds\r\n- Prepare, maintain the data migration processes inside RDB\r\n- Create, maintain, and optimize database elements using stored procedures, views, functions, triggers, jobs, and execution plan analysis\r\n- Experience using SQL Profiler and Extended Events to troubleshoot and optimize new and existing database code\r\n- Proactively address data quality concerns; troubleshoot errors\r\n- Apply/implement business logic for processes\r\n- Provide daily support for database activities\r\n- Manage security\r\n \r\nJob Skills/Requirements:\r\n‚óè MS SQL Server with T-SQL ‚Äì minimum 2 plus years‚Äô experience\r\n‚óè Experience with SQL Server 2008 R2 through 2017.\r\n‚óè Visual Studuo + SSDT \r\n‚óè Experience with SSRS, creating new queries / reports and setting up and maintaining services and shared service components.\r\n‚óè SSIS experience\r\n‚óè Plus skills:  XML, Web protocols, TFS,  ASP.NET\r\n‚óè Familiarity with .Net Core, Visual Studio, and Powershell for SQL Server and Azure SQL \r\n\r\nWe offer: \r\n‚Ä¢ Competitive salary \r\n‚Ä¢ Comfortable office, located in the city center with bike parking\r\n‚Ä¢ Official employment, paid sick leave, 20 days of paid vacation\r\n‚Ä¢ Paid lunch\r\n‚Ä¢ Free English lessons\r\n‚Ä¢ Flexible work schedule\r\n‚Ä¢ Official Ukrainian holidays are non-working days\r\n‚Ä¢ Career development plan\r\n‚Ä¢ Friendly team of young IT professionals \r\n\r\nAbout the project:\r\nProject is uniquely configurable cloud-based platform is designed to guide and reinforce behaviors that drive results; mobilize employees; strategically align individuals with company values and objectives; and solve an organization‚Äôs ever-changing business issues. The system‚Äôs Activity Streams and Leaderboard allow users to see how they compare alongside others in the organization, which helps businesses create a culture of recognition where individuals feel more connected to the company and their coworkers through Manager Discretionary, Peer-to-Peer, Service Anniversary & Milestones and Sales Incentive Programs\r\n\r\n \r\nTeam:  4 Senior .NET dev, 1 Middle  .NET dev, 5 Manual QA, 1 Senior Automation QA, 3 Senior DB dev, 1 Junior DB dev, 3 Markup/Front-End devs. \r\n\r\n–í—Å–µ–≥–æ –≤ –•–∞—Ä—å–∫–æ–≤—Å–∫–æ–º –æ—Ñ–∏—Å–µ 65 + —á–µ–ª–æ–≤–µ–∫.\r\n–ì—Ä–∞—Ñ–∏–∫: 5/2, 8 —á–∞—Å–æ–≤–æ–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å, –≥–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫. –ë–µ–∑ –ø–æ–∑–¥–Ω–∏—Ö –º–∏—Ç–∏–Ω–≥–æ–≤ –∏ –æ–≤–µ—Ä—Ç–∞–π–º–æ–≤.",
         "Argument",
         "2y",
         "Data Science",
         "intermediate",
         "2021-04-01T00:00:00+03:00",
         "en",
         "cd7fe1db-fb8c-5b8d-898b-49d6346b0f2e",
         "27470"
        ],
        [
         "10",
         "1815/06 Lead/Senior Backend Engineer (Python)",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\r\nPython - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ SQL\r\n–û–ø—ã—Ç –≤ NoSQL\r\n–û–ø—ã—Ç –≤ Kubernetes\r\n–û–ø—ã—Ç –≤ Docker\r\n–û–ø—ã—Ç –≤ Methodologies\r\n–û–ø—ã—Ç –≤ TensorFlow\r\n–û–ø—ã—Ç –≤ PyTorch\r\n\r\n**Requirements**\r\n- 3-5+ years of experience in Python development\r\n- B.Sc in computer science or a related field\r\n- Worked on large-scale service oriented distributed systems\r\n- Experience with different types of data storage (SQL, NoSQL, search engines, big data databases, object stores)\r\n- Experience with containerization and cluster management technologies like Docker and Kubernetes\r\n- Tech savvy - we are looking for someone who likes to learn and develop tech skills of the latest technologies and methodologies\r\n- Experience collaborating with Research teams working with PyTorch or TensorFlow ‚Äì advantage\r\n- Good spoken and written English\r\n\r\n**Responsibilities**\r\n- Design & develop the infrastructure for training, deploying and monitoring of AI models in development and production environments.\r\n- Build high-quality, containerized, scalable high throughput services.\r\n- Build observability systems for tracking performance metrics and business KPIs.\r\n- Work with the Product and Research teams to build products in the AI domain.\r\n- Be a valuable member of the engineering team, have a meaningful impact on the stack, review code and share best practices.",
         "Argument",
         "3y",
         "Python",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "b326dd43-41f3-53b2-a1d8-63bed999aea8",
         "27471"
        ],
        [
         "11",
         "1831/29 Senior Java Developer",
         "Requirements:\r\n‚Ä¢ BS or MS in Computer Science or related field\r\n‚Ä¢ Significant experience in Java8 (Core, Networking, RES, RabbitMQ, CouchDB, Spring Framework, Google\r\nProtobuf, Google,Guava, javax.servlet, javax.ws.rs, Mockito, JUnit, NewRelic, DataDog, Gradle)\r\n‚Ä¢ Knowledge of Python will be a big plus\r\n‚Ä¢ Knowledge of C/C++ will be a plus\r\n‚Ä¢ Understanding of media (audio/video) encoding/decoding will be plus\r\n‚Ä¢ Knowledge of JavaScript (nodeJS) technologies will be plus\r\n‚Ä¢ Self-starter who is ready to work on a fast-paced early stage project without daily direction/hand-holding\r\n‚Ä¢ Good verbal and writing English language communication skills.\r\n\r\nBenefits:\r\n‚Ä¢ Salary based on individual qualifications, experience, and interview results\r\n‚Ä¢ Outstanding job stability with great opportunities for professional growth and advancement\r\n‚Ä¢ Western management practices\r\n‚Ä¢ Prospect of business travel to the US and –ïurope\r\n‚Ä¢ Modern and comfortable office in Kyiv within walking distance from subway station\r\n‚Ä¢ Great benefits package including medical, education, and fitness\r\n‚Ä¢ Reimbursement for moving expenses for out-of-town candidates\r\n‚Ä¢ Flexible working hours (including opportunities to periodically work from home)\r\n‚Ä¢ Performance bonuses and annual salary reviews\r\n‚Ä¢ Choice of desktop or a laptop as the main workstation\r\n‚Ä¢ Bicycle and car-friendly office\r\n‚Ä¢ In-office gym\r\n‚Ä¢ Regular team-building events",
         "Argument",
         "3y",
         "Java",
         "upper",
         "2021-04-01T00:00:00+03:00",
         "en",
         "5a2df212-d3cf-5223-8c79-6d9421826e99",
         "27472"
        ],
        [
         "12",
         "1913/06 Trainee/Junior Database developer",
         "–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–≤—ã–∫–∏\r\n‚Äî Being able to assist with schema design, code review and SQL query tuning.\r\n‚Äî Develop stored procedures, functions, packages and views using PLSQL, PGSQL, and SQL\r\n‚Äî Write and deploy SQL script upgrade\r\n‚Äî Knowledge of the system catalog\r\n‚Äî Tools: Posgtressql DBeaver, pgAdmin , Oracle sql developer, Toad\r\n‚Äî Proven work experience as a Database developer or Administrator\r\n‚Äî Knowledge of scripting languages is a plus\r\n‚Äî Knowledge on Jira software, Git (or svn) is a plus\r\n‚Äî Spoken Intermediate+ English level\r\n\r\n–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º\r\n‚Äî Office near Naukova (only office work)\r\n‚Äî Annual paid vacations (20 working days) and 10 days sick leave;\r\n‚Äî Medical insurance;\r\n‚Äî English classes;\r\n‚Äî Warm and friendly working environment;\r\n‚Äî Professional development and career growth.\r\n\r\n–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏\r\nYou will be working with a distributed team in London and Paris, on our internal database structure.\r\nWork will include schema design, code review and SQL query tuning. Your will be developing stored procedures, functions, packages, etc for both Oracle and POstGre databases.",
         "Argument",
         "no_exp",
         "Data Science",
         "intermediate",
         "2021-04-01T00:00:00+03:00",
         "en",
         "4284f37e-1a57-5d53-aa11-6d6f8ba1ec9d",
         "27473"
        ],
        [
         "13",
         "1919/08 Middle Python Developer",
         "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\r\nPython 3 - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Amazon AWS\r\n–û–ø—ã—Ç –≤ REST API\r\n–û–ø—ã—Ç –≤ NoSQL\r\n\r\nYou need to have:\r\n- 3+ years of experience with Python 3\r\n- Proficient in GCP or AWS, GCP preferred\r\n- Experienced in creating REST APIs, using a python API framework such as Flask or Django\r\n- Debugging / testing skills\r\n- Experience with No-sql database\r\n\r\nYou will:\r\n- Making edits and optimizations to pre-existing APIs\r\n- Building out extensive unit testing, logging, and monitoring for APIs\r\n- Create APIs and integrate with 3rd party SDKs to support new features, such as automated mail-in bank fee negotiations\r\n\r\nWith us you can:\r\n- Develop your professional skills;\r\n- Grow within the company;\r\n\r\nWe offer:\r\n- Flexible working conditions;\r\n- 12 days of paid vacation (working days);\r\n- 5 sick days;\r\n- Office in the city center;\r\n- Friendly and open-minded team;\r\n- English classes;\r\n- Relax and fun zones.",
         "Argument",
         "3y",
         "Python",
         "intermediate",
         "2021-04-01T00:00:00+03:00",
         "en",
         "c2d24e11-fdcd-523f-a390-6317c258b8cf",
         "27474"
        ],
        [
         "14",
         "1919/10 Junior Ruby on Rails Developer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**\r\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: 1 –≥–æ–¥\r\nRuby on Rails - 1 –≥–æ–¥\r\n–û–ø—ã—Ç –≤ PostgreSQL\r\n–û–ø—ã—Ç –≤ Unit Testing\r\n–û–ø—ã—Ç –≤ HTML & CSS\r\n–û–ø—ã—Ç –≤ JavaScript\r\n\r\n**Requirements:**\r\n- 1+ year in Ruby on Rails development;\r\n- good knowledge of PostgreSQL and ActiveRecord ORM;\r\n- good knowledge of Unit-testing (Rspec);\r\n- good knowledge of HTML, CSS, JS;\r\n- level of English intermediate or higher;\r\n\r\n**Will be a plus:**\r\n- experience with cloud services such as AWS (S3, SNS, Lambda);\r\n- experience with Heroku;\r\n- experience with payment services such as Stripe or PayPal;\r\n- experience with jQuery;\r\n- experience with ActiveAdmin;\r\n- experience with ElasticSearch;\r\n\r\n**We offer:**\r\n- Flexible working conditions;\r\n- 12 days of paid vacation (working days);\r\n- 5 sick days;\r\n- Office in the city center;\r\n- Friendly and open-minded team;\r\n- English classes;\r\n- Relax and fun zones.",
         "Argument",
         "1y",
         "Product Manager",
         "intermediate",
         "2021-06-01T00:00:00+03:00",
         "en",
         "761f5073-f471-51df-b9c9-7705a0369b8e",
         "27475"
        ],
        [
         "15",
         "1926/05 DevOps Engineer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**\r\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: 3 –≥–æ–¥–∞\r\nDevOps - 2 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Engineering skills\r\n–û–ø—ã—Ç –≤ Terraform\r\n–û–ø—ã—Ç –≤ Ansible\r\n–û–ø—ã—Ç –≤ Git\r\n–û–ø—ã—Ç –≤ Docker\r\n–û–ø—ã—Ç –≤ Drupal\r\n–û–ø—ã—Ç –≤ React\r\n–û–ø—ã—Ç –≤ Nginx\r\n–ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –°—Ä–µ–¥–Ω–∏–π\r\n\r\n**Remote/Kharkiv**\r\n\r\nThe DevOps Engineer's responsibilities include establishing/optimizing the automation of server processes. Main focus on: AWS, terraform, etc.\r\n\r\nEmployment form:\r\nfull-time\r\n\r\n**Required skills:**\r\n- Engineering skills\r\n- Terraform, Ansible\r\n- Git\r\n- AWS (RDS, EC2, EFS, S3, SQS)\r\n- CloudWatch, CloudFront\r\n- ElasticSearch, ElasticCache\r\n- Batch\r\n- VPC, SG, ASG, etc.\r\n- Nginx\r\n- Percona Monitoring Tool\r\n- Docker\r\n- Solr (good to know)\r\n\r\n**Soft Skills:**\r\n- Responsibility for committed scope of work.\r\n- Time management skill.\r\n- Regular communication with a team and client via chat/task (as a comment).\r\n- Personal activity in a project.\r\n- Team Player.\r\n- Person who accepts regular work/code review.\r\n- Person who is oriented to results.\r\n\r\n\r\n**We offer:**\r\n- Paid sick leave/vacation days (6/15 working days per year).\r\n- Possibility to work from office or remotely.\r\n- A cozy office in the heart of the city (Rymarska str).\r\n- Friendly experienced team and nice environment.\r\n- English speaking club, internal courses and other educational activities.\r\n- Board games, parties, team buildings and corporate events.\r\n- Delicious coffee / tea / biscuits / fruit / milk in the office.",
         "Argument",
         "3y",
         "DevOps",
         "intermediate",
         "2021-05-01T00:00:00+03:00",
         "en",
         "79f61014-570d-5860-adc2-1caa8bce7430",
         "27476"
        ],
        [
         "16",
         "1926/07 Senior Java Software Engineer",
         "**Your responsibilities**\r\n- Take ownership of the design, development and maintenance of microservices powering our open platform for the energy and utilities industry.\r\n- Work on scalable components performing financial transactions, billing calculations and quotations for millions of energy consumers and metering points.\r\n- Analyze our legacy components in terms of throughput, latency, security and reliability and proactively drive refactorings and rebuilds.\r\n- Create POCs demonstrating the power of JVM technologies and frameworks and act as an evangelist to share your knowledge with the company.\r\n- Mentor and coach junior developers in pair programming sessions.\r\n\r\n**Our requirements**\r\n- You have a degree in computer science or a related subject.\r\n- You have profound experience as a backend engineer.\r\n- You have hands-on coding skills in Microservice architectures using Java 8+, Spring Boot, Hibernate or related JVM-based technology Stacks.\r\n- You have a background working with event-driven architectures using RabbitMQ, NATs or Kafka\r\n- You have experience working with SQL and NoSQL databases, preferably MySQL\r\n- You have strong conceptual knowledge of OO-patterns, Domain Driven Design, and database design.\r\n- You have strong technical coaching and mentoring skills.\r\n= You are proficient in English and keen to work in an international environment.\r\n\r\n**Our tech stack**\r\nJava 11, Spring Boot, MySQL/MariaDB, Bitbucket, Jenkins, AWS.\r\n\r\n**What we offer**\r\n- You are going to be part of a vibrant and international developer team who revolutionizes the energy industry with leading-edge technologies.\r\n- We know that our employees make the difference. Therefore we take care of every team member individually and provide manifold training opportunities.\r\n- Our teams work with agile methods without outdated structures.\r\n- We offer you an environment in which you can fulfill yourself and that enables your success as part of the whole.\r\n- Possibility to work from the Kharkiv office or remotely.\r\n- Paid sick leave/vacation days (6/15 working days per year).\r\n- Stability and excellent conditions for long-term cooperation.\r\n- English speaking club, internal corces, certifications and other educational activities.\r\n- Board games, parties, team buildings and corporate events.\r\n- Delicious coffee / tea / biscuits / fruit / milk in the office.\r\n*Potentially possible short business-trips to Germany.",
         "Argument",
         "3y",
         "Java",
         "intermediate",
         "2021-05-01T00:00:00+03:00",
         "en",
         "0ee0827c-8b40-530a-b16f-b95d24d32b70",
         "27477"
        ],
        [
         "17",
         "1940 Middle Java Developer + Welcome Bonus!",
         "Work at Exadel - Who We Are:\r\nSince 1998, Exadel has been engineering its own software products and custom software for clients of all sizes. Headquartered in Walnut Creek, California, Exadel currently has 1700+ employees in development centers across America, Europe, and Asia. Our people drive Exadel‚Äôs success, and they are at the core of our values, so Exadel is a people-first cultured company.\r\n\r\nAbout Our Customer:\r\nThe —Åustomer is a leading provider of vehicle lifecycle solutions, enabling the companies that build, insure, repair, and replace vehicles to power the next generation of transportation. The company delivers advanced mobile, artificial intelligence, and connected car technologies through its platform, connecting a vibrant network of 350+ insurance companies, 24,000+ repair facilities, OEMs, hundreds of parts suppliers, and dozens of third-party data and service providers. The customer's collective set of solutions inform decision-making, enhance productivity, and help clients deliver faster and better experiences for end consumers.‚ÄØ \r\nThe —Åustomer‚Äôs company was ranked #17 in the Top 100 Digital Companies in Chicago in 2020 by Built in Chicago, an online community for digital technology entrepreneurs in Chicago, and was named one of Forbes best mid-sized companies to work for in 2019 ‚Äì an important accolade and retention tool for the 2,600+ full-time company employees (alongside 350 dedicated contractors). \r\n\r\nAbout Our Project:\r\nThe team creates a software platform for the collection, analysis, processing, and reporting of automatically generated vehicle telemetry for new automobiles. These services process terabytes of information and integrate with artificial intelligence models to identify and assess crashes and their severity. Driver behavior, active safety features, and environmental conditions are just some of the data attributes collected and evaluated in real time. In the event of accidents, these services initiate automated responses in the form of emergency assistance, vehicle transport, a replacement vehicle, medical services, etc.\r\n\r\nProject Team:\r\nTeam 1:\r\n1 Lead Software Engineer, 2 Software Engineer, 1 DevOps Engineer, 1 AQA, and 1 Senior Product Owner\r\nTeam 2:\r\n2 Software Engineers, 2 AQAs, and 1 Business Analyst\r\n\r\nProject Advantages: \r\nGain experience working with large data volumes and high-scale processing\r\nGain experience in vehicle telematics        \r\nGain experience with microservices\r\nProject Tech Stack:\r\nJava 8+, AWS, Containerization (Docker & Kubernetes), DropWizard/Spring boot, No SQL (DynamoDB), and Async Messaging (Kafka/Active MQ)\r\n\r\nCurrent Project Stage:\r\nResourcing \r\n\r\nRequirements:\r\n    Bachelor‚Äôs degree in computer science, mathematics, or a related field\r\n    2+ years of experience developing Java-based applications.\r\n    Strong experience with Java 8+, OOP, and REST services\r\n    Good understanding of microservices-based software design and best practices\r\n    Knowledge of software design patterns\r\n    Experience with any of the following:\r\n        ‚ó¶ NoSQL data stores, Relational DBs, Object stores, cache frameworks\r\n        ‚ó¶ Docker / Kubernetes\r\n        ‚ó¶ Drop wizard or Spring Boot\r\n        ‚ó¶ Apache Kafka\r\n    Familiarity with Git or another modern source repository\r\n    Strong experience in unit testing principles and methodologies        \r\n    Experience in Agile and Scrum practices\r\n    A quality-oriented mindset, focused on product delivery\r\n    A strong capacity and desire to learn\r\n    Proven ability to collaborate and proven ability to lead junior engineers\r\n\r\nResponsibilities: \r\nCollaborate with product stakeholder teams to identify and implement functional and non-functional requirements\r\nBe responsible for on-time delivery of high-quality software and infrastructure components\r\nWork closely with engineering team members and architects to design, develop, and test all tiers of the application \r\nParticipate in ongoing maintenance and support, including resolving any production issues/defects when needed\r\nEnsure that the services are built and deployed in an automated fashion\r\nMentor and assist in the training and onboarding of other team members\r\nParticipate in open, frank discussions, especially in technical matters, while giving and accepting feedback and constructive criticism\r\n\r\nTop Skills:\r\nJava EE\r\nRest Web Services\r\nDrop Wizard or Spring Boot \r\nMicroservices\r\n\r\nNice to Have:\r\nWeb Service technologies:\r\n‚ó¶ GraphQL\r\n‚ó¶ WebSockets\r\nOAuth2\r\nAWS technologies:\r\n‚ó¶ Lambda\r\n‚ó¶ Kinesis\r\n‚ó¶ Dynamo\r\n‚ó¶ Aurora\r\n\r\nAdvantages of Working with Exadel:\r\nYou can build your expertise with our Sales Support team, who provide assistance with existing and potential projects\r\nYou can join any Exadel Community or create your own to communicate with like-minded colleagues\r\nYou can participate in continuing education as a mentor or speaker \r\nYou can take part in internal and external meetups as a speaker or listener. We support you in broadening your horizons and encourage knowledge sharing for all of our employees\r\nYou can learn English with the support of native speakers\r\nYou can take part in cultural, sporting, charity, and entertainment events\r\nWorking at Exadel means always upgrading your skills and proficiency, so we provide plenty of opportunities for professional development. If you‚Äôre looking for a challenge that will lead you to the next level of your career, you‚Äôve found the right place \r\nWe work hard to ensure honest and open relations between employees and leadership, so our offices are friendly environments",
         "Exadel",
         "2y",
         "Java",
         "intermediate",
         "2021-11-01T00:00:00+02:00",
         "en",
         "f594db26-4594-5710-8c51-dbe79a9d49cc",
         "27478"
        ],
        [
         "18",
         "1C/Baf developer",
         "The project goal is to develop the 1C ERP system according to stakeholders‚Äô requirements and newly established business processes within the Avenga: financial reporting, resource management, asset management etc. \r\n\r\nTogether with our CIS team, you will implement new features into the 1C system, monitor system integrity, deal with system data and provide audits.\r\nRequirements:\r\nMore than 3 years of experience in 1C/BAF development; \r\nUnderstanding of accounting principles;\r\nGood at Web/Think form development;\r\nEnglish ‚Äì Pre-intermediate or higher.\r\n\r\nResponsibilities:\r\nContinue implementation efforts of 1C system ‚Äì GL, Inventory, Purchasing, A/P, A/R and Reporting;\r\nGain understanding and skill in monitoring Avenga processes for issues;\r\nWork closely with IT on manufacturing and financial analytics as well as system integrity;\r\nAssist with system data clean-up and reconciliation;\r\nWork with engineering resources to appropriately document the 1C system in the correct repository;\r\nAssist with additional phases of 1C implementation;\r\nPerform, maintain and document system audits on regular cadence;\r\nMaintain clear and accurate system documents and procedures for reference and training purposes.",
         "Perfectial",
         "2y",
         "Other",
         "pre",
         "2022-09-01T00:00:00+03:00",
         "en",
         "22d230a7-669d-5c5a-be97-bc7980419e1b",
         "27479"
        ],
        [
         "19",
         "1C bas erp",
         "We are looking for an experienced 1C Analyst to join our team. You will be responsible for analyzing and optimizing the functionality of BAS ERP subsystems.\r\n\r\nRequirements:\r\n‚óè Knowledge of the principles of operation of the main subsystems of BAS ERP.\r\n‚óè Strong knowledge of the subject area, including accounting, tax and management accounting, production, warehousing and logistics.\r\n‚óè Ability to formalize client requirements and identify gaps between typical system functionality and these requirements.\r\n‚óè Experience in building and modeling customer processes in BAS ERP.\r\n‚óè Understanding of 1C system metadata, such as directories, registers, documents.\r\n‚óè Experience with workflow systems such as Jira, Trello, Worksection.\r\n\r\nResponsibilities:\r\n‚óè Studying the functionality of BAS ERP subsystems and identifying their compliance with customer requirements.\r\n‚óè Analyze and identify gaps between the current system functionality and customer needs.\r\n‚óè Formalization of customer requirements and preparation of analysis reports.\r\n‚óè Development and modeling of customer processes in BAS ERP.\r\n‚óè Collaboration with developers and testers to implement the changes.\r\n‚óè Ensuring high quality and meeting project deadlines.\r\n\r\nWe are looking for an independent and responsible person with high analytical thinking. Experience in working with BAS ERP subsystems and knowledge of accounting systems will be a great advantage. You should have good communication skills and the ability to work effectively in a team.",
         "PLATMA",
         "3y",
         "Data Science",
         "intermediate",
         "2023-07-01T00:00:00+03:00",
         "en",
         "30e87102-4df5-5a48-a746-8811475e483b",
         "27480"
        ],
        [
         "20",
         "1C Engineer",
         "N-iX is one of the fastest growing Ukrainian IT companies providing comprehensive software development services to a number of well-known international companies as well as European and US tech start-ups. Since 2002 we‚Äôve delivered excellence in software engineering and deep domain expertise in finance, healthcare, hospitality, telecom and other industries, helping our clients to implement technology and business transformations.\r\n\r\nDue to the development the company is currently seeking for 1C Engineer\r\nResponsibilities:\r\n- Developing new modules\r\n- Maintaining existing infrastructure\r\n\r\nQualification:\r\n- Experience in 1–° systems (modifications of configurations on controlled forms)\r\n- Experience in 1C Web forms\r\n- Knowledge of typical configurations 1C8\r\n- Experience in 1C API\r\n- Experience in 1C programming from 2 years old\r\n- Knowledge of SKD / updating the default configurations\r\n\r\nWe offer:\r\n- Flexible working hours\r\n- A competitive salary and good compensation package\r\n- Healthcare & Sport benefits program\r\n- Best hardware\r\n- An inspiring and comfy office\r\n\r\nProfessional growth:\r\n- Challenging tasks and innovative projects\r\n- An individual development plan\r\n- Mentorship program\r\n\r\nFun:\r\n- Corporate events and outstanding parties\r\n- Exciting team buildings\r\n- Memorable anniversary presents\r\n- A fun zone where you can play video games, ping pong, and more",
         "N-iX",
         "2y",
         "Other",
         "intermediate",
         "2021-06-01T00:00:00+03:00",
         "en",
         "2c6d9770-5bf4-51dd-b4e8-bcd857879541",
         "27481"
        ],
        [
         "21",
         "1C¬†QA Specialist",
         "WHAT YOU WILL BE DOING:\r\n‚Ä¢ Designing the relevant Test Cases/Check Lists to verify a test software effectively and apply to both new and existing product features\r\n‚Ä¢ Manual/automatic testing of modifications\r\n‚Ä¢ Writing documentation on the testing functionality\r\n‚Ä¢ Drafting instructions and PRDs\r\n\r\nWHAT YOU SHOULD HAVE:\r\n‚Ä¢ 2+ years of work as a tester or analyst 1C 8.–•\r\n‚Ä¢ Experience with non-typical 1C configurations\r\n‚Ä¢ Understanding the basic principles of 1C platform\r\n‚Ä¢ Understanding the basic principles of the financial part of accounting systems\r\n‚Ä¢ Participation in the end-to-end software development lifecycle\r\n‚Ä¢ Good skills in business analysis and writing functional documentation\r\n‚Ä¢ Experience in analyze the project documentation to ensure a thorough understanding of the business and technical requirements\r\n‚Ä¢ Experience in composing and writing relevant Test Cases/Check Lists to verify a test software effectively\r\n‚Ä¢ Experience with a managed application\r\n‚Ä¢ Basic knowledge of 1C queries\r\n\r\nWHAT WE OFFER:\r\nüßò Flat organizational structure\r\nüîù OKR-based planning\r\nüèÑüèª‚Äç‚ôÇÔ∏è Opportunities for professional development and personal growth\r\nüéì Unlimited budget for learning and development activities\r\nüíµ Social wellness package for medical insurance, sports, and health-related activities\r\nüëåüèª Flexible schedule and possibility to work entirely remotely\r\nüéâ Corporate events, holiday celebrations, team building activities\r\n\r\nSince 2008, iDeals has won the trust of half a million business users. We have supported thousands of customers to run high-value and mission-critical projects, from the cross-border sales of multi-billion-dollar assets to the development of revolutionary biotech products. Commitment to excellence has made iDeals the choice of big names, as well as ambitious startups. The growth goes on: the team is getting stronger; our client base and revenues are increasing year on year.\r\n\r\nWith us, you will grow professionally by doing work you can be proud of, receive top-market compensation, and collaborate with a motivated and diverse team.\r\n\r\niDeals is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people from all walks of life. We don‚Äôt discriminate against employees or applicants based on gender identity or expression, sexual orientation, race, religion, age, national origin or citizenship.",
         "iDeals Solutions",
         "2y",
         "Other",
         null,
         "2021-02-01T00:00:00+02:00",
         "en",
         "ddcdf438-aa18-5c11-919b-e4f12377a5dc",
         "27482"
        ],
        [
         "22",
         "1C Solution and Support Developer",
         "1C development, Python\t\t\t \r\nSQL\r\nWindows server and SQL server administration\r\nWeb services\t\r\nSAP or ERP system\r\nFluent English\n\nYour role\r\nSolution Development and Defects Fixes\r\n- Perform all phases of development of specific changes to the system \r\n- Ensure the quality of the solution and strive to identify and fix all defects \r\n- Ensure the Implementation and continuous improvement of the development processes \r\nCustomer and Production Support  \r\n- Ensure the systems are available according to availability agreements with key stakeholders \r\n- Ensure the systems are working correctly and the business teams can perform their work. Address any incidents, fulfill any request as necessary \r\n- Become a recognized customer point of contact for all inquiries or support issues and services requests on the systems in scope. \r\n- Manage customer satisfaction and service experience with a specific emphasis on customer care and the collection of customer feedback \r\n- Ensure the Implementation and continuous improvement of the Incident and service management processes \r\n- Advise internal partners on potential support issues and risks  \r\n- Use consistently ITIL best practices \r\n\r\nSkills needed \r\nGeneral development and support experience -  5 year  \r\n1C development, Python\t- 5 years  \r\nSQL\t- 5 years  \r\nWindows server and SQL server administration - 5 years  \r\nWeb services - 2 years  \r\nSome knowledge of FlyDoc, MeDoc  \r\nSAP or other similar ERP system - 2 year  \r\nUkraine accounting practices\t- 2 years  \r\nInternational accounting practices -1 year \r\nEnglish - fluent",
         "SII UKRAINE",
         "5y",
         "Other",
         "fluent",
         "2022-12-01T00:00:00+02:00",
         "en",
         "1c8dd404-6909-58df-bbe4-705b3b2f1871",
         "27483"
        ],
        [
         "23",
         "1Full Stack Software Engineer - NY Startup (React, Node, REST API) + –û–ø—Ü—ñ–æ–Ω!",
         "Our client, a US-based digital ordering technology developer with the most powerful personalization engine, is now looking for a Full Stack Software Engineer to join their team.\r\n\r\nType: Remote, full-time\r\n\r\nWhat is the project about:\r\n\r\nThe company reimagines the restaurant guest experience and develops an omnichannel digital ordering platform that uses AI and Machine Learning to power a guest preferences engine. Today, the company powers in-store ordering for leading restaurant brands like By Chloe, Togo's, Veggie Grill, and Num Pang.  \r\nTo provide a seamless experience to guests and restaurant brands, the company needs to communicate with a broad and ever-growing array of external services. The platform has a modular plug-n-play architecture that makes it easy to add any new integration from Sale systems to loyalty platforms to payments processors. The platform also have a completely customizable guest UI that can deploy to every restaurant in seconds. And it's all built using Node.js and MongoDB. \r\nOne example project that the company is looking to do in the next little while is to allow guests to pay simply by scanning a barcode on their phone and avoid the hassle of using a credit card.\r\nNow we are looking for a Full Stack Software Engineer to join the NYC or Toronto team and help take the platform to the next level to serve more guests and more restaurants. \r\n \r\nResponsibilities:\r\nBuilding web applications using HTML/CSS, JavaScript/Typescript, and Node.js\r\nWorking with product and design to creatively solve complex problems\r\nPrototyping and building clean and intuitive user interfaces through various iterations\r\nWriting modular, well-tested, and documented code\r\nDriving communication with 3rd-party companies that we have integrations with\r\nTaking ownership of engineering projects and seeing them through to completion\r\n\r\nRequirements:\r\nKnowledge how to throw together HTML and CSS in just the right way to make beautiful UI\r\nExpert in building all the logic in JavaScript using the latest standards\r\nExperience with Rea—Åt and understand components and state management\r\nExperience with REST APIs\r\nExperience with Github and Agile Development\r\nKnowledge all the latest developments in the space and are excited about applying them\r\nHave a passion for developing high-quality, modular, well-tested code\r\nEnglish - Upper Intermediate+\r\n\r\nIt would be especially awesome if:\r\n\r\nYou are familiar with Node.JS\r\nYou have build out REST APIs",
         "Art2Hire",
         "5y",
         "Node.js",
         "upper",
         "2021-08-01T00:00:00+03:00",
         "en",
         "e11eff69-5736-589b-aeb7-4e1e2d85d54f",
         "27484"
        ],
        [
         "24",
         "1.Middle/Senior Embedded C/C++",
         "The CHI team is looking for a Middle/Senior Embedded C/C++\n\nAbout the client:\r\nThe leading global supplier of embedded and connected software for the automotive industry.\r\nClient`s company develops the award-winning iGO Navigation Engine, which is flexible, designed for automotive use, and assists in prototyping and developing proofs of concept, whether it‚Äôs navigation, connectivity, HMI, or the complete in-car experience.\r\nFor deep integration, he configures his technology to communicate with the car sensors, the surrounding environment (ADAS), smartphones, and the cloud.\r\nThe client provides map updates and the latest map guarantee through various options, including incremental updates, over-the-air updates, end-user solutions, and partner solutions. This way, end users are guaranteed that their software, maps, and content are accurate, effective, and easy to keep fresh.\r\n\r\nRequirements\r\n- 3 years of relevant experience in C++ software development\r\n- Experience in software design and development in an Embedded environment\r\n- Familiarity with iPhone, Android, Linux, Windows CE, or QNX programming\r\n- Additional experience in Embedded memory management solutions, garbage collectors, performance measurement, and performance improvement\r\n- Active command of English\r\n- Creativity, a high level of independence\r\n\r\nResponsibilities\r\n- Work with automotive suppliers on developing unique navigation software solutions for next-generation car models\r\n- Develop iGO navigation software for different platforms\r\n- Create digital content for the Client‚Äôs navigation system, based on information provided by external suppliers\r\n- Work closely with project managers, software testers, and other staff\r\n\r\nBenefits\r\n\r\nWith us, you can\r\nDevelop your technical knowledge:\r\n- Use the latest technologies\r\n- Participate in technical events and conferences (the cost is covered by the company)\r\n- Regular tech talks and professional development\r\nImprove your soft skills:\r\n- Build strong teamwork skills and become an essential part of the dynamic teams\r\n- Improve your English in classes and speaking directly with clients\r\n- Increase your productivity and communication level via Scrum, Kanban, Agile methodologies\r\n\r\nWhat else do we offer?\r\n- Competitive compensation and benefits\r\n- Flexible working schedule\r\n- Remote work\r\n- Covered rest period (20 business days + 5 days off)\r\n- Professional growth: a variety of projects, regular technical events, mentorship\r\n- Free English classes (we have a fantastic English teaching team)\r\n- Speaking club with a native English speaker",
         "CHI Software",
         "3y",
         "C++",
         "intermediate",
         "2022-11-01T00:00:00+02:00",
         "en",
         "fa22a869-2b55-5bbb-9875-d3d688a73251",
         "27485"
        ],
        [
         "25",
         "#1 Senior Recruiter",
         "**We need \"hunter\"**, who will chase TOP1 candidates, give **fresh ideas** to our sourcing team about **recruitment strategy**, follow-ups and company **employee brand**.\r\n\r\n**#1 recruiter** who will **inspire candidates** with our mission, who is passionate enough to make candidates follow. \r\n\r\nGood candidates have ton of offers and propositions, so **we must be courage enough and fresh in our ideas to attract best candidates. **\r\n\r\n**We want those candidates, who is choosing options.** We don't need those, who doesn't have options. \r\n\r\n**We need **\r\n- Specialist with 3+ years of experience in recruitment and hiring C-level positions.\r\n - With excellent English\r\n - And great communication skills\r\n\r\nRight now our recruitment team consist of 2 sourcing people:\r\n- one girl, who is super good in automating outreach in LinkedIn and collecting database of candidates\r\n- one guy, who is doing hand-made sourcing on djinni, freelance, etc\r\n\r\nAll interviews and key decisions to hire right now performed by C-level: CEO, COO, Head of Sales, CMO.\r\n\r\n\"good polite HR girl\" is not something we are looking for. Our HR processes are working enough good as for now. \"–¢–µ–∫—É—á–∫–∞\" is very very low, around 3%/yearly.\r\n\r\n**Join us and let's make it together! Send your CV!**",
         "EvaCodes",
         "2y",
         "Recruiter",
         "fluent",
         "2022-11-01T00:00:00+02:00",
         "en",
         "408a5918-20b9-57b8-8a58-ff2ef355c43b",
         "27486"
        ],
        [
         "26",
         "1st / 2nd Line IT Support Engineer",
         "THE ROLE:\r\nOur Engineers help small businesses with any technology questions or problems, we basically do what an IT Department would for a large business - anything technology! From servers, laptops, Macs, PCs, printers, mobile devices to websites, hosting and advising on product specifications - we do it all. We currently need a Systems Engineer to work with our high calibre team to help our client base.\r\n\r\n**YOUR BACKGROUND:**\r\nDemonstrated field experience is required, with at least 3 years industry experience essential. You must have sound knowledge and experience in:\r\n\r\nExperience in managing cloud solutions (GSuite, Office 365)\r\n**Office 365 experience\r\nWindows Server and/or OS X Server\r\nWindows client & Mac OS\r\nGeneral networking\r\nGeneral email and hosting services\r\nGeneral computer hardware**\r\nPowershell and Bash knowledge is a plus\r\nMicrosoft certificates is a plus\r\nExperience with Apple Macs & iPhones, Android, Windows Phone, Linux, and small businesses would be desired.\r\nA terrific client service attitude\r\nA willingness to learn and develop\r\nA decent level of spoken and written English (English courses will be provided)\r\n**WE OFFER**\r\nFlexible working with up to 50% time working from home\r\nPerformance bonus\r\nAutomatic overtime\r\nDouble pay on weekends\r\nCommission when you help the sales team\r\nWorld-class benefits (from health coverage to holidays)\r\nBi-annual competitions with big prizes & incentives\r\nEngineers can easily put 20-40% on their base salary with bonuses, overtime and commission\r\n2 English lessons/week (business hours, at company's cost);\r\nBar on company's account;\r\nMonthly fun events;\r\nAnd more!\r\nWe'll leave it up to you to tell us why you would be a good addition to our friendly and knowledgeable team. We look after clients with Windows, Mac and Linux machines, so tell us where your passion lies!\r\n\r\n**REMUNERATION AND WORK HOURS**\r\nThe Engineer role is full time (40 hours per week, 5 x 8 hour days) with negotiable flexible hours - whatever makes you more productive! You'll be asked to work as a Private Entrepreneur. Probation period\r\n4 months",
         "MeekoTeams",
         "2y",
         "Sysadmin",
         "upper",
         "2022-11-01T00:00:00+02:00",
         "en",
         "85a70afa-cef9-5a10-88e8-5d7aac3328e9",
         "27487"
        ],
        [
         "27",
         "1st and 2nd Level Support",
         "**Product and Support Specialist (m/f/d)**\r\nRemote. Full-time. Contractor.\r\n\r\n**As a Product and Support Specialist you will:**\r\n**TROUBLESHOOTING** ‚Äì You are our customers‚Äò primary and secondary technical contact and answer customer requests in in-product live-chat. You are finding the best solutions for upcoming issues either by only answering small questions or by supporting the operation of our software solutions and server. You provide first-lever and second-level support for EU time zone customers and US customers outside US working hours.\r\n\r\n**SAAS MONITORING** ‚Äì You use the monitoring systems and tools to proactively monitor, identify and process any incidents by communicating to the customer or fixing the problem.\r\n\r\n**SETUP AND OPERATIONS** ‚Äì You are responsible for setting up, configuring, and using cloud management/monitoring tools and managing the cloud environments (backup, etc.). Additionally, you will support the operation of our software and servers and perform software updates and upgrades on Windows and Linux customer \r\n\r\n**Our ultimate candidate will have:**\r\n- Understanding of database technology\r\n- Experience with Cloud Platforms (AWS, Azure) & container platforms\r\n- Working experience with Linux\r\n- Good SQL skills\r\n- Ability to debug the source code and to reproduce customer issues in a local environment\r\n- Minimum 2-3 years experience in software support/consulting or comparable function\r\n- Basic understanding of Business intelligence use cases\r\n- Strong communication skills paired with empathy\r\n- Fluent in spoken and written English\r\n- Self-organized working method\r\n- The highest levels of motivation, responsibility, and ambition to proactively support the growth of our company\r\n- Problem solving skills\r\n- Inquiring mindset\r\n\r\n**What we offer**\r\n- A job with the stability and team spirit of an employee, but with the freedom and flexibility of a freelancer\r\n- Flexible working hours \r\n- Contributing to the success of a growing company \r\n- Supporting groundbreaking data technology and working with cutting edge technologies\r\n- Full integration into our teams and invitation for our team events worldwide\r\n- Continuity and growth potential\r\n\r\n**What our amazing team worldwide additionally loves about working with Data Virtuality**\r\n- Flexibility to decide where to work\r\n- Knowledgeable and approachable C-Level\r\n- Reliable and fast monthly payment ‚Äì in EUR, USD Crypto, as you prefer\r\n- Friendly and international colleagues\r\n\r\nAt Data Virtuality, you will experience respectful interactions, harmonious teamwork, without a dog-eat-dog mentality!\r\n\r\n**Data Virtuality in a Sec**\r\nLeading various large scale data integration projects at a global media company, our founder Dr. Nick Golovin experienced that it isn‚Äôt enough to rely on just one data integration approach to meet the ever-changing business needs. That‚Äôs why the Data Virtuality Platform uniquely combines data virtualization and ETL, to provide data professionals with a data integration tool that allows to always choose the right method for the specific requirement. Data Virtuality‚Äôs flexible data integration approach is the reliable enabler and accelerator for modern data architectures, like data fabric, data mesh, unified data platform and hybrid-/multi-cloud environments.",
         "Data Virtuality",
         "2y",
         "Support",
         "upper",
         "2022-03-01T00:00:00+02:00",
         "en",
         "bc1b694a-544c-5c9a-957a-565f91bac3b7",
         "27488"
        ],
        [
         "28",
         "1st level customer support - FLUENT ENGLISH",
         "Voxloud is looking for a high-energy and dynamic Customer Support Agent to provide 1st support to our English customers.\r\nThe successful candidate will be included in the 1st level customer service team and will be responsible for analyzing and developing relationships with acquired customers with a view to improving the service, problem-solving, resolving 1st level problems. A further purpose of the phone, chat, or email contact will be to understand any latent needs of the customer or unexpressed problems and solve them proactively, thanks to the tools made available by the company.\r\n\r\nThe customer support service will be provided via phone, email, and chat. The resource will be fully trained by the company, both before and after insertion into the department. The candidate, in particular, will deal with:\r\n\r\n1st level problem solving\r\nGuide users to read the right articles of our Help Center and follow them during the necessary operations\r\nAny follow-up for optimal ticket closure and feedback collection\r\n\r\nMinimum requirements:\r\n\r\nHigh level of English written and spoken\r\nComfort in communicating with the customer by phone, email, and chat\r\nAbility to manage various tasks\r\n\r\nNice to have:\r\n\r\nMinimum experience in customer care or customer support\r\nKnowledge of troubleshooting and internal communication tools like Intercom, Slack, Jira\r\n\r\nWe offer:\r\n\r\nOpportunity to work in a young multinational team of professionals\r\nPaid vacations\r\nFull remote ‚Üí work from home 100% of the time\r\nBest-in-class training program and opportunity to grow inside the company\r\nCompany culture based on meritocracy and teamwork.\r\nCompetitive salary, based on experience and skills",
         "Wildix",
         "1y",
         "Support",
         "upper",
         "2021-01-01T00:00:00+02:00",
         "en",
         "4c940d37-cd24-5c2f-8769-5fb69c990c1f",
         "27489"
        ],
        [
         "29",
         "1st line Customer Support Engineer",
         "The 1st line Customer Support Engineer is a direct point of contact for customers who assists in troubleshooting and resolving issues with the product, or detects the need to escalate/transfer the issue to the next level of technical support.\r\n\r\nResponsibilities:\r\n\r\n- Receive and manage customers' requests, questions through Support Team communications channels\r\n- Research and identify solutions to software and hardware issues reported by customers with the help of 2nd line of Support and Product Teams\r\n- Diagnose and troubleshoot technical issues, including account setup\r\n- Ask customers targeted questions to quickly understand the root of the problem and gather additional details for higher levels of support\r\n- Monitor issues through to resolution, within agreed time limits (Support SLA)\r\n- Talk clients through a series of actions, either via web meeting session, email or chat, until they've solved an issue\r\n- Properly escalate issues unresolved by 1st line to appropriate internal teams - 2nd line and/or Product Teams, etc.\r\n- Refer to internal database, public database or external resources to provide accurate solutions\r\n- Ensure all issues are properly logged within the ticketing system\r\n- Prioritize and manage several open issues at one time\r\n- Follow up with clients to ensure their systems are fully functional after troubleshooting\r\n- Maintain jovial, friendly relationships with customers\r\n\r\nRequirements:\r\n\r\n- English: Upper-Intermediate or higher\r\n- Russian or Ukrainian - Upper-Intermediate or higher\r\n- Excellent PC skills and a good technical background in general\r\n- Excellent communication skills\r\n- Team player\r\n- Ability to multitask\r\n- Ability to work in shifts\r\n- Flexible and abstract thinking\r\n- Stress-resistant\r\n- Being ready to make decisions and explain them\r\n\r\nWe offer:\r\n\r\n- An opportunity for self-realization and professional growth\r\n- Convenient location (a few minutes from a subway station)\r\n- Paid sick-leave, 20 working days of vacation, days off in accordance with national calendar of holidays\r\n- Friendly team of professionals\r\n- Comfortable working environment, free coffee and cookies\r\n- Corporate health insurance\r\n- Compensation for training and English courses\r\n- Corporate events, team building\r\n\r\nWe hugely rely on common sense in all we do at FluentPro.\r\n\r\nOur software development is flexible and everyone on the Team gets time to both perform set tasks and communicate with colleagues, do research and extra training, etc.\r\n\r\nWhen you send your CV you give us consent to the processing of your personal data in order to selecting and hiring the company's staff.",
         "FluentPro",
         "1y",
         "Support",
         "upper",
         "2022-06-01T00:00:00+03:00",
         "en",
         "b3916c69-0670-5cb3-bfb7-e5b2fd3cf675",
         "27490"
        ],
        [
         "30",
         "1st Line Customer Support (night shifts)",
         "Day-to day activities\r\nRegistration, description, classification of the incoming issues\r\nProvide 1st line support (via chat) to customers to ensure their content functions as designed and that Customers are taking full advantage of the various Viseven services functionality.\r\nAid Customer in streamlining business processes for increased productivity and efficiency.\r\nGenerate and share educational resources, trainings, and best practices.\r\nExpected to consistently provide excellent Customer services and represent client needs and goals within Viseven to ensure quality.\r\nBuild relationships with Customer to encourage repeat business opportunities.\r\nKeep abreast of new company products and services, and introduce them into Customers' development processes.\r\nTroubleshoot software-related issues and provide fast feedback about them\r\n\r\nRequirements\r\nEnglish Level ‚Äî from Upper-Intermediate (B2+);\r\nStrong problem solving and research skills;\r\nAbility to learn and adapt fast;\r\nStress tolerance and decision-making;\r\nAbility to work in team;\r\nHigh ability to demonstrate and present our solutions to technical and non-technical audiences;\r\nDriven and motivated mindset;\r\nCustomer support experience will be a great plus!\r\n\r\nWhat we provide:\r\nWe understand that our team members are essential to making our goals a reality, so we value and empower them to share their vision. And we reward this kind of passion with a highly competitive compensation and exceptional benefits, such as:\r\n¬∑ Passionate experienced team and enjoyable working environment\r\n¬∑ Professional and career growth\r\n¬∑ Paid time off 18 business days per year\r\n¬∑ Paid time off 3 business days in case of marriage or childbirth\r\n¬∑ Healthcare insurance ‚Äì including dentist and gym\r\n¬∑ Accounting assistance\r\n¬∑ Free tea/coffee, fruit and snacks\r\n¬∑ English learning courses\r\n¬∑ Opportunities to participate in professional forums and conferences\r\n¬∑ Regular corporate events and team-buildings",
         "Viseven",
         "1y",
         "Support",
         "upper",
         "2021-08-01T00:00:00+03:00",
         "en",
         "b591b7c5-212d-57de-bc7c-dec40e6c70b7",
         "27491"
        ],
        [
         "31",
         "1st Line Support Engineer",
         "Responsibilities:\r\n\r\n‚Ä¢ Ensure the best quality of the service provided for our customers\r\n‚Ä¢ Incident management\r\n‚Ä¢ Incidents intake via phone, emails, or helpdesk\r\n‚Ä¢ Performing incident analysis\r\n‚Ä¢ Details/materials collection (stack traces, screenshots, logs, scanner files)\r\n‚Ä¢ Providing calls with clients\r\n‚Ä¢ Performing planned functional system monitoring\r\n‚Ä¢ Documentation update\r\n\r\nRequired skills:\r\n\r\n‚Ä¢ Upper-intermediate/Advanced English (written and spoken)\r\n‚Ä¢ Nice to have a technical background or basic IT education\r\n‚Ä¢ Experience working with helpdesk\r\n\r\nAs a plus:\r\n\r\n‚Ä¢ Pro-activeness in communication with the customer and 2nd line of support\r\n‚Ä¢ Highly motivated with a strong sense of responsibility, result-oriented\r\n‚Ä¢ Willing to gain new skills and learn new product\r\n‚Ä¢ Attentive to details; strong logical thinking\r\n\r\nWe offer:\r\n\r\n‚Ä¢ Competitive compensation higher than average on the market\r\n‚Ä¢ Paid 24-day vacation, compensation of educational courses\r\n‚Ä¢ Regular salary review based on employee performance\r\n‚Ä¢ Ability to learn from industry leaders and work with international clients\r\n‚Ä¢ Convenient office location in a quiet downtown area (Pecherska St.)\r\n‚Ä¢ Business trips to European countries\r\n‚Ä¢ No micromanagement: we encourage self-organization and trust\r\n‚Ä¢ English classes with the opportunity to upgrade your grammar and speaking skills\r\n‚Ä¢ Friendly, international democratically oriented team\r\n‚Ä¢ PS4, regular corporate events",
         "Edsson Ukraine LLC",
         "1y",
         "Support",
         "intermediate",
         "2021-08-01T00:00:00+03:00",
         "en",
         "2e7aeb94-d9f8-52b0-8c2f-6278d0c57993",
         "27492"
        ],
        [
         "32",
         "1st. Line Support Engineer / Customer Success Engineer",
         "GLOBRECS | Global Recruitment Solutions is a recruiting company specializing on timely and high-quality IT recruitment and Executive Search services around the globe.\r\n\r\nWe are looking for the 1st. Line Support Engineer / Customer Success Engineer for a growing and innovative product in the enterprise integration market.\r\n\r\nOur client is a Salesforce-native customer engagement toolset that helps its clients to lead their team to repeatable revenue. Covering the full sales cycle from getting the first touch to closing and upselling, our clients‚Äô product allows users to analyze, execute and lead their growth strategy.\r\n\r\nTO DO LIST:\r\nProviding the 1st. line support for the company‚Äôs software products;\r\nRespond to Customer Support Cases and Escalations in a timely manner and maintaining high customer satisfaction;\r\nPro-actively monitor the customers‚Äô activities and to resolve or escalate the customers‚Äô issues;\r\nDrive the issues resolution and custom solutions implementation;\r\nManage technical discovery sessions to gather Customer requirements;\r\nConduct Data and Configuration audits to verify integration prior to launch, and assist in other testing/QA activities in support of getting your Customers live;\r\nDrive prove-of-concept projects;\r\nRecommend best-practice approaches to integration, implementation, and product configuration, and provide technical instruction to Customer teams during Onboarding;\r\nPartner with cross-functional teams. Work with Product Management, Support, and Engineering to translate Customer business needs and product feedback into new solutions. Assist Sales in setting up prospective customers for success in onboarding;\r\nBe a reliable direct point-of-contact for the company‚Äôs customers (mainly located in the USA);\r\nDocument the requirements and integration approach for the Customers;\r\nDocument the use cases and support cases in the knowledge base.\r\n\r\nQUALIFICATIONS:\r\nExcellent spoken and written English is a must;\r\n3+ years relevant work experience in a customer-facing customer success engineering, professional services, or technical consulting role. SaaS experience preferred;\r\nDemonstrated cloud and desktop software troubleshooting skills;\r\nDemonstrated web applications troubleshooting skills;\r\nDemonstrated Windows desktop OS troubleshooting skills;\r\nExperience with application logs investigation and interpretation;\r\nAdvanced Microsoft Outlook user;\r\nUnderstanding of SQL databases;\r\nFamiliarity with Salesforce.com or other CRM platform;\r\nFamiliarity with JIRA or other ticket tracking system;\r\nExperience with requirements gathering;\r\nStrong analytical skills;\r\nCustomer-oriented mindset;\r\nProduct quality improvement-oriented mindset;\r\nBasic XML knowledge;\r\nAbility to work on shifted schedules (USA work hours);\r\nExperience in technical documents writing (in English).\r\n\r\nNICE TO HAVE:\r\nKnowledge of Microsoft Azure Application Insight;\r\ncom custom development;\r\nEnterprise application development or integration;\r\nWeb Development, including HTML and JavaScript;\r\nExperience with MAC OS applications troubleshooting;\r\nResponsible and self-motivated;\r\nAbility to learn new technologies;\r\nAbility to multitask and prioritize between competing activities;\r\nAbility to travel abroad for onsite customer workshops and events (1-2 weeks).\r\n\r\nQUIRKS & PERKS:\r\nFriendly, informal, and knowledge-sharing environment with smart people around you;\r\nChance to join a team and a company globally recognized for its cutting edge products;\r\nA great opportunity for your further professional growth;\r\nA nice monthly salary 2000-2500$ (which as always depends on skills);\r\n20-days of annual paid vacation;\r\n20-days paid out of office work annually;\r\nPremium medical insurance for those who successfully pass their trial period;\r\nCorporate activities, including common travels, skiing, events, team numerous buildings;\r\nPartly or fully paid trainings (when necessary);\r\nSnacks and drinks in the office;\r\nTable football, ping-pong in the office;\r\nPerformance bonus program;\r\nOffice location in downtown, nearby Olimpiyska metro station.\r\n\r\nGLOBRECS | Global Recruitment Solutions ‚Äì your success is our challenge!",
         "GLOBRECS | Global Recruitment Solutions",
         "2y",
         "Support",
         "fluent",
         "2020-11-01T00:00:00+02:00",
         "en",
         "20cd2d93-0912-58e6-b838-fe3f8913ea61",
         "27493"
        ],
        [
         "33",
         "1st. Line Support Engineer / Customer Success Engineer",
         "Our client is a Salesforce-native customer engagement toolset that helps its clients to lead their team to repeatable revenue. Covering the full sales cycle from getting the first touch to closing and upselling, our clients‚Äô product allows users to analyze, execute and lead their growth strategy.\r\n\r\nTO DO LIST:\r\nProviding the 1st. line support for the company‚Äôs software products;\r\nRespond to Customer Support Cases and Escalations in a timely manner and maintaining high customer satisfaction;\r\nPro-actively monitor the customers‚Äô activities and to resolve or escalate the customers‚Äô issues;\r\nDrive the issues resolution and custom solutions implementation;\r\nManage technical discovery sessions to gather Customer requirements;\r\nConduct Data and Configuration audits to verify integration prior to launch, and assist in other testing/QA activities in support of getting your Customers live;\r\nDrive prove-of-concept projects;\r\nRecommend best-practice approaches to integration, implementation, and product configuration, and provide technical instruction to Customer teams during Onboarding;\r\nPartner with cross-functional teams. Work with Product Management, Support, and Engineering to translate Customer business needs and product feedback into new solutions. Assist Sales in setting up prospective customers for success in onboarding;\r\nBe a reliable direct point-of-contact for the company‚Äôs customers (mainly located in the USA);\r\nDocument the requirements and integration approach for the Customers;\r\nDocument the use cases and support cases in the knowledge base.\r\n\r\nQUALIFICATIONS:\r\nExcellent spoken and written English is a must;\r\n3+ years relevant work experience in a customer-facing customer success engineering, professional services, or technical consulting role. SaaS experience preferred;\r\nDemonstrated cloud and desktop software troubleshooting skills;\r\nDemonstrated web applications troubleshooting skills;\r\nDemonstrated Windows desktop OS troubleshooting skills;\r\nExperience with application logs investigation and interpretation;\r\nAdvanced Microsoft Outlook user;\r\nUnderstanding of SQL databases;\r\nFamiliarity with Salesforce.com or other CRM platform;\r\nFamiliarity with JIRA or other ticket tracking system;\r\nExperience with requirements gathering;\r\nStrong analytical skills;\r\nCustomer-oriented mindset;\r\nProduct quality improvement-oriented mindset;\r\nBasic XML knowledge;\r\nAbility to work on shifted schedules (USA work hours);\r\nExperience in technical documents writing (in English).\r\n\r\nNICE TO HAVE:\r\nKnowledge of Microsoft Azure Application Insight;\r\ncom custom development;\r\nEnterprise application development or integration;\r\nWeb Development, including HTML and JavaScript;\r\nExperience with MAC OS applications troubleshooting;\r\nResponsible and self-motivated;\r\nAbility to learn new technologies;\r\nAbility to multitask and prioritize between competing activities;\r\nAbility to travel abroad for onsite customer workshops and events (1-2 weeks).\r\n\r\nQUIRKS & PERKS:\r\nFriendly, informal, and knowledge-sharing environment with smart people around you;\r\nChance to join a team and a company globally recognized for its cutting edge products;\r\nA great opportunity for your further professional growth;\r\nA nice monthly salary 2000-2500$ (which as always depends on skills);\r\n20-days of annual paid vacation;\r\n20-days paid out of office work annually;\r\nPremium medical insurance for those who successfully pass their trial period;\r\nCorporate activities, including common travels, skiing, events, team numerous buildings;\r\nPartly or fully paid trainings (when necessary);\r\nSnacks and drinks in the office;\r\nTable football, ping-pong in the office;\r\nPerformance bonus program;\r\nOffice location in downtown, nearby Olimpiyska metro station.",
         "Freelance",
         "3y",
         "Support",
         "fluent",
         "2020-11-01T00:00:00+02:00",
         "en",
         "d75ce0b1-52ae-58a3-b527-941c157c2dd6",
         "27494"
        ],
        [
         "34",
         "1st Sales Development Representative",
         "Requirements:\r\n\r\nThe following are absolute MUST-HAVEs for this role:\r\n\r\n‚Äî fluent spoken English with a neutral accent\r\n‚Äî significant experience doing sales development at a tech startup/outsourcing company with a proven track record (revenue generated, conversions, stats etc)\r\n‚Äî self-motivated and self-organized\r\n‚Äî team-oriented attitude\r\n\r\nWhat we offer:\r\n‚Äî salary + bonuses (% for pipeline generated and for pipeline won by our Account Executives)\r\n‚Äî you‚Äôll be the first dedicated SDR on the team and with the dep-t‚Äôs growth you‚Äôll have the opportunity to build and lead it\r\n‚Äî the friendliest fast-moving ambitious startup team you can find in Ukraine\r\n‚Äî opportunity to work with the world‚Äôs brightest entrepreneurs ‚Äî our customers. Our founders too ‚Äî they‚Äôre Y Combinator alumni after all\r\n‚Äî great comedy content tips: standup specials and TV series\r\n‚Äî work schedule: Monday-Friday, the hours are flexible but our sales team generally works 13:00-21:00 because of the overlap with the US customers\r\n‚Äî location: LVIV (a quite neat office) OR REMOTE\r\n\r\nTasks:\r\n1) setting up SD best practices, building processes,\r\n2) daily cold outreach to leads with a goal to set up ‚Äôproduct demo calls‚Äô (contacts will be provided):\r\n‚Äî cold emailing, social media, experimental channels,\r\n‚Äî occasional cold calling too.\r\n3) following-up,\r\n4) outreach analytics and CRM management,\r\n5) research on various customer-related topics,\r\n6) transferring qualified leads to the Account Executives.",
         "Che IT Group",
         "3y",
         "Sales",
         "fluent",
         "2021-02-01T00:00:00+02:00",
         "en",
         "21b6b51d-a6c3-5125-b50e-c3a2c86588b5",
         "27495"
        ],
        [
         "35",
         "1 to 4 Senior Backend .NET Developers",
         "What we definitely expect from you:\r\nBack End / Full stack\r\nMicrosoft .NET Core\r\nMicroservices\r\nWeb API\r\nSQL Server\r\nRabbitMQ\r\nFront end: Angular + Knockout (Legacy).\r\nEnglish - Upper-Intermediate+\r\n\r\nWe offer:\r\nFull-time workload\r\nProject starts ASAP after approval\r\nLong-term involvement (12 months)\r\nWorthy reward based on your skills and experience",
         "AOG.jobs",
         "5y",
         ".NET",
         "upper",
         "2021-09-01T00:00:00+03:00",
         "en",
         "c90c29c1-4539-520b-8fba-e0e1f9973467",
         "27496"
        ],
        [
         "36",
         "2004/07 Senior BackEnd Engineer",
         "**We are looking for a self-motivated and goal oriented Senior Back End Engineer who would like to be a part of a team working on brand new startup projects for foreign customers. We are looking for a senior backend engineer who is fluent in Python. This is a great opportunity to define and implement a large scale zero trust solution that allows companies to provide employees seamless and secure access to internal and cloud-based resources. You will be part of a passionate and high energy team that is creating compelling, new and innovative online technologies. This position requires someone who thrives on finding innovative solutions to real problems.**\r\n\r\n**REQUIREMENTS**\r\n- B.Sc in Computer Science, Computer Engineering or related technical discipline\r\n- 5 years hands-on experience in building and delivering large scale application into production\r\n- Strong proficiency in Python. Django experience is a big advantage.\r\n- Hands-on experience in a public cloud environment (AWS, Azure, GCP)- GCP is a big advantage\r\n- Passionate in writing high quality and clean code - OOP, SOLID, etc.\r\n- Experience in building systems in a micro-services architecture\r\n- Excellent verbal and written English\r\n- Hands on experience with both relational and no-SQL databases\r\n- Excellent communication skills and being able to work independently or in a full team\r\n\r\n**Optional, but a major plus:**\r\n- Hands on experience with docker/k8s is a big plus\r\n- Experience building GraphQL APIs\r\n- Building CI pipelines\r\n- Familiar with Async programming concepts\r\n- Knowledge in basic computers networking\r\n- Technical Leadership/Mentoring experience\r\n\r\n**RESPONSIBILITIES**\r\n- Develop large scale security solution\r\n- Design and architect a micro-services system\r\n- Take ownership on entire lifecycle management\r\n- Keep innovating while working on bleeding edge technologies\r\n- Mentor junior engineers\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- Friendly climate inside the company ‚Äì previous employees have come back often\r\n- Flexible working hours\r\n- 100% paid sick leave\r\n- Paid participating in the sports events\r\n- Educational budget\r\n- Paid sick leave 9 days\r\n- Paid vacation - 18 working days",
         "Argument",
         "5y",
         "Python",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "92d5c93e-4cc1-5d7b-94fb-bcaf712e995f",
         "27497"
        ],
        [
         "37",
         "2004/12 Database Administrator (DBA)",
         "WE OFFER\r\nPeople-oriented management without bureaucracy\r\nFriendly climate inside the company ‚Äì previous employees have come back often\r\nFlexible working hours\r\nBusiness trips to customers\r\n100% paid sick leave\r\n\r\nRESPONSIBILITIES\r\nRDS configuration and tuning\r\nRDS monitoring, db design and schema updates with Dev team\r\nExisting SP and SQL improvements\r\nCreation of new SP and SQL, same from MongoDB\r\nWill be handling SQL and tuning for our Siesnse Cude (BI tool)\r\n\r\nREQUIREMENTS\r\n4+ years of experience as a DBA\r\nCritical Skills: SQL/MySQL/AWS Amazon (RDS)\r\nHands-on experience in database administration with MySQL (RDS), including monitoring, capacity planning, load balancing, performance tuning, high availability and multi-site disaster recovery deployment on complex database environments\r\nExtensive knowledge with complex SQL programming and optimization\r\nExperience in database schema design including logical and physical database schemas design for large scale, highly available and mission-critical application systems\r\nExperience designing and supporting the database components of software applications, and understanding of entire application development life cycle\r\nAbility to communicate on English\r\n\r\nWILL BE A PLUS\r\nProven experience working with Sisense Cube\r\nHand-on experience in database administration with MongoDB\r\nProgramming experience (Python)\r\n\r\nThe project is an award-winning collaborative hiring platform for high-growth companies. The project was funded in 2013 to bring modern collaboration and workflow tools to help high-growth companies build their global teams. The initial launch in early 2015 was focused on Israel, where it has become the fastest-growing recruiting software solution and the system of choice for Israeli tech companies. More than 100 companies, including Fiverr, Playtika, Playbuzz, and AppsFlyer have chosen or switched to the project to build their global teams. Today, the project is expanding globally also through global strategic partnerships with leading international brands who will introduce and champion the project to their networks. The project offers a cloud-based collaborative recruiting platform that feels like user-friendly consumer software. It provides structured and streamlined processes to enable companies to make better hires, faster. The project requires little to no training. Because it is so easy to use, the system boasts a very high participation rate of non-HR members per recruiter, making the platform not only collaborative in theory but also in practice.\r\nThe project is an UpWest Labs graduate with offices in Palo Alto and Tel Aviv",
         "Argument",
         "3y",
         "SQL",
         "upper",
         "2021-04-01T00:00:00+03:00",
         "en",
         "390b30c2-710d-5524-81a7-fd4418502465",
         "27498"
        ],
        [
         "38",
         "2004/23 RoR Full Stack Developer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**\r\nRuby on Rails - 3 –≥–æ–¥–∞\r\nHTML & CSS - 3 –≥–æ–¥–∞\r\nJavaScript - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ NoSQL\r\n–û–ø—ã—Ç –≤ TDD\r\n–û–ø—ã—Ç –≤ RSpec\r\n\r\n**ABOUT THE PROJECT**\r\nThe project is where enterprise tech decision-makers go to read peer product reviews in Cybersecurity, DevOps, and IT. Every reviewer on the project is verified to help buyers make well-informed, smart business decisions.\r\n\r\nThe project has grown into a dynamic, real-time platform that offers user information that is current, objective, and relevant. It protects privacy in that users can either post anonymously to freely express their views or use their real names to promote their expertise. It enables knowledgeable experts, including real users and independent consultants, to share their expertise in a high-quality community of decision-makers.\r\n\r\n**WE OFFER**\r\n- People oriented management without bureaucracy\r\n- Friendly climate inside the company ‚Äì previous employees have come back often\r\n- Flexible working hours\r\n- 100% paid sick leave\r\n- Paid participating in the sport events\r\n- Educational budget\r\n\r\n**RESPONSIBILITIES**\r\n- Introducing new APIs and vendor integrations (Constantly changing)\r\n- The business logic code supporting operations. (Ruby on Rails)\r\n- The underlying business data (MySQL, Postgres/TimescaleDB)\r\n- The tracking and reporting pipelines to provide consistent and critical data reports about every aspect of the site (Google Analytics, Postgres)\r\n- Basic server operations (Unix, Chef, Apache, Load Balancing, DNS)\r\n\r\n**REQUIREMENTS**\r\n- 3 years of experience with RoR\r\n- 3 years of experience with JavaScript, HTML, CSS\r\n- Experience with relational and NoSQL databases\r\n- Experience with TDD and writing unit tests with RSpec\r\n- Strong sense of ownership over everything you do. - You own your work from definition to delivery.\r\n- Constant learner ‚Äì Should be interested in staying up to date on technical developments as well as our business environment.\r\n- Collaboration specialist - As part of the dev team, you‚Äôll be supporting every part of the business and working with almost everyone. That‚Äôs a good thing!\r\n- Excellent communication skills\r\n- Excellent spoken and written English",
         "Argument",
         "3y",
         "Ruby",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "734ee1ed-c97c-5dc3-ab26-77ace2a90b28",
         "27499"
        ],
        [
         "39",
         "2004/25 Middle Full Stack Developer",
         "ABOUT THE PROJECT\r\nThe project provides a self-service environment platform that anyone can easily create and use. Empowered by a Drag'N'Drop functionality, project's suite offers an intuitive, visual, and codeless interaction. The platform streamlines the delivery of virtual environments for produc\r\n\r\nWE OFFER\r\n- People-oriented management without bureaucracy.\r\n- Friendly climate inside the company ‚Äì previous employees have come back often.\r\n- Flexible working hours.\r\n- 100% paid sick leave.\r\n- Paid participation in sports events.\r\n- Educational budget.\r\n\r\nRESPONSIBILITIES\r\n- Design and develop reliable, scalable, and maintainable products\r\n- Develop software that meets the product requirements\r\n- Ensuring development products are delivered on time\r\n\r\nREQUIREMENTS\r\n- At least 2 years‚Äô hands-on programming experience in languages such as Java, Python, JavaScript (Specifically React)\r\n- Experience in adapting various frontend libraries (i.e., vis.js) and React frameworks (i.e., Material-UI)\r\n- Experience in Cloud / SAAS products\r\n- Experience with cloud infrastructure (as development platform)\r\n- Proven software design experience\r\n- BA/BS degree in Computer Science or related engineering field or equivalent practical experience\r\n- English level ‚Äì upper-intermediate, good speaking and writing\r\nWILL BE A PLUS\r\n- Experience with Orchestration, Provisioning and Automation technologies (i.e. Terraform, Puppet, Chef, Ansible)\r\n- Experience with front/back/database development of dashboards based on React and Java\r\n- Experience with Infrastructure as code projects\r\n- DevOps state of mind\r\n- You have built, deployed, and maintained large scale SaaS applications",
         "Argument",
         "2y",
         "Python",
         "intermediate",
         "2021-04-01T00:00:00+03:00",
         "en",
         "13285fa3-5b45-59a5-8f6d-31690a71cbc6",
         "27500"
        ],
        [
         "40",
         "2004/30 Senior Software Development Engineer (Java)",
         "**ABOUT THE PROJECT**\r\nProject is a catalyst for your value-based healthcare system. It is a healthcare technology company that offers software, analytics, network solutions, and technology-enabled services to help create a stronger, more collaborative healthcare system. It helps deliver measurable value not only at the point of care, but also before, after, and in between care episodes.\r\n\r\n**ABOUT THE POSITION**\r\nCompany is looking for a self-motivated and goal-oriented Software Development Engineer who would like to be a part of a team working on brand new startup projects for foreign customers.\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- Friendly climate inside the company ‚Äî previous employees have come back often\r\n- 100% paid sick leave\r\n- Paid participating in the sports events\r\n- Educational budget\r\n- Paid sick leave ‚Äî 9 days\r\n- Paid vacation ‚Äî 20 working days\r\n\r\n**RESPONSIBILITIES**\r\n- Contributes to the plans associated with the software development of features. Executes the design, development, deployment, and operation of cloud-based services. Contributes to prioritization of new features versus technical debt resolution.\r\n- Holds themselves to high standards in writing quality scalable and supportable code, complete with appropriate unit tests, automated testing, documentation, and operationalization aspects in a CI/CD environment.\r\n- Seeks technical excellence in implementing new functionality and improvements to existing implementations\r\nInterface with user representatives or other engineering groups to define requirements and/or necessary modifications when required\r\n- Proactively collaborates with other teams resolve roadblocks and ensure a smooth delivery.\r\n\r\n**REQUIREMENTS**\r\n- 5+ years of professional software development experience\r\n- Proficiency with Java/JVM languages (Kotlin, Scala etc.)\r\n- Experience in building complex, highly scalable, performant, secure and reliable software systems\r\n- Experience in Cloud-native design, principles, and best practices\r\n- Exposure to AWS, GCP or Azure\r\n- Exposure to TDD and CI/CD processes\r\n- Sharp analytical abilities and proven design skills\r\n- Demonstrated ability to achieve stretch goals in a highly innovative and fast paced environment\r\n- Excellent verbal and written English\r\n\r\n**WILL BE A PLUS**\r\n- Proficiency with .NET/C#.\r\n- Strong knowledge of data structures, algorithms, distributed systems, and asynchronous architectures\r\n- Understanding of data modeling and database theory (ACID, CAP etc.)\r\n- Experience designing, creating, and securing APIs; Web Services (SOAP/XML, REST/JSON), OAuth, JWT/JWE/JWS, WS-Security, SAML\r\n- Bachelor‚Äôs or master‚Äôs degree in computer science",
         "Argument",
         "5y",
         "Java",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "6e732f79-f82a-5774-b0d6-dec36a943aef",
         "27501"
        ],
        [
         "41",
         "2004/30 Senior Software Development Engineer (Java)",
         "Software development - 5+ –ª–µ—Ç\r\n–û–ø—ã—Ç –≤ TDD\r\n–û–ø—ã—Ç –≤ .NET - –±—É–¥–µ—Ç –ø–ª—é—Å–æ–º\r\n\r\nABOUT THE PROJECT\r\nProject is a catalyst for your value-based healthcare system. It is a healthcare technology company that offers software, analytics, network solutions, and technology-enabled services to help create a stronger, more collaborative healthcare system. It helps deliver measurable value not only at the point of care, but also before, after, and in between care episodes.\r\n\r\nABOUT THE POSITION\r\nCompany is looking for a self-motivated and goal-oriented Software Development Engineer who would like to be a part of a team working on brand new startup projects for foreign customers.\r\n\r\n\r\nWE OFFER\r\n- People-oriented management without bureaucracy\r\n- Friendly climate inside the company ‚Äî previous employees have come back often\r\n- 100% paid sick leave\r\n- Paid participating in the sports events\r\n- Educational budget\r\n- Paid sick leave ‚Äî 9 days\r\n- Paid vacation ‚Äî 20 working days\r\n\r\nRESPONSIBILITIES\r\n- Contributes to the plans associated with the software development of features. Executes the design, development, deployment, and operation of cloud-based services. Contributes to prioritization of new features versus technical debt resolution.\r\n- Holds themselves to high standards in writing quality scalable and supportable code, complete with appropriate unit tests, automated testing, documentation, and operationalization aspects in a CI/CD environment.\r\n- Seeks technical excellence in implementing new functionality and improvements to existing implementations\r\nInterface with user representatives or other engineering groups to define requirements and/or necessary modifications when required\r\n- Proactively collaborates with other teams resolve roadblocks and ensure a smooth delivery.\r\n\r\n\r\nREQUIREMENTS\r\n- 5+ years of professional software development experience\r\n- Proficiency with Java/JVM languages (Kotlin, Scala etc.)\r\n- Experience in building complex, highly scalable, performant, secure and reliable software systems\r\n- Experience in Cloud-native design, principles, and best practices\r\n- Exposure to AWS, GCP or Azure\r\n- Exposure to TDD and CI/CD processes\r\n- Sharp analytical abilities and proven design skills\r\n- Demonstrated ability to achieve stretch goals in a highly innovative and fast paced environment\r\n- Excellent verbal and written English\r\n\r\nWILL BE A PLUS\r\n- Proficiency with .NET/C#.\r\n- Strong knowledge of data structures, algorithms, distributed systems, and asynchronous architectures\r\n- Understanding of data modeling and database theory (ACID, CAP etc.)\r\n- Experience designing, creating, and securing APIs; Web Services (SOAP/XML, REST/JSON), OAuth, JWT/JWE/JWS, WS-Security, SAML\r\n- Bachelor‚Äôs or master‚Äôs degree in computer science",
         "Argument",
         "5y",
         "Java",
         "upper",
         "2021-04-01T00:00:00+03:00",
         "en",
         "cc232fdb-4481-5e02-9caf-6a6406aa512d",
         "27502"
        ],
        [
         "42",
         "2004/35 Senior Java Developer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\r\nJava 8 - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Play 2.X\r\n–û–ø—ã—Ç –≤ Amazon AWS\r\n–û–ø—ã—Ç –≤ NoSQL\r\n–û–ø—ã—Ç –≤ Redis\r\n–û–ø—ã—Ç –≤ Agile\r\n–û–ø—ã—Ç –≤ MongoDB\r\n–û–ø—ã—Ç –≤ ElasticSearch\r\n–û–ø—ã—Ç –≤ Scrum\r\n\r\n**We offer**\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company\r\n- Flexible working hours\r\n- Paid to participate in the sports events\r\n- Educational budget\r\n\r\n**RESPONSIBILITIES**\r\n- Being part of the core development team of the product.\r\n- Creating the smart dialog between the end-user and the brand.\r\n- Many responsibilities beyond backend development, such as Dev-Ops with AWS cloud, and developing NLP technologies and sophisticated algorithms.\r\n\r\n**REQUIREMENTS**\r\n- 3+ years of experience developing in Java 8 and above\r\n- Strong experience developing high scale web services with frameworks such as Play 2.X\r\n- Experience with AWS cloud and micro-services.\r\n- Experience with NoSQL databases such as: ElasticSearch, MongoDB\r\n- Experience working with distributed cache such as: Redis\r\n- Experience with Agile scrum methodology\r\n- Being a team player\r\n\r\n**WILL BE A PLUS**\r\n- Experience with NLP technologies\r\n- Experience developing a skill for Alexa or Google Assistant action\r\n- Experience in the domain of chatbots",
         "Argument",
         "3y",
         "Java",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "cca4c5cd-8d55-5f05-aeb9-adebb15c10d0",
         "27503"
        ],
        [
         "43",
         "2004/37 Senior Back End Engineer (Python)",
         "ABOUT THE POSITION\r\nCompany is looking for a self-motivated and goal-oriented Senior Back End Engineer who would like to be a part of a team working on brand new startup projects for foreign customers.\r\n\r\nWe offer:\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company\r\n-Flexible working hours\r\n- Paid to participate in the sports events\r\n- Educational budget\r\n\r\nRESPONSIBILITIES\r\n- Build from scratch a complete back-end cloud-based infrastructure\r\n- The system is designed to handle very high QPS, generating terabytes of data daily\r\n- Responsible for building distributed services running on K8S that will serve our business needs\r\n- Working with the latest streaming and concurrency technologies to handle network-intensive workloads\r\n\r\nREQUIREMENTS\r\n- At least 3 years of experience working as a Backend engineer\r\n- Knowledge of Python\r\n- Experience with or willingness to learn Docker and K8S\r\n- A positive, ‚Äúcan do‚Äù attitude who isn‚Äôt afraid to lead the Backend efforts of a Startup\r\n- Experience in building Microservices and services clusters\r\n- Experience in building CI/CD pipelines\r\n- BA/B.Sc in Computer Science (or equivalent), or a veteran of a technological army unit\r\n- Excellent English skills\r\n- Experience in AWS/other cloud providers\r\n \r\n\r\nWILL BE A PLUS\r\n- Experience in containers, clusters orchestration\r\n- Experience in building high scale production environments / Ad Tech",
         "Argument",
         "3y",
         "Python",
         "upper",
         "2021-04-01T00:00:00+03:00",
         "en",
         "eb6b0be6-1311-5d44-94c2-8d5ff9abfbf7",
         "27504"
        ],
        [
         "44",
         "2004/37 Senior Back End Engineer (Python)",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\r\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: 3 –≥–æ–¥–∞\r\nBackend Engineer - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Python\r\n–û–ø—ã—Ç –≤ Docker\r\n–û–ø—ã—Ç –≤ CI/CD\r\n–û–ø—ã—Ç –≤ Amazon AWS\r\n\r\n**We offer:**\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company\r\n-Flexible working hours\r\n- Paid to participate in the sports events\r\n- Educational budget\r\n\r\n**RESPONSIBILITIES**\r\n- Build from scratch a complete back-end cloud-based infrastructure\r\n- The system is designed to handle very high QPS, generating terabytes of data daily\r\n- Responsible for building distributed services running on K8S that will serve our business needs\r\n- Working with the latest streaming and concurrency technologies to handle network-intensive workloads\r\n\r\n**REQUIREMENTS**\r\n- At least 3 years of experience working as a Backend engineer\r\n- Knowledge of Python\r\n- Experience with or willingness to learn Docker and K8S\r\n- A positive, ‚Äúcan do‚Äù attitude who isn‚Äôt afraid to lead the Backend efforts of a Startup\r\n- Experience in building Microservices and services clusters\r\n- Experience in building CI/CD pipelines\r\n- BA/B.Sc in Computer Science (or equivalent), or a veteran of a technological army unit\r\n- Excellent English skills\r\n- Experience in AWS/other cloud providers\r\n\r\n**WILL BE A PLUS**\r\n- Experience in containers, clusters orchestration\r\n- Experience in building high scale production environments / Ad Tech",
         "Argument",
         "3y",
         "Python",
         "upper",
         "2021-05-01T00:00:00+03:00",
         "en",
         "a7ad9686-b1dd-5093-a65f-e6ef1d739dca",
         "27505"
        ],
        [
         "45",
         "2004/38 Senior DevOps Engineer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\r\nDevOps - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Backend Engineer\r\n–û–ø—ã—Ç –≤ Kubernetes\r\n–û–ø—ã—Ç –≤ Node.js\r\n–û–ø—ã—Ç –≤ Golang\r\n–û–ø—ã—Ç –≤ Git - –±—É–¥–µ—Ç –ø–ª—é—Å–æ–º\r\n–û–ø—ã—Ç –≤ Blockchain - –±—É–¥–µ—Ç –ø–ª—é—Å–æ–º\r\n–ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –°—Ä–µ–¥–Ω–∏–π\r\n\r\n**We offer:**\r\n\r\n- People-oriented management without bureaucracy.\r\n- Friendly climate inside the company ‚Äì previous employees have come back often.\r\n- Flexible working hours.\r\n- 100% paid sick leave.\r\n- Paid participation in sports events.\r\n- Educational budget.\r\n\r\n**RESPONSIBILITIES**\r\n- Act as a key technical resource for ORIGYN and its clients, including top management, regarding security matters related to DevSecOps and secure development practices.\r\n- Lead, define and map digital architecture processes for designing large scale DevSecOps pipelines.\r\n- Coordinate DevOps security in order to assist IT teams in delivering secure infrastructure solutions with his/her security recommendations and requirements.\r\n- Work as part of a team using Agile development technology.\r\n\r\n**REQUIREMENTS**\r\n- 3+ years professional experience in a position of DevOps / Back-end engineer (Node.js)\r\n- Proven track record using Kubernetes and open-source technologies\r\n- Can write documentable code (Node.js, Golang, etc.)\r\n- English level ‚Äì Intermediate or higher\r\n\r\n**WILL BE A PLUS**\r\n- Bachelors‚Äô Degree in Computer Sciences or any related discipline\r\nTechnical IT certification\r\n- Security certification (CISSP and/or GIAC)\r\n- Blockchain experience\r\n- Git / Gitlab-CI\r\n- Hashicorp products (Terraform, Vault‚Ä¶)",
         "Argument",
         "3y",
         "DevOps",
         "intermediate",
         "2021-04-01T00:00:00+03:00",
         "en",
         "e19db489-2bb8-5763-8409-01c4fe68df40",
         "27506"
        ],
        [
         "46",
         "2004/45 Senior DevOps Engineer",
         "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**\r\nDevOps - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ SQL\r\n–û–ø—ã—Ç –≤ CI/CD\r\n–û–ø—ã—Ç –≤ Amazon AWS\r\n–û–ø—ã—Ç –≤ GCP\r\n–û–ø—ã—Ç –≤ Azure\r\n–û–ø—ã—Ç –≤ Linux\r\n–ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –°—Ä–µ–¥–Ω–∏–π\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- Friendly climate inside the company ‚Äì previous employees have come back often\r\n- Flexible working hours\r\n- 100% paid sick leave\r\n- Paid participating in the sports events\r\n- Educational budget\r\n\r\n**RESPONSIBILITIES**\r\n- Work directly with the DevOps team and Senior DevOps manager to test system integrity\r\n- Design and implement build, deployment, and configuration management Test implemented designs\r\n- Build and test automation tools for infrastructure provisioning\r\n- Handle code deployments in all environments\r\n- Monitor metrics and develop ways to improve\r\n- Brainstorm for new ideas and ways to improve development delivery\r\n- Consult with peers for feedback during testing stages\r\n- Build, maintain, and monitor configuration standards\r\n- Maintain day-to-day management and administration of projects\r\n- Manage Circle CI/CD platform\r\n- Document and design various processes; update existing processes\r\n- Improve infrastructure development and application development\r\n- Follow all best practices and procedures as established by the company\r\n\r\n**REQUIREMENTS**\r\n- High school degree or equivalent; bachelor‚Äôs degree in CS, engineering, software engineering, or related field\r\n- Minimum 2 years‚Äô previous experience in development and operations, or related IT, computer, or operations field\r\n- Previous experience with software development, infrastructure development, or development and operations\r\n- Experience with Linux infrastructures, database SQL (MS SQL), CI/CD tools, scripting in any language\r\n- Experience with AWS/GCP/Azure\r\n- Good interpersonal skills and communication with all levels of management\r\n- Intermediate English",
         "Argument",
         "2y",
         "DevOps",
         "intermediate",
         "2021-06-01T00:00:00+03:00",
         "en",
         "5297a7c7-6722-5684-8378-e6567dede5f8",
         "27507"
        ],
        [
         "47",
         "2004/51 SRE Developer",
         "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\r\nDevOps - 3 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ SSH\r\n–û–ø—ã—Ç –≤ Linux\r\n\r\n\r\nProject is a catalyst for your value-based healthcare system. It is a healthcare technology company that offers software, analytics, network solutions, and technology-enabled services to help create a stronger, more collaborative healthcare system. It helps deliver measurable value not only at the point of care, but also before, after, and in between care episodes. \r\nCompany is looking for a self-motivated and goal-oriented SRE Developer.\r\n\r\nAs an automated engineer in the Site Reliability Engineering (SRE) team, you will help automate processes to help the team in ensuring reliability, security, and efficiency. \r\n\r\nThis an opportunity to be instrumental in our evolution into a cloud SaaS solution with a rapidly growing customer base.\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company which is confirmed by the frequent come back of previous employees\r\n- Flexible working schedule\r\n- Paid time off (20 working days per year, plus all national holidays and 9 sick days)\r\n- Laptop of your choice: MacBook Pro or Windows/Linux business laptop + large extra screen\r\n- Full financial and legal support for private entrepreneurs\r\n- Education compensation\r\n- Free English classes with native speakers or with Ukrainian teachers (for your choice)\r\n- Dedicated HR\r\n- Comfortable offices in the city center (pets friendly btw:) )\r\n- Possibility to choose your workspace either remote or combination of your home and one of our development offices/possibility of rotation between offices (Kyiv, Kharkiv)\r\n- We help with relocation. If you‚Äôd like to move to Kyiv or Kharkiv, we‚Äôll try our best to make your relocation smooth and effortless\r\n- Sign-on bonus 1000$\r\n- Last but not least - regular team buildings and corporate events\r\n\r\n**RESPONSIBILITIES**\r\n- Responsibilities include production deployments, monitoring, ensuring SLAs are met, and incident response management. In addition, we try to improve our operations via software development by building automation for otherwise manual work\r\n- Automation: Software development/scripting to automate manual tasks such as monitoring app for performance and compliance, infrastructure deployments, and alerting\r\n- Operations: Sometimes involved in operation work like system admin tasks, BC/DR backups, firewall/network changes, monitoring app, and infrastructure\r\n\r\n**REQUIREMENTS**\r\n- Bachelor's degree in Information Systems, Computer Science, Engineering or related field or equivalent experience\r\n- 2+ years of DevOps/SRE/Cloud Infrastructure experience or equivalent experience in mainstream software development\r\n- 2+ years of experience in programming/scripting\r\n- Excellent communicator (both verbal and written English skills). The role requires interaction with many teams\r\n- Solid foundation in OS scripting & administration experience: Linux (bash, SSH etc) & Windows (PowerShell)\r\n\r\n**WILL BE A PLUS**\r\n(The bold items are preferred)\r\n\r\n- Good programming skills (e.g., Git, Python, Bash, Powershell)\r\n- Strong knowledge of cloud infrastructure including compute, networking, storage, and other cloud services e.g. (GCP, AWS, Azure)\r\n- Strong knowledge of software fundamentals like web traffic (HTTP, TCP, REST), Networking, VPNs, Certs, LoadBalancers, etc\r\n- Infrastructure as code (e.g., Terraform, Ansible, Chef, Puppet)\r\n- Experienced in containerization technologies (e.g., Docker, GKE/Kubernetes, EKS, Rancher)\r\n- Setup and use of monitoring frameworks (e.g., Stackdriver, Influx DB/TICK, grafana, ELK, Prometheus, Splunk, Nagios, NewRelic, Dynatrace, etc)\r\n- Able and willing to work in a fast-paced, quickly changing environment",
         "Argument",
         "3y",
         "Python",
         "intermediate",
         "2021-06-01T00:00:00+03:00",
         "en",
         "64a99699-7245-548a-a3ad-7d32b787d84e",
         "27508"
        ],
        [
         "48",
         "2004/52 Senior Full Stack Developer",
         "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\r\n–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: 5+ –ª–µ—Ç\r\nAngular - 5+ –ª–µ—Ç\r\n–û–ø—ã—Ç –≤ Python\r\n–û–ø—ã—Ç –≤ JavaScript\r\n–ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ\r\n\r\n**ABOUT THE PROJECT**\r\nProject is a well-funded startup in a double-digit growth space. We offer a cutting-edge Autonomous Training Platform that increases corporate cybersecurity resilience. Founded in Israel four years ago project is experiencing expeditious growth in Europe We value hard work, and we value family life even more. This means remote and on-premises work to support work life balance.\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company which is confirmed by the frequent come back of previous employees\r\n- Flexible working schedule\r\n- Paid time off (18 working days per year, plus all national holidays and 9 sick days)\r\n- Laptop of your choice: MacBook Pro or Windows/Linux business laptop + large extra screen\r\n- Full financial and legal support for private entrepreneurs\r\n- Education compensation\r\n- Free English classes with native speakers or with Ukrainian teachers (for your choice)\r\n- Dedicated HR\r\n- Comfortable offices in the city center (pets friendly btw:) )\r\n- Possibility to choose your workspace either remote or combination of your home and one of our development offices/possibility of rotation between offices (Kyiv, Kharkiv)\r\n- We help with relocation. If you‚Äôd like to move to Kyiv or Kharkiv, we‚Äôll try our best to make your relocation smooth and effortless\r\n- Last but not least - regular team buildings and corporate events\r\n\r\n**RESPONSIBILITIES**\r\n- Develop new apps for internal and external use\r\n- Create serverless projects\r\n- Contribute to many products whether it‚Äôs frontend/backend/serverless\r\n- Take part in designing features and code reviews\r\n- Take part in development tasks outside of your comfort zone\r\n\r\n**REQUIREMENTS**\r\n- At least 5 years‚Äô experience in developing apps in both frontend and backend\r\n- Experience in Python/Django - must\r\nExperience in:\r\n¬∑ Angular - advantage\r\n¬∑ Modern JS, CSS, and HTML\r\n¬∑ Cloud computing - AWS advantage\r\n¬∑ Serverless technology/framework - big advantage\r\n- Great understanding about web-flow from frontend to backend \r\n- Knowledge and actual experience in unit, integration and e2e tests\r\n- English level ‚Äì upper-intermediate, good speaking and writing",
         "Argument",
         "5y",
         "Python",
         "upper",
         "2021-06-01T00:00:00+03:00",
         "en",
         "2003e579-d1a2-5882-9afd-f70192711bc1",
         "27509"
        ],
        [
         "49",
         "2004/53 Full Stack Developer",
         "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\r\nPython - 2 –≥–æ–¥–∞\r\n–û–ø—ã—Ç –≤ Node.js\r\n–ê–Ω–≥–ª–∏–π—Å–∫–∏–π - –°—Ä–µ–¥–Ω–∏–π\r\n\r\nProject is developing the next generation of application log alerting for Cybersecurity. Helping organizations reduce the risk and prevent damage is what project is all about, bringing the industry‚Äôs most robust insider threat protection there is. We have just started developing our cloud offering and looking for team members that are looking to work in a creative environment.\r\n\r\n**WE OFFER**\r\n- People-oriented management without bureaucracy\r\n- The friendly climate inside the company which is confirmed by the frequent come back of previous employees\r\n- Flexible working schedule\r\n- Paid time off (18 working days per year, plus all national holidays and 9 sick days)\r\n- Laptop of your choice: MacBook Pro or Windows/Linux business laptop + large extra screen\r\n- Full financial and legal support for private entrepreneurs\r\n- Education compensation\r\n- Free English classes with native speakers or with Ukrainian teachers (for your choice)\r\n- Dedicated HR\r\n- Comfortable offices in the city center (pets friendly btw:) )\r\n- Possibility to choose your workspace either remote or combination of your home and one of our development offices/possibility of rotation between offices (Kyiv, Kharkiv)\r\n- We help with relocation. If you‚Äôd like to move to Kyiv or Kharkiv, we‚Äôll try our best to make your relocation smooth and effortless\r\n- Last but not least - regular team buildings and corporate event\r\n\r\n**RESPONSIBILITIES**\r\n- Add features to our legacy and new product\r\n- Make sure that the system scale for both cloud and on-prem installations\r\n- Be involved in shaping the requirements of the features and make sure the code fits those requirements\r\n\r\n**REQUIREMENTS**\r\n- 2+ years in development for enterprise products\r\n- Experience in Python.\r\n- Experience in Node.JS\r\n- Experience in web development.\r\n- Highly knowledgeable in Linux and Bash\r\n- Science or engineering degree\r\n- English level ‚Äì at least intermediate, good speaking and writing",
         "Argument",
         "2y",
         "Python",
         "intermediate",
         "2021-06-01T00:00:00+03:00",
         "en",
         "93224c9a-8b8b-5973-a8b2-40ddd264c47e",
         "27510"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 141897
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Long Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Exp Years</th>\n",
       "      <th>Primary Keyword</th>\n",
       "      <th>English Level</th>\n",
       "      <th>Published</th>\n",
       "      <th>Long Description_lang</th>\n",
       "      <th>id</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 + Blockchain Nodes / Masternodes to set up</td>\n",
       "      <td>*Requirements*\\r\\n\\r\\nWe're looking for a long...</td>\n",
       "      <td>MyCointainer</td>\n",
       "      <td>2y</td>\n",
       "      <td>Sysadmin</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2020-10-01T00:00:00+03:00</td>\n",
       "      <td>en</td>\n",
       "      <td>c0ca96e7-85df-50df-a64e-d934cd02a170</td>\n",
       "      <td>27461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 .NET Developers (Middle and Senior level)</td>\n",
       "      <td>Greetings! My name is Maria, I am in urgent ne...</td>\n",
       "      <td>TechScout.tech</td>\n",
       "      <td>2y</td>\n",
       "      <td>.NET</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2022-03-01T00:00:00+02:00</td>\n",
       "      <td>en</td>\n",
       "      <td>64f4b7ea-36e4-5bdd-a8b1-185f32f7dc7f</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10X Engineer (co-founder, #4 employee, USD 11-...</td>\n",
       "      <td>**Product**\\r\\nThe product is a live video cha...</td>\n",
       "      <td>Innoteka</td>\n",
       "      <td>5y</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>fluent</td>\n",
       "      <td>2021-07-01T00:00:00+03:00</td>\n",
       "      <td>en</td>\n",
       "      <td>b9a1303e-dd0c-5ed1-8f62-be2bc4c7da4f</td>\n",
       "      <td>27463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16 - Amazon Brand Manager</td>\n",
       "      <td>Currently, TCM expanding its activities to Ukr...</td>\n",
       "      <td>FirstFive</td>\n",
       "      <td>2y</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>upper</td>\n",
       "      <td>2022-01-01T00:00:00+02:00</td>\n",
       "      <td>en</td>\n",
       "      <td>99cb3f4a-9b4b-53d9-9a3b-bab2c22da346</td>\n",
       "      <td>27464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 - Amazon Brand Manager</td>\n",
       "      <td>Hello,\\r\\nWe, MIMIRB2B, are an outstaff compan...</td>\n",
       "      <td>MimirB2B</td>\n",
       "      <td>1y</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>upper</td>\n",
       "      <td>2021-12-01T00:00:00+02:00</td>\n",
       "      <td>en</td>\n",
       "      <td>bc1419f7-28e2-582b-8d53-22e28b2f0210</td>\n",
       "      <td>27465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141892</th>\n",
       "      <td>–¢–∞—Ä–≥–µ—Ç–æ–ª–æ–≥</td>\n",
       "      <td>We are looking for a highly motivated and resu...</td>\n",
       "      <td>4Service</td>\n",
       "      <td>1y</td>\n",
       "      <td>SEO</td>\n",
       "      <td>upper</td>\n",
       "      <td>2023-09-01T00:00:00+03:00</td>\n",
       "      <td>en</td>\n",
       "      <td>78a67302-f559-507d-80e4-209c739cf730</td>\n",
       "      <td>169353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141893</th>\n",
       "      <td>–¢–∞—Ä–≥–µ—Ç–æ–ª–æ–≥</td>\n",
       "      <td>We are looking for an experienced targetologis...</td>\n",
       "      <td>ROCKETECH</td>\n",
       "      <td>3y</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2022-11-01T00:00:00+02:00</td>\n",
       "      <td>en</td>\n",
       "      <td>246364be-ac7b-59b3-bdf2-fa7e6c10a9f0</td>\n",
       "      <td>169354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141894</th>\n",
       "      <td>–¢–µ–∞m Lead React</td>\n",
       "      <td>Responsibilities\\r\\n    ‚Ä¢ Analyze and estimate...</td>\n",
       "      <td>AboutHR</td>\n",
       "      <td>3y</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>upper</td>\n",
       "      <td>2021-10-01T00:00:00+03:00</td>\n",
       "      <td>en</td>\n",
       "      <td>988b0bf4-3ebe-5b81-88d0-ab144c2d8781</td>\n",
       "      <td>169355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141895</th>\n",
       "      <td>–¢–µ—Å—Ç—É–≤–∞–ª—å–Ω–∏–∫</td>\n",
       "      <td>Duties and Responsibilities\\r\\n‚óè HelpdDeliver ...</td>\n",
       "      <td>Flawless</td>\n",
       "      <td>3y</td>\n",
       "      <td>QA</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2022-11-01T00:00:00+02:00</td>\n",
       "      <td>en</td>\n",
       "      <td>9e18fa91-1d16-5875-80c0-b5c2f2a88e3b</td>\n",
       "      <td>169356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141896</th>\n",
       "      <td>–•–º–∞—Ä–Ω–∏–π –∞—Ä—Ö—ñ—Ç–µ–∫—Ç–æ—Ä DevOps / DevOps Cloud Archi...</td>\n",
       "      <td>We are looking for a talented and brilliant  D...</td>\n",
       "      <td>Tango Me</td>\n",
       "      <td>5y</td>\n",
       "      <td>DevOps</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2022-10-01T00:00:00+03:00</td>\n",
       "      <td>en</td>\n",
       "      <td>684759df-c87b-58a9-9d02-007be095d1da</td>\n",
       "      <td>169357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141897 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Position  \\\n",
       "0           10 + Blockchain Nodes / Masternodes to set up   \n",
       "1            10 .NET Developers (Middle and Senior level)   \n",
       "2       10X Engineer (co-founder, #4 employee, USD 11-...   \n",
       "3                               16 - Amazon Brand Manager   \n",
       "4                               16 - Amazon Brand Manager   \n",
       "...                                                   ...   \n",
       "141892                                         –¢–∞—Ä–≥–µ—Ç–æ–ª–æ–≥   \n",
       "141893                                         –¢–∞—Ä–≥–µ—Ç–æ–ª–æ–≥   \n",
       "141894                                    –¢–µ–∞m Lead React   \n",
       "141895                                       –¢–µ—Å—Ç—É–≤–∞–ª—å–Ω–∏–∫   \n",
       "141896  –•–º–∞—Ä–Ω–∏–π –∞—Ä—Ö—ñ—Ç–µ–∫—Ç–æ—Ä DevOps / DevOps Cloud Archi...   \n",
       "\n",
       "                                         Long Description    Company Name  \\\n",
       "0       *Requirements*\\r\\n\\r\\nWe're looking for a long...    MyCointainer   \n",
       "1       Greetings! My name is Maria, I am in urgent ne...  TechScout.tech   \n",
       "2       **Product**\\r\\nThe product is a live video cha...        Innoteka   \n",
       "3       Currently, TCM expanding its activities to Ukr...       FirstFive   \n",
       "4       Hello,\\r\\nWe, MIMIRB2B, are an outstaff compan...        MimirB2B   \n",
       "...                                                   ...             ...   \n",
       "141892  We are looking for a highly motivated and resu...        4Service   \n",
       "141893  We are looking for an experienced targetologis...       ROCKETECH   \n",
       "141894  Responsibilities\\r\\n    ‚Ä¢ Analyze and estimate...         AboutHR   \n",
       "141895  Duties and Responsibilities\\r\\n‚óè HelpdDeliver ...        Flawless   \n",
       "141896  We are looking for a talented and brilliant  D...        Tango Me   \n",
       "\n",
       "       Exp Years Primary Keyword English Level                  Published  \\\n",
       "0             2y        Sysadmin  intermediate  2020-10-01T00:00:00+03:00   \n",
       "1             2y            .NET  intermediate  2022-03-01T00:00:00+02:00   \n",
       "2             5y      JavaScript        fluent  2021-07-01T00:00:00+03:00   \n",
       "3             2y       Marketing         upper  2022-01-01T00:00:00+02:00   \n",
       "4             1y       Marketing         upper  2021-12-01T00:00:00+02:00   \n",
       "...          ...             ...           ...                        ...   \n",
       "141892        1y             SEO         upper  2023-09-01T00:00:00+03:00   \n",
       "141893        3y       Marketing  intermediate  2022-11-01T00:00:00+02:00   \n",
       "141894        3y      JavaScript         upper  2021-10-01T00:00:00+03:00   \n",
       "141895        3y              QA  intermediate  2022-11-01T00:00:00+02:00   \n",
       "141896        5y          DevOps  intermediate  2022-10-01T00:00:00+03:00   \n",
       "\n",
       "       Long Description_lang                                    id  \\\n",
       "0                         en  c0ca96e7-85df-50df-a64e-d934cd02a170   \n",
       "1                         en  64f4b7ea-36e4-5bdd-a8b1-185f32f7dc7f   \n",
       "2                         en  b9a1303e-dd0c-5ed1-8f62-be2bc4c7da4f   \n",
       "3                         en  99cb3f4a-9b4b-53d9-9a3b-bab2c22da346   \n",
       "4                         en  bc1419f7-28e2-582b-8d53-22e28b2f0210   \n",
       "...                      ...                                   ...   \n",
       "141892                    en  78a67302-f559-507d-80e4-209c739cf730   \n",
       "141893                    en  246364be-ac7b-59b3-bdf2-fa7e6c10a9f0   \n",
       "141894                    en  988b0bf4-3ebe-5b81-88d0-ab144c2d8781   \n",
       "141895                    en  9e18fa91-1d16-5875-80c0-b5c2f2a88e3b   \n",
       "141896                    en  684759df-c87b-58a9-9d02-007be095d1da   \n",
       "\n",
       "        __index_level_0__  \n",
       "0                   27461  \n",
       "1                   27462  \n",
       "2                   27463  \n",
       "3                   27464  \n",
       "4                   27465  \n",
       "...                   ...  \n",
       "141892             169353  \n",
       "141893             169354  \n",
       "141894             169355  \n",
       "141895             169356  \n",
       "141896             169357  \n",
       "\n",
       "[141897 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4e383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6a5a28fe-b4c7-40e8-96c9-ed7ff5c457c5",
       "rows": [
        [
         "DevOps Engineer",
         "1587"
        ],
        [
         "Business Analyst",
         "1109"
        ],
        [
         "Project Manager",
         "1066"
        ],
        [
         "Java Developer",
         "796"
        ],
        [
         "Senior Java Developer",
         "673"
        ],
        [
         "IT Recruiter",
         "630"
        ],
        [
         "QA Engineer",
         "628"
        ],
        [
         "Senior DevOps Engineer",
         "600"
        ],
        [
         "Manual QA Engineer",
         "552"
        ],
        [
         "Data Engineer",
         "532"
        ],
        [
         "Android Developer",
         "486"
        ],
        [
         "Python Developer",
         "462"
        ],
        [
         "DevOps",
         "445"
        ],
        [
         "Frontend Developer",
         "369"
        ],
        [
         "PHP Developer",
         "359"
        ],
        [
         "Sales Manager",
         "345"
        ],
        [
         "Product Manager",
         "340"
        ],
        [
         "Senior Python Developer",
         "339"
        ],
        [
         "Automation QA Engineer",
         "331"
        ],
        [
         "QA Automation Engineer",
         "329"
        ],
        [
         "iOS Developer",
         "327"
        ],
        [
         "Middle Java Developer",
         "326"
        ],
        [
         "Business Development Manager",
         "320"
        ],
        [
         "UIUX Designer",
         "308"
        ],
        [
         "Middle QA Engineer",
         "303"
        ],
        [
         "React Native Developer",
         "300"
        ],
        [
         "Full Stack Developer",
         "294"
        ],
        [
         "Data Analyst",
         "290"
        ],
        [
         "Angular Developer",
         "286"
        ],
        [
         "Scrum Master",
         "262"
        ],
        [
         "Data Scientist",
         "254"
        ],
        [
         "Product Owner",
         "254"
        ],
        [
         "Lead Generation Specialist",
         "249"
        ],
        [
         "Nodejs Developer",
         "248"
        ],
        [
         "C Developer",
         "233"
        ],
        [
         "Recruiter",
         "232"
        ],
        [
         "Copywriter",
         "232"
        ],
        [
         "Technical Writer",
         "229"
        ],
        [
         "Marketing Manager",
         "225"
        ],
        [
         "Lead Generation Manager",
         "224"
        ],
        [
         "Senior Data Engineer",
         "224"
        ],
        [
         "Senior Business Analyst",
         "221"
        ],
        [
         "Junior QA Engineer",
         "220"
        ],
        [
         "Account Manager",
         "218"
        ],
        [
         "Java developer",
         "217"
        ],
        [
         "Middle Python Developer",
         "217"
        ],
        [
         "Middle DevOps Engineer",
         "212"
        ],
        [
         "Golang Developer",
         "209"
        ],
        [
         "Flutter Developer",
         "209"
        ],
        [
         "Senior PHP Developer",
         "202"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 66467
       }
      },
      "text/plain": [
       "Position\n",
       "DevOps Engineer                 1587\n",
       "Business Analyst                1109\n",
       "Project Manager                 1066\n",
       "Java Developer                   796\n",
       "Senior Java Developer            673\n",
       "                                ... \n",
       "TO                                 1\n",
       "TO for outsourcing company         1\n",
       "TO Team Lead Unity Developer       1\n",
       "TOTech Lead NET                    1\n",
       "ustomer Care Manager Support       1\n",
       "Name: count, Length: 66467, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Position\"].value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e306f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Position', 'Long Description'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6044fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[ 'Company Name', 'Exp Years',\n",
    "       'Primary Keyword', 'English Level', 'Published',\n",
    "       'Long Description_lang', 'id', '__index_level_0__', 'Position_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9468ac2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*Requirements*\\r\\n\\r\\nWe're looking for a long term collaboration with someone that has an experience in crypto, masternodes, nodes, validators etc. We need to set up:\\r\\n\\r\\nKyber Network\\r\\nNebulas\\r\\nSecretNetwork\\r\\nTron\\r\\nAion\\r\\nDeFiChain\\r\\nEOS\\r\\nTomoChain\\r\\nElrond\\r\\nIRISnet\\r\\nIoTeX\\r\\nTerra\\r\\nChainX\\r\\nThorchain\\r\\n\\r\\nSuccesful candidates will have an opportunity to get more jobs and long term collaboration.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Long Description\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ece3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df[\"Position\"].isin([\"DevOps Engineer\",\"Project Manager\",\"IT Recruiter\",\"QA Engineer\",\"Data Engineer\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892d620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Position",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Long Description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "96048c35-2884-4cc0-8543-62167c515b08",
       "rows": [
        [
         "20533",
         "Data Engineer",
         "1. Project description\r\nClient is in the process of a data lake implementation in AWS after spending 18 months using GCP Big Query as the main data platform.\r\n2. Client description\r\nThe client helps everyone pet parent like a pro. Pets make us better humans ‚Äì people who care. We envision a world where everyone cares. So, we use data, tech, and compassion to help everyone bring the best care to their pets.\r\n3. Details on tech stack\r\nAWS\r\nLambdas\r\nRedshift\r\nPython\r\nSpark\r\nPostgres\r\nStepFunctions\r\nEMR clusters\r\nTerraform\r\n4. Min requirements to the candidate\r\nHands-on experience with AWS cloud platform required\r\nExperience using terraform lake formation\r\nCan describe experiences working with AWS Console\r\nDemonstrated examples of building Lambdas for 3rd party data sources, enabling CDC and ingesting RDS/postgres data sources, implementing Glue Crawler, creating JSON parsers, etc."
        ],
        [
         "20534",
         "Data Engineer",
         "**8allocate** is a global provider of end-to-end custom software development solutions to companies all over the globe, from North America to the EU to Israel to Australia.\r\n\r\nHeadquartered in Estonia, we run offshore R&D centers in Kyiv and Lviv. Our team is 50% remote and distributed. We specialize in flexible interaction exclusively with international clients (we cover industries from commercial aviation to fintech) thanks to a multinational support group of experts and management.\r\n\r\nCurrently, we are looking for a **Data Engineer** for an Adtech-related project.\r\n\r\n**About the project:** a market leader in developing Competitive Intelligence for AdTech Search.\r\nApplication teams develop unparalleled technologies that help our clients understand their paid and organic search landscape and improve campaign performance.\r\n\r\nAs a Data Engineer, you will be working across our entire stack, so a real passion to drive the product and technology forward is something that we value. Your responsibilities will include helping with a vision for the future architecture of this complex data system, adding innovative ideas that use the latest cutting edge technology. You will work closely with Web and Data Science teams to deliver user-centric solutions to our customers and become an expert in developing high quality technical solutions.\r\n\r\n**The stack of a project:**\r\nLanguages: Java, Scala, JavaScript (React, Backbone), SQL and scripting using Bash and Python\r\nFrameworks: DropWizard, React, Akka and Play Framework (Scala)\r\nDatabases: PostgreSQL, AWS(S3), Redshift, Redis, MongoDB, Cassandra\r\nTechnologies: RabbitMQ (messaging), Quartz scheduling, Docker and Kubernetes, Maven\r\nCI/CD: TeamCity, Jenkins\r\nSource Control: Git (GitHub)\r\nOther Tools: IntelliJ IDEA, Jira, Grafana\r\n                                                                                                                                                                                       \r\n**Main responsibilities and activities:**\r\nBuild services/features/libraries that serve as a definitive examples for new engineers and makes major contributions to library code or core services\r\nDesign low risk Spark process and write effective complex Spark jobs (data processes, aggregations, pipeline)\r\nDesign low risk APIs and write complex asynchronous, highly parallel low latency APIs and processes\r\nWork as part of Agile team to maintain, improve, monitor Adthena's data collection processes using Java and Scala\r\nWrite high quality, extensible and testable code by applying good engineering practices (TDD, SOLID) using.\r\nUnderstand and apply modern technologies, data structures and design patterns to solve real problems efficiently\r\nSupport TA and Data Science team to help deliver and productionise their backlog/prototypes\r\nTake ownership and pride in the products we build and always make sure they are of the highest standard\r\nBe empathetic towards team members and customers\r\n\r\n**You will fit if you:**\r\nCommercial experience developing Spark Jobs using Scala\r\nCommercial experience using Java and Scala (Python nice to have)\r\nExperience in data processing using traditional and distributed systems (Hadoop, Spark, AWS - S3)\r\nExperience designing data models and data warehouses.\r\nExperience in SQL, NoSQL database management systems (PostgreSQL and Cassandra)\r\nCommercial experience using messaging technologies (RabbitMQ, Kafka)\r\nExperience using orchestration software (Chef, Puppet, Ansible, Salt)\r\nConfident with building complex ETL workflows (Luigi, Airflow)\r\nGood knowledge working cloud technologies (AWS)\r\nGood knowledge using monitoring software (ELK stack)\r\nMotivated problem-solving skills, ability to bring ideas forward and adapt solutions to complex challenges\r\n\r\n**Why choose us?**\r\n‚ÄúFamily and Friends‚Äù. We are no longer a start-up, but still, have a family atmosphere in our supportive and spirited team, who are all working together on the same goal.\r\n‚ÄúJust break down all barriers and find a better way‚Äù. Every day you‚Äôll meet with interesting and challenging (international) projects that are covering industries from commercial aviation to fintech (different technologies, different products).\r\n‚ÄúHungry for learning‚Äù. You will get a lot of chances for career advancement and the development of new skills, opportunities for mentorship, or learning from more experienced colleagues.\r\n\r\n**Benefits from 8allocate:**\r\nCorporate events, holidays and team buildings for your joy.\r\nTraining and development: we have a huge library (about 500 books!) and a budget for your professional development.\r\nPeople-oriented management without bureaucracy.\r\nPaid vacation and sick leaves.\r\nRelocation program: if you are from another city and want to move to Kyiv, we will be happy to help you."
        ],
        [
         "20535",
         "Data Engineer",
         "8allocate is a global provider of end-to-end custom software development solutions to companies all over the globe, from North America to the EU to Israel to Australia.\r\n\r\nHeadquartered in Estonia, we run offshore R&D centers in Kyiv and Lviv. Our team is 50% remote and distributed. We specialize in flexible interaction exclusively with international clients (we cover industries from commercial aviation to fintech) thanks to a multinational support group of experts and management.\r\n\r\n \r\nProject: the leading fashion and lifestyle retail destination.\r\nData never stops growing and the team also never stops learning, innovating and expanding so that we can bring in or build the latest and best tools and technologies. In this role, you will be able to create strategic data models, develop and maintain data architecture used to power high-impact business initiatives that contribute to the overall growth and strategy for us.\r\n\r\nWhat responsibilities & tasks will wait for you?\r\n‚Äî Work daily to scale machine learning problems. For this purpose, you are expected to be involved in the process of collecting, storing, processing, and analyzing data generated from our database, in addition to joining our data scientists in the design of machine learning models.\r\n‚Äî Work in a diverse, international setting with teammates who are experts in various topics. We often conduct workshops to improve our individual skill sets, and to improve our workflow as a team.\r\n\r\nWhat skills/qualities are required:\r\nBachelor or Master degree in Computer Science or a related technical discipline\r\nBe familiar with:\r\n‚Äî Data structures & algorithms\r\n‚Äî Data modelling\r\n‚Äî Basic machine learning algorithms\r\n‚Äî Following languages: SQL, Python, R, Java/Scala\r\n‚Äî Any of the following databases: MySQL, PostgreSQL, MongoDB, HBase, Cassandra, Redshift\r\n‚Äî Cloud technologies: AWS, GCP (BigQuery)\r\nBe knowledgeable in:\r\n‚Äî Object oriented design and design patterns\r\n‚Äî Large-scale distributed systems\r\n‚Äî Hadoop, Spark and Pandas or similar processing engines\r\n‚Äî Jupyter Notebook or Zeppelin\r\n‚Äî Apache Airflow, Apache Superset\r\n\r\nWill be a plus:\r\n‚Äî Knowledge of data visualization\r\n‚Äî Good background in statistics\r\n‚Äî Knowledge in data analysis, data mining, or machine learning\r\n‚Äî Experience working with big data\r\n\r\nWork Schedule:\r\nYou can work from 9 am till 6 pm or from 10 am till 7 pm.\r\n\r\nWhy choose us?\r\n‚Äî ‚ÄúFamily and Friends‚Äù. We are no longer a start-up, but still, have a family atmosphere in our supportive and spirited team, who are all working together on the same goal.\r\n‚Äî ‚ÄúJust break down all barriers and find a better way‚Äù. Every day you‚Äôll meet with interesting and challenging (international) projects that are covering industries from commercial aviation to fintech (different technologies, different products).\r\n‚Äî ‚ÄúHungry for learning‚Äù. You will get a lot of chances for career advancement and the development of new skills, opportunities for mentorship, or learning from more experienced colleagues.\r\n\r\nBenefits from 8allocate:\r\n‚Äî You‚Äôll work in a supportive and spirited team of professionals.\r\n‚Äî Corporate events, holidays and team buildings for your joy.\r\n‚Äî Training and development: we have a huge library (about 500 books!) and a budget for your professional development.\r\n‚Äî People-oriented management without bureaucracy.\r\n‚Äî Paid vacation and sick leaves.\r\n‚Äî Relocation program: if you are from another city and want to move to Kyiv, we will be happy to help you!\r\n\r\n–ü—Ä–æ –∫–æ–º–ø–∞–Ω—ñ—é 8allocate:\r\n8allocate is a provider of software development solutions to companies all over the globe, from North America to the EU. We deliver market-ready solutions for FinTech/InsurTech, eCommerce, AI, Web, Mobile, and other domains."
        ],
        [
         "20536",
         "Data Engineer",
         "**8allocate** is a global provider of end-to-end custom software development solutions to companies all over the globe, from North America to the EU to Israel to Australia.\r\n\r\nHeadquartered in Estonia, we run offshore Research and Developments\r\ncenters in Kyiv and Lviv. Our team is 50% remote and distributed. We specialize in flexible interaction exclusively with international clients (we cover industries from commercial aviation to fintech) thanks to a multinational support group of experts and management.\r\n\r\nCurrently, we are looking for a **Data Engineer**.\r\n\r\n**Project:** Our client is not only created gComm ‚Äì the first-ever purchasing platform that lets gamers buy physical products directly inside mobile games ‚Äì but also pioneered a brand new market category: Gaming Commerce. \r\n\r\nAs a Gen-Z-focused B2B2C company embraces social commerce and anticipates the evolution of mobile games into a new form of social media, with gComm facilitating an effortless shopping experience coupled with uninterrupted gameplay. gComm‚Äôs 3-fold advantage gives DTC brands direct access to their Gen-Z gamer audience, allows game publishers to increase retention rates and monetize content in brand new ways, and lets gamers enjoy an elevated gaming experience.\r\n\r\n**What responsibilities and tasks will wait for you?**\r\nYou will be responsible for designing and developing our data pipeline architecture which collects, processes, streams, and analyzes very large amounts of data. Building the infrastructure will require optimal extraction, transformation, and loading of data from a wide variety of data sources. As part of making the data easily accessible, you will build analytics tools that will utilize the data platform to provide actionable insights and BI.\r\n\r\n**What skills/qualities are required:**\r\n‚Äî At least 2 years of experience working as a Data engineer.\r\n‚Äî Knowledge and experience of SQL, experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\r\n‚Äî A positive, ‚Äúcan do‚Äù attitude who isn‚Äôt afraid to lead the Data management efforts of a Startup.\r\n‚Äî Experience building and optimizing ‚Äòbig data‚Äô data pipelines, architectures, and data sets.\r\n‚Äî Build processes supporting data transformation, data structures, metadata, dependency, and workload management.\r\n‚Äî BA/B.Sc in Computer Science (or equivalent), or a veteran of a technological army unit.\r\n‚Äî Excellent English skills.\r\n‚Äî Strong project management and organizational skills.\r\n‚Äî Experience with big data tools: Hadoop, Spark, Kafka, Kinesis etc.\r\n‚Äî Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.\r\n‚Äî Experience with AWS cloud services: EC2, EMR, RDS, Redshift.\r\n‚Äî Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.\r\n\r\n**Why choose us?**\r\n‚Äî ‚ÄúFamily and Friends‚Äù. We are no longer a start-up, but still, have a family atmosphere in our supportive and spirited team, who are all working together on the same goal.\r\n‚Äî ‚ÄúJust break down all barriers and find a better way‚Äù. Every day you‚Äôll meet with interesting and challenging (international) projects that are covering industries from commercial aviation to fintech (different technologies, different products).\r\n‚Äî ‚ÄúHungry for learning‚Äù. You will get a lot of chances for career advancement and the development of new skills, opportunities for mentorship, or learning from more experienced colleagues.\r\n\r\n**Benefits from 8allocate:**\r\n‚Äî You‚Äôll work in a supportive and spirited team of professionals.\r\n‚Äî Corporate events, holidays, and team buildings for your joy.\r\n‚Äî Training and development: we have a huge library (about 500 books!) and a budget for your professional development.\r\n‚Äî English classes.\r\n‚Äî –°overage of sports activities.\r\n‚Äî People-oriented management without bureaucracy.\r\n‚Äî Paid vacation and sick leaves.\r\n‚Äî Relocation program: if you are from another city and want to move to Kyiv, we will be happy to help you!"
        ],
        [
         "20537",
         "Data Engineer",
         "**About Datassential**\r\n\r\nDatassential is a leading market research firm for the food industry, combining research with expert insights from a team of creative, inquisitive problem-solvers and food lovers. Datassential is a full-service firm offering both syndicated and custom research solutions to a number of Fortune 500 clients. Datassential also has the largest and most accurate menu database in the marketplace today. The company head office is in Chicago, State of Illinois.\r\n\r\n**Desired skills:**\r\n- 2+ years of experience\r\n- Expert in SQL and able to write structured and efficient queries on large data sets\r\n- Practical experience with Python\r\n- Experience with BI tools (Looker is a big plus, Tableau, Pentaho)\r\n- Experience with ETL tools such as Airflow\r\n- Experience with Snowflake Data Cloud / Data Warehouse or similar (e.g. Redshift, Big Query, etc.)\r\n- Experience working in git workflows\r\n- Excellent communication skills to work with stakeholders to translate business needs and ideas into clearly defined data models and SQL queries\r\n- Upper-Intermediate level of English\r\n \r\n**Responsibilities:**\r\n- Data transformation, enriching of data with new features\r\n- Research, patterns identification and formulating insights\r\n- End-to-end data flows checks\r\n- Data issues investigation\r\n- Extension of ETL processes\r\n- Incorporate automation wherever possible to improve access to data and analyses\r\n- Performance optimization\r\n- Document work, prioritize data governance, and evangelize best practices\r\n \r\n**The company offers you:**\r\n- Competitive salary with regular revisions\r\n- Long-term employment with paid vacation and other social benefits\r\n- Direct contract with US company\r\n- Medical insurance\r\n- Career and professional growth\r\n- Possibility to work on interesting projects\r\n- Coaching sessions to help you reach your goals;\r\n- Attendance at Ukrainian and international conferences and events."
        ],
        [
         "20538",
         "Data Engineer",
         "*About Intellectsoft:* We are a digital transformation consultancy and engineering company that delivers cutting-edge solutions for global organizations and technology startups. Since 2007 we have been helping companies and established brands reimagine their business through digitalization.\r\n\r\n*Our values:* DIVERSITY, OPENNESS, TEAMWORK. We embrace our diversity, strive for open dialogue and constructive feedback, and this unites us and allows us to be an amazing team!\r\n\r\n*Project:* As a Data Engineer, you‚Äôll be responsible for implementing platforms and technologies that enable Business and Engineering Teams to generate, transport, and consume data as well as design and build analytics platforms.\r\n\r\n*Requirements*\r\nMongoDB, Microsoft SQL Server Some Scripting (BASH, Powershell, Ansible, or Python are preferred)\r\nExpertise in Database Administration/DataOps Engineering\r\nKnowledge of engineering fundamentals and architecture\r\nMinimum 3 years of hands-on Database Administration/DataOps experience in the following areas: managing and supporting data storage and data transport systems; software development; distributed configuration management; high availability designs; public cloud systems\r\nExperience working in a technical environment that makes use of languages, frameworks, and technologies such as Python, Golang, Java, Ruby, DataKitchen, Spark, Hadoop, Kafka, Splunk, Elasticsearch, Kubernetes, REST API development, SQL, NoSQL, MongoDB, SQL Server, MySQL, Git, GitLab-CI, Jenkins, Docker\r\nExperience working in a product-oriented, team-based environment that uses modern digital delivery approaches such as user experience design, lean, agile, DevOps, and cloud computing\r\nAble to think holistically around engineering issues A thoughtful, adaptive, and positive mindset Empathetic, humble, and collaborative mindset\r\nAble to teach, coach, and mentor other engineers Good written and verbal communication skills in English, technical and otherwise\r\n\r\n*Responsibilities*\r\nDatabase hosting and management\r\nBackup and restore operations\r\nDatabase scripting\r\nDatabase monitoring\r\nDeveloper and Operations team support\r\n\r\n*Benefits*\r\n35 paid absence days per year for work-life balance of each specialist + 1 additional day for each following year of cooperation with the company\r\nUp to 15 unused absence days can be add to income after 12 month of cooperation\r\n60$/month ‚Äî insurance compensation\r\n55$/month ‚Äî depreciation compensation for personal laptop usage for work needs\r\nUdemy courses of your choice\r\nRegular soft-skills trainings\r\nExcellence –°enters meetups"
        ],
        [
         "20539",
         "Data Engineer",
         "ABOUT PROJECT:\r\nA world-leading research-based pharmaceutical company with a powerful combination of skills and resources that provides a platform for delivering strong growth in today‚Äôs rapidly changing healthcare environment The mission is to improve the quality of human life by enabling people to do more, feel better and live longer.\r\n\r\nWHAT WE EXPECT FROM YOU:\r\n4+ years of experience in SQL and Python\r\nExperience in Relative DataBases like MySQL, PostgreSQL, or similar\r\nExperience with Cloud platforms like AWS/GCP/Azure\r\nExperience in common developer instruments ‚Äî Linux/Mac, Git, Docker, Jira, etc.\r\nUnderstanding microservices architecture and deployment process\r\nStrong Communications Skills ‚Äî Fluent in English\r\nWE OFFER:\r\nCompletely remote work\r\nComfortable social package\r\nEnglish courses, yoga, and health insurance.\r\nFull support for accounting issues and tax coverage\r\nFunny team buildings and corporate events, as well as nice gifts\r\nA team with a family type of culture"
        ],
        [
         "20540",
         "Data Engineer",
         "**About Project:**  \r\nThe project's vision is to create best of class sustainable agriculture for the future by making high quality and standardized agronomic data freely available for ag professionals to translate into impact. To do that, the project is building a leading digital field trials technology that is revolutionizing data driven agriculture. The project's technology disrupts a domain where lack of common language, connectivity and data curation methodologies are significant barriers for improvements. Implementing the project solutions will allow agricultural professionals around the world to increase crops yields while reducing environmental damage and improving crop quality over time.\t\r\n\r\n**Responsibilities:**\r\n- Explore new technologies and tools to keep us on the cutting edge. Continuously evolve yourself by keeping up to date with the latest Data Engineering technologies.\r\n- Be a role model of engineering excellence delivering products in high quality and cadence. You will be managing our data engineering functions\r\n- Work closely with the team to collect product feedback and think of innovative ways to solve problems, address customer needs and drive product adoption.\r\n\r\n**Experience:**\r\n- 3-5 years of experience in deep technical expertise in Data Engineering, DBA.\r\n- An all-around data engineering: strong DBA background, experience in experimentation, data visualization, machine learning frameworks, optimization, and big data.\r\n- Experience in delivering data pipelines with an expert knowledge in Redshift (ETL/ELT, Modeling, Stream/data processing technologies, and related AWS services).\r\n- Mandatory to have a good experience in Python (PySpark) development and JS is an advantage.\r\n- Experience in SQL/NoSQL and data modeling according to business requirements.\r\n- Hands-on experience developing micro-services and backend API (both REST and GraphQL).\r\n- Experience with machine learning frameworks and libraries in AWS, GCP.\r\n- Experience with Git and PR workflow.\r\n- Experience with Linux-based environments.\r\n- High ability to use new technologies and understand them in depth through rapid self-learning.\r\n- Thorough and methodical approach to any task.\r\n- Proactive by nature; internal drive for excellence and improvement.\r\n- BSc, MSc or equivalent experience in a quantitative field (Computer Science, Statistics,\r\nMathematics, Engineering, etc.).\r\n- Creative, out-of-the-box thinking.\r\n- Great interpersonal relations, team player\r\n\r\n**We offer:**\r\n- Opportunity to work remotely;\r\n- Direct communication with Client;\r\n- Competitive salary and benefits.\r\n- Flexible working hours.\r\n- Vacation ‚Äì 15 working days‚Äô annual leave.\r\n- Paid sick days.\r\n- State holidays are granted.\r\n- Corporate accountant and tax refund.\r\n- Bureaucracy-free and transparent management."
        ],
        [
         "20541",
         "Data Engineer",
         "ABOUT PROVECTUS\r\n\r\nProvectus is a Silicon Valley-based Artificial Intelligence consultancy and solutions provider.\r\n\r\nAt Provectus, we are obsessed with leveraging cloud, data, and AI to reimagine the way businesses operate, compete, and deliver customer value. With the wide range of AI solutions for various use cases and industry verticals, Provectus is recognized by technology analysts and top cloud vendors as a leading AI consultancy and solutions provider. We are transformational leaders for our clients and employees.\r\nWe are working with AI, but we are looking for a human being who will work alongside other humans which is a much more complicated task to do than working with machines.\r\n\r\nCurrently, we are looking for a highly motivated and self-driven Data Engineer.\r\n\r\nYour prospects:\r\nLarge international team\r\nA lot of internal projects that differ in business objectives\r\n\r\nJoin us!\r\n\r\nREQUIREMENTS\r\n\r\nMin. 3+ years Experience as Python DeveloperExperience with developer tools such as Git, Gitflow\r\nExperience with Big Data Hive or Spark tools.\r\nExperience with Apache AirFlow.\r\nKnowledge and understanding of relational and no-SQL databases.\r\nExperience in developing server-side API\r\nExperience in the use and application of modern development patterns\r\n\r\nWILL BE A PLUS\r\nExperience with Kafka, Maven, Jenkins, Docker\r\n\r\nRESPONSIBILITIES\r\n\r\nTo design and implement low-latency, high-availability, and performance applications\r\nTo design and implement data pipelines\r\nWriting auto-tests, participating in code reviews\r\nWriting and optimization of complex database queries to build analytical reports."
        ],
        [
         "20542",
         "Data Engineer",
         "About the client:\r\nIt is a leading provider of financial security for middle market consumers. With a history of innovation, the company is redefining the life insurance industry with patented products and processes. The client pioneered the use of predictive analytics to streamline the new business process and revolutionize the speed with which policies can be issued.\r\nThe client is revolutionizing the life insurance industry to make life insurance more accessible and affordable for everyday Americans. With an integrated marketing, product manufacturing, and controlled distribution system, the enterprise is uniquely positioned for growth.\r\n\r\nAbout the role:\r\nAs a key member of the Big Data Analytics team, you will be responsible for creating and operating the Big Data environment that enables to optimize business processes and grow rapidly. You will move and integrate data across multiple disparate systems, aggregate and organize large sets of data in order to enable lead operations, analytics, and predictive modeling. If you would love being an owner-operator of a fast-growing complex online business with modern technology stacks, building analytical and infrastructure solutions, and driving success via analytics, this role is for you!\r\n\r\nResponsibilities:\r\nOwn the creation and maintenance of company data structures and databases in AWS to support predictive model development, analytics, and business intelligence.\r\nImplement, test, document, and deploy integrations and maintain production readiness for cloud-based technology stack including real-time streaming, batch feeds, and predictions models from multiple cloud-based and on-premise sources.\r\nTake on specific ETL projects to assimilate data from multiple new structured and unstructured data sources in batch or real-time, as appropriate.\r\nAssimilate and implement business rules to process raw data. Set up visualization tools to meet the needs of both cloud and on-premise user community.\r\nServe as data steward for Analytics team and third-party technology partners.\r\n\r\nPosition requirements:\r\nBachelor‚Äôs degree in Computer Science, Mathematics, Management Information Systems, Physics, or related field is required.\r\n3+ years of professional data engineer experience working with large data sets and predictive services.\r\n3+ years of professional experience working with SQL and Python with working knowledge PySpark.\r\nMust have hands-on experience with AWS services: Lambda, Athena, Redshift Spectrum, Glue, S3, EKS, EC2, EMR, Kinesis, and RDS.\r\nKnowledge and experience in Big Data and in building Data Pipelines/ETL processes.\r\nSpoken English."
        ],
        [
         "20543",
         "Data Engineer",
         "**About The Client**\r\n\r\nWe¬†are looking for a¬†person to¬†has solid expertise with PowerBI to¬†be¬†able to¬†create apps that will solve the business problems of¬†our clients and deploy them fast into our platform.\r\n\r\nThe partner you will work with is¬†building a¬†platform for data analytics and data visualization in¬†the consultancy area. Built on¬†complex backend mathematics, it¬†solves various retail problems and provides extensive analytical insights based on¬†numerouswell-designed metrics. The team works with Scrum ceremonies to¬†ensure stable product delivery. Tech stack is¬†Python, FastAPI, Postgresql, Pandas, Scipy, Spark, AzureDatabricks, Plotly, React js.\r\n\r\nOur customer is a leading cybersecurity provider of digital identity solutions with more than 700,000 customers and over 20 years of experience in online trust, has partners with organizations of all sizes to deliver automated public and private PKI solutions for securing webservers, user access, connected devices, and applications. They have been recognized for their award-winning innovation and best-in-class global customer support has the proven performance needed to secure the digital landscape of today and tomorrow.\r\n\r\n** About the Project**\r\nOur team builds software for a new messaging-based contact channel for Amazon Customer Service with an Automated Assistant (ChatBot) that uses new cutting edge technologies and ML. Despite continuous improvements in our self-service offerings on Amazon.com, many customers still prefer to get support using natural language. Our intention is to answer questions and solve customer problems using automation to allow us to scale globally across many languages for the millions of customers that use our marketplaces every day.\r\n\r\n **Tech Stack**\r\n‚Äî¬†BS¬†or¬†MS degree in¬†Computer Science or¬†a¬†related technical field\r\n‚Äî¬†3+¬†years coding experience in¬†Python/ pySpark\r\n‚Äî¬†Experienced in¬†Analysis Services.\r\n‚Äî¬†2+¬†years‚Äô experience with Data Visualization tool¬†‚Äî Power BI, Tableau\r\n‚Äî¬†Excellent problem solving and troubleshooting skills\r\n‚Äî¬†Process oriented with great documentation skills\r\n‚Äî¬†Excellent oral and written English communication skills\r\n‚ÄîTeam player with analytical talent, high performance motivation, curiosity,\r\npersuasiveness\r\n‚ÄîExperience with or¬†knowledge of¬†Agile Software Development\r\nmethodologies is¬†a¬†plus\r\n\r\n‚Ä¢ Excellent understanding of distributed computing technologies, approaches, and patterns\r\n‚Ä¢ Proficiency in one of the following programming languages: Java, Scala, or Python\r\n‚Ä¢ Cloud experience which is a big plus point: AWS, GCP or Azure\r\n‚Ä¢ Hands-on experience with Hadoop, NoSQL, MPP technologies, processing frameworks, or other Big Data technology areas: data ingestion, consolidation, streaming or batching\r\n‚Ä¢ Skill in at least one of the processing and computation frameworks: Kafka Streams, Storm, Spark, Flink, Beam/DataFlow, Akka, etc.\r\n‚Ä¢ Experience in at least one of the RDBMS or NoSQL engines: PostgreSQL, MySQL, Cassandra, HBase, Elasticsearch, Redis, MongoDB, Impala, Kudu, etc.\r\n‚Ä¢ Background of implementing Data Lakes, Data Warehousing, or analytics systems is a big advantage. \r\n\r\n**Technical stack of the project: **\r\nAzure Services, Azure DevOps, Azure Functions, Azure Redis Service, Azure SignalR Service, Azure SQL Service, Azure Table Storage, Azure CosmosDB, .NET, .NET Core, AngularJS(migrating to Angular 2+), Angular 8\r\n\r\n**Job responsibilities**\r\n‚Äî¬†Analyze and organize raw data\r\n‚Äî¬†Build data systems and pipelines\r\n‚Äî¬†Evaluate business needs and objectives, propose effective solutions\r\n‚Äî¬†Detect and interpret trends and patterns\r\n‚Äî¬†Conduct complex data analysis and report on¬†results\r\n‚Äî¬†Prepare data for prescriptive and predictive modeling\r\n‚Äî¬†Explore ways to¬†enhance data quality and reliability, develop\r\nmeasurements to¬†assess the data\r\n‚Äî¬†Collaborate with data scientists and architects on¬†projects\r\n‚Äî¬†Suggest and set up¬†processes and systems to¬†monitor data quality,\r\nensuring production data is¬†always accurate.\r\n‚Äî¬†Perform data analysis required to¬†troubleshoot data related issues and\r\nassist in¬†the resolution of¬†data issues.\r\n‚Äî¬†Contribute to¬†engineering wiki, and documents work. (swapped with the\r\nprev one to¬†keep data quality points closer)\r\n‚Äî¬†Work closely with a¬†team of¬†frontend and backend engineers, product\r\nmanagers, and analysts"
        ],
        [
         "20544",
         "Data Engineer",
         "**About the Company:**\r\nAllSTARSIT is an international Software R&D, Technical Support, and Talent Acquisition service provider established in 2004. \r\nHeadquartered in Warsaw, Poland, AllSTARSIT operates development hubs across the whole CEE Region (Poland, Ukraine, Czech Republic, Romania, and Bulgaria), Israel, and Dubai.\r\nAdditionally, AllSTARSIT has Tech Customer Support offices in the LATAM region, with an HQ in Colombia. \r\nThe company has over 800+ talented Software Engineers and Tech Specialists spread across all locations.\r\n\r\nAllSTARSIT‚Äôs expertise covers a variety of industries:\r\n‚Äì Cybersecurity\r\n‚Äì InsurTech\r\n‚Äì AdTech\r\n‚Äì Healthcare\r\n‚Äì AI/Machine Learning\r\n‚Äì Telecommunications\r\n‚Äì Real Estate\r\n‚Äì IoT\r\n‚Äì Mobile\r\n‚Äì Fintech\r\n\r\n**About the Project:**\r\nAnodot‚Äôs AI analytics can analyze 100% of the data you collect, detect anomalies and business incidents in real-time and identify their root cause, enabling you to remedy problems faster and capture opportunities sooner. Anodot's patented monitoring technology identifies and resolves incidents before they impact your customers, revenue, or costs. Get the full context of what is happening and easily initiate automated actions for the fastest time to resolution.\r\n\r\n**Specialization:** Analytics\r\n**Headquarters: **Israel\r\n**Years on the market:** 8, Up to 200 employees\r\n**Current technology stack:** SQL, Python, Spark/Redshift/Vertica, AWS\r\n\r\n**Requirements:**\r\n‚Äì Bachelor‚Äôs degree in Information Systems, Industrial Engineering or Computer Science\r\n‚Äì At least 3-4 years' experience working with SQL in a large scale data warehouse or data lakehouse environment such as Spark, Redshift, or Vertica\r\n‚Äì Excellent knowledge of database / dimensional modeling/data integration tools\r\n‚Äì Experience writing Python scripts\r\n‚Äì A can-do attitude, hands-on approach, passion for data\r\n\r\n**Would be a plus:**\r\n‚Äì Experience working in a Cloud environment, preferably AWS\r\n‚Äì Extensive experience dealing directly with customers about their data needs\r\n\r\n**Scope of work:**\r\n‚Äì Develop data-centric software using leading-edge Big Data technologies. These include database design, Python, near-real-time ETL pipelines, and dashboards.\r\n‚Äì Be the go-to person for anything and everything regarding understanding the data - exploration, pipelines, analytics, etc\r\n‚Äì Gather data needs from customers and translate those requirements into a working database and analytic software\r\n‚Äì Collaborate with colleagues both locally and in remote locations\r\n‚Äì Influence the software architecture, performance, and working procedures for building data and analytics\r\n‚Äì Participate in design and code reviews\r\n‚Äì Manage your own time, and work both independently and as part of a team\r\n\r\n**What we offer:**\r\n**Flexible working conditions:** Office (Warsaw, Poland), remote, or hybrid format. Car & bicycle parking and free scooters.\r\n\r\n**‚ÄçLearning & Development program:** A team of senior developers, a mentorship program, individual budget for self-education, free English, Spanish, and Hebrew courses, English for kids, regular tech meetups on various topics, free music lessons.\r\n\r\n**‚ÄçWellness program:** Extended medical insurance, Covid19/flu vaccination, sport/hobby compensation, massage room, music room, lounge zones with a billiard table, kicker, and PlayStation, daily food servings, and Friday brunches."
        ],
        [
         "20545",
         "Data Engineer",
         "**About the company:** Company is the leading provider of AI-based Big Data analytics. \r\nOur client is dedicated to helping financial organizations combat financial cybercrimes such as money laundering and fraud facilitating malicious crimes such as terrorist financing, narco trafficking, and human trafficking which negatively impact the global economy.  \r\n\r\n**Requirements:**\r\n‚Äî 3+ years of experience as a data engineer/big-data developer.\r\n‚Äî Experience in writing code in Python and Pyspark.\r\n‚Äî Experience in defining and implementing feature engineering processes for ML based products       \r\n‚Äî BSc/BA in Mathematics, Physics, Computer Science, Economics or another related field.\r\n‚Äî Experience with building solutions with Big Data tools and frameworks such as Spark, Hadoop, etc.\r\n‚Äî Experience working with and optimizing ‚Äòbig data‚Äô data pipelines, architectures and data sets.\r\n‚Äî Experience in developing machine learning oriented solutions for the financial sector - advantage\r\n‚Äî Experienced with deep/machine learning framework such as TensorFlow/Keras/Sklearn - advantage\r\n‚Äî Experience in NLP - an advantage.\r\n‚Äî Great communication skills.\r\n‚Äî Ability to quickly learn new technologies, frameworks, and algorithms.\r\n‚Äî Very good English, written and verbal.\r\n \r\n**Responsibilities:** as Lead Data Engineer, you will participate in the implementation team and perform the tasks set by the team leader. Client‚Äôs Intuitive AI solutions for Anti Money Laundering and Fraud Detection enable clients to manage risk, detect money laundering schemes, uncover fraud, expose bad loans, uncover operational issues, and reveal valuable new growth opportunities. Working on a project from scratch\r\n\r\n**Tasks:**\r\n‚Äî Develop ML focused solutions for the financial sector using best-of-breed tools combining  unique algorithms with frameworks such as spark, MLflow, Airflow, etc. in cloud native environments.\r\n‚Äî Participate in research and technology innovation to develop more efficient and automated ways to handle ML/DL workloads.\r\n‚Äî Participate in new product/feature definitions and implementation\r\n‚Äî Work mostly with Python/Spark on Kubernetes environments.\r\n\r\n**We offer:**\r\n‚Äî Remote work;\r\n‚Äî Competitive salary;\r\n‚Äî Performance review once a year;\r\n‚Äî Work schedule Sunday - Thursday; \r\n‚Äî Relocate is possible;\r\n‚Äî Accountant's help.\r\n\r\n**Are you interested? Please contact us**"
        ],
        [
         "20546",
         "Data Engineer",
         "About the company\r\n\r\nOrderin is one of South Africa‚Äôs leading on-demand delivery services. We deliver our customers‚Äô favorite meals, beverages, and other goods right to their doorstep, all in a matter of minutes... and we do it with mad amounts of love.\r\n\r\nThe data engineer will ensure the link between data production and data consumption is smooth by creating and maintaining data pipelines. They will integrate new data sources into data lake, data warehouse or data marts. In addition, they will work closely with data scientists in building data flows in machine learning models, and serving them to relevant stakeholders. They will be in charge of creating and/or maintaining data processing subsystems that manage and orchestrate large volumes of data streams at any required speed.\r\n\r\nQualifications and Experience:\r\n\r\nKnowledge of big data engineering technologies: data processing frameworks, data streaming technologies, and orchestrations frameworks.\r\nDatabase management and data warehousing: Relational database, NoSQL, and in-memory databases.\r\nCloud technologies: AWS data services, Google Cloud (good to have)\r\nAt least 2 years of experience in the field of data engineering."
        ],
        [
         "20547",
         "Data Engineer",
         "About the company:\r\nWe engineer the future of TV. We create and deploy TV apps for every screen, from set-top boxes, Smart TVs and media players to game consoles, tablets and mobile phones. From a single office in Amsterdam, we have grown to many other locations across Europe and also to the US. An open and trust-based culture flourishes at our company, where new technologies and innovations are our daily bread and butter. \r\n\r\nResponsibilities:\r\n‚Ä¢\tUsing and developing data engineering tools to build highly scalable data pipelines and clean datasets around key business metrics;\r\n‚Ä¢\tImplementing data products for customer-facing functions and features with other engineering team members;\r\n‚Ä¢\tDesigning and implementing robust product data pipelines for online and batch learning processes, internal testing and external insights delivery;\r\n‚Ä¢\tBuilding and improving internal tools to support ongoing analytics needs for performance measurement. \r\nRequired skills, knowledge and experience:\r\n‚Ä¢\tIndustry experience in data engineering, software engineering, and data science areas;\r\n‚Ä¢\tHands-on expertise in data engineering, pipeline design and/or applied machine learning;\r\n‚Ä¢\tPrevious experience in the design, implementation, deployment, and support of data engineering features;\r\n‚Ä¢\tStrong practical experience with statistics;\r\n‚Ä¢\tHands-on management and familiarity with frameworks for processing and computation (Spark, Hadoop, Hive, Kafka, e.g.), storage (ClickHouse, Druid, BigQuery, Redshift, e.g.), presentation (Tableau, Superset, e.g.), or overall data management (Snowflake, Databricks, e.g.);\r\n‚Ä¢\tGood verbal and written communication skills in English;\r\n‚Ä¢\tAbility to work well in a fast-paced start-up environment. \r\n\r\nWe offer:\r\n‚Ä¢\tCompetitive work environment\r\n‚Ä¢\tAttractive salary at or above market rate\r\n‚Ä¢\tFull career development program\r\n‚Ä¢\tFlexible working schedule\r\n‚Ä¢\tCompensation for sick lists and regular vacations\r\n‚Ä¢\tAll expenses paid trips abroad\r\n‚Ä¢\tUnforgettable corporate events within the friendly young team\r\n‚Ä¢\tFree English language school\r\n‚Ä¢\tFully equipped kitchen with beverages and snacks\r\n‚Ä¢\tCozy relax spot\r\n‚Ä¢\tBreathtaking scenery view from a new modern office"
        ],
        [
         "20548",
         "Data Engineer",
         "**About the project:** A market leader in developing Competitive Intelligence for AdTech Search. Application teams develop unparalleled technologies that help our clients understand their paid and organic search landscape and improve campaign performance.\r\n\r\n**Timezone requirements:** GMT+2/ GMT\r\n\r\n**Requirements:**\r\n‚Äî 4+ years of commercial experience using Java and Scala (must have both Java and Scala)\r\n‚Äî Experience in data processing using traditional and distributed systems (Hadoop, Spark, AWS - S3)\r\n‚Äî Experience designing data models and data warehouses. \r\n‚Äî Experience in SQL, and NoSQL database management systems (PostgreSQL and Cassandra)\r\n\r\n**Responsibilities:**\r\n‚Äî Build services/features/libraries that serve as a definitive example for new engineers and make major contributions to library code or core services\r\n‚Äî Design low-risk Spark processes and write effective complex Spark jobs (data processes, aggregations, pipeline)\r\n‚Äî Design low-risk APIs and write complex asynchronous, highly parallel low latency APIs and processes\r\n‚Äî Write high-quality, extensible, and testable code by applying good engineering practices (TDD, SOLID) using the company's Engineering Practices, etc.\r\n\r\nWhat's from us:\r\n‚Äî You‚Äôll work with a supportive and spirited team of professionals;\r\n‚Äî Corporate events, holidays, and team buildings for your joy;\r\n‚Äî Training and development: we have a huge library (about 500 books!) and a budget for your professional development;\r\n‚Äî People-oriented management without bureaucracy;\r\n‚Äî Paid vacation and sick leaves;\r\n‚Äî Relocation program: if you are from another city and want to move to Kyiv, we will be happy to help you!\r\n\r\nWhy choose us?\r\n‚Äî ‚ÄúFamily and Friends‚Äù. We are no longer a start-up, but still, have a family atmosphere in our supportive and spirited team, who are all working together on the same goal.\r\n‚Äî ‚ÄúJust break down all barriers and find a better way‚Äù. Every day you‚Äôll meet with interesting and challenging (international) projects that are covering industries from commercial aviation to fintech (different technologies, different products).\r\n‚Äî ‚ÄúHungry for learning‚Äù. You will get a lot of chances for career advancement and the development of new skills, opportunities for mentorship, or learning from more experienced colleagues.\r\n\r\nWill you skip this opport today, or will you join us tomorrow?\r\nWe are waiting for you!"
        ],
        [
         "20549",
         "Data Engineer",
         "**About the project**:\r\nAs a member of the Arlo Smart Home team, you will work on software and tools to support advanced video and audio analytics features for Arlo smart home devices.\r\n**Duties**:\r\n1. Organization of data sets for training and evaluating computer vision and audio recognition models: data collection, validation, data cleaning, organization of the markup process (improvement of existing markup processes), data accounting and storage, creation and refinement of lists for training, validation and testing.\r\n2. Creation/improvement of model evaluation tools.\r\n**Required skills**:\r\nKnowledge of data processing tools (packages for validation and analysis);\r\nExperience with Data Markup Tools (CVAT);\r\nKnowledge of the basics of mat. statistics, standard accuracy metrics (precision, recall, f1 score, mAP, clustering metrics);\r\nExperience working with python, pandas, numpy, json, bash.\r\n**A big plus, but not essential**:\r\nLiving in Lviv;\r\nExperience working with Jenkins, aws cli, dynamo DB, computer vision.\r\n**We offer**:\r\nChallenging tasks and Silicon Valley working experience;\r\nBusiness trips to the other company offices;\r\nA comfortable workplace with a good laptop and the opportunity to warm up in the office;\r\nFlexible working schedule (8 hours working day);\r\nPaid sick days, annual vacations;\r\nEnglish courses;\r\nAccess to the training platforms (Udemy, Coursera, etc.), compensation for external training, conferences, meetups and certifications."
        ],
        [
         "20550",
         "Data Engineer",
         "**About the project:**\r\n\r\n**GrubTech** is a customer-centric all-in-one **SaaS solution** for **F&B** players looking to thrive in their **digital** **evolution**.\r\n\r\nAs off-premise dining grows, F&B players need to adapt their operations to be able to sell more online, while also focusing on staying technologically enabled for their on-premise dining. New business models such as Cloud Kitchens and Virtual Brands are scaling at a fast rate, but unfortunately, the technology providers in this space have not pivoted fast enough to capture the demand. Grubtech provides the most comprehensive all-in-one solution for all players in the F&B landscape relying on technology for efficiency and growth.\r\n\r\n**What do they do?**\r\n\r\nThey are one of the few companies globally that are purpose-built from the ground up to cater to delivery-centric restaurants and cloud kitchens. The product suite encompasses the entire end-to-end operations from on-premise ordering and payment solutions, online demand generation and integration into different channels, payment providers and last-mile delivery, and thorough in-kitchen operations tools. The solution provides a high degree of automation which reduces manpower costs, unlocks digital channel revenues, and improves the consumer experience on-premise and off-premise. Their customers are leading enterprise restaurant groups and cloud kitchen platforms. We power customers in 12 countries across EMEA and SEA and have processed over 1.5 million orders. They empower customers to focus on what they do best, making great food while we handle the technology landscape to bring best-of-breed capabilities to assist in navigating the digital transformation of their sector.\r\n\r\n**Job Overview:**\r\n\r\nThe solution addresses a key gap in the market, and we have witnessed significant demand for the product both regionally and globally. The GrubTech team is growing at a significant rate to ensure that we successfully meet that demand, effectively serves customers, consistently exceed expectations, and continuously innovate and identify new opportunities.\r\n\r\nThe Data Engineer is responsible for collecting, cleansing, and manipulating anonymized data using tools and algorithms to generate relevant insights for GrubTech and its clients. Our ideal data engineer candidate is passionate about visualizing data, discovering trends and solutions, has business sense and is adept at defining metrics and building future-proof tools to better mine and extract value from large sets of data.\r\n\r\n**Responsibilities and Duties:**\r\n\r\n- **Build** high-quality **analysis** and **prediction** **systems**, e.g. for customer segmentation, recommendation generation, and A/B testing.\r\n- Hands-on application **design** and **implementation** by applying best practices including **proof-of-concept projects**.\r\n- Monitoring systems and troubleshooting performance-related issues.\r\n- **Conducting** **code review process** and providing feedback.\r\n- **Collect**, **cleanse** and manipulate large **data** **sets**.\r\n- Ensure the integrity and accuracy of data mined and analyzed.\r\n- **Optimize** the **data** **collection** and **analysis** **process**.\r\n- Supplement GrubTech data with third-party sources, when required.\r\n- Stay up to date on the latest technology trends.\r\n- Generate and present insights for internal discussions with relevant teams.\r\n- **Work** **closely** with the **product**, **strategy**, and **engineering** teams to understand needs and develop solutions as well as to identify opportunities to leverage data for the creation of new or enhancement of existing business solutions.\r\n- Coordinate with relevant teams to implement solutions and monitor outcomes.\r\n- All levels are applicable: **mid, senior, lead**.\r\n\r\n**Qualifications:**\r\n\r\n- BS or MS in Computer Science or a related field.\r\n- Minimum of **2 years of practical experience** in **data** **mining** and **statistical** **analysis**.\r\n- Minimum of **5 years** of **practical** **experience** in **professional** software engineering in designing and implementing backend applications.\r\n- **Experience** in **design** and **implementation** with **Java** and **Spring Boot.**\r\n- **Strong** **understanding** of **OOP** concepts.\r\n- Experience with **NoSQL** databases and cache mechanisms such as **MongoDB**, **Elasticsearch**, **Redis**, and **Hazelcast**.\r\n- Experience in **OLTP/OLAP** database systems such as **PostgreSQL**, **MySQL**, **Apache Druid**, and **Cassandra**.\r\n- Experience in **data** **warehouse** and data lake systems such as **Redshift**, **Snowflake**, and **Hadoop** **Ecosystem**.\r\n- Experience with streaming technologies such as **Apache Kafka**, **Apache** - **Spark Stream**, and **AWS** Kinesis.\r\n- Experience with data processing technologies such as **Spark**, **Airflow**.\r\n- Experience with **reporting**/**analytical** tools such as **Apache** **Superset** is an added advantage.**\r\n- Experience working with **Docker** containerization and orchestration tools such as **AWS ECS** and **EKS**.\r\n- Experience in distributed systems such as event-driven, micro**service, or serverless architectures.\r\n- Experience in **agile** methodologies.\r\n- Knowledge of **AWS** cloud services.\r\n- Passionate, proactive, and action-oriented.\r\n- A problem solver.\r\n- Curious and inquisitive.\r\n- Has a drive for staying abreast of technology trends.\r\n- Comfortable with uncertainty and unfamiliar territory.\r\n- **Strong** communication skills in **English**.\r\n- **Adept** at **understanding** various **data** **structures** and methods for **data** **transformation**.\r\n- Experience working with and **creating** **data** **architectures**.\r\n- **Capable** of using and **building** a variety of **data** **tools** and models to **analyze** **large** **data** sets.\r\n- Proven ability to analyze data, synthesize relevant insights and drive successful business-related outcomes.\r\n\r\n**We offer:**\r\n\r\n‚Äî Competitive salary, room for development and growth;\r\n‚Äî Possibility to work in the Bratislava office or fully remotely;\r\n‚Äî Loyal management, interesting tasks, constant support;\r\n‚Äî Medical insurance;\r\n‚Äî Paid vacations 20 workdays, paid sick leave, regular salary reviews;\r\n‚Äî Flexible schedule and ability to manage your working hours;\r\n‚Äî Support your personal growth and skills upgrading;\r\n‚Äî The great environment inside the team, support of initiatives, and ability to contribute to the common goal."
        ],
        [
         "20551",
         "Data Engineer",
         "About the project:\r\n\r\nIt is well funded startup backed by top VC and Blockchain & Crypto experts that is going to disrupt the Blockchain & Crypto security market.\r\n\r\nWhat we are doing?\r\n\r\nDeFi & Blockchain security company that provides cryptocurrency attack detection in real-time using cutting-edge geometric anomaly detection. We analyzes business off-chain and blockchain on-chain data and defines profiles of typical behavior for crypto users. This activity enables the identification of anomalies in behavior, a multiplicity of which may indicate malicious activity by hackers. Our Security Operation Platform empowers #security, compliance, fraud and risk teams to automatically detect and respond to incidents that matter across the entire crypto attack surfaces.\r\n\r\nWhat are we looking for?\r\n\r\nWe are searching for an experienced, highly motivated, and open-minded cloud data engineer to join our core team and work in full cooperation with other team members to define and develop the system‚Äôs data flows, including data collection, consumption, and processing.\r\n\r\nRequirements ‚Äì What you should have\r\n\r\nBachelor‚Äôs degree in computer science or a related field\r\nHands-on development experience in Python ‚Äì at least 2 years\r\nExperience developing cloud-based applications (Preferably over AWS) ‚Äì at least 2 years\r\nDeep understanding and experience with data lakes and data pipelines architectures\r\nExperience with big data architecture, processing, and scaling in the cloud\r\nExperience with ETL and streaming technologies (AWS Glue, Delta Lake)\r\nExperience working with relational and NoSQL distributed databases\r\n\r\nAn Advantage:\r\n\r\nExperience or knowledge with web3 and blockchain technologies\r\nBackground or knowledge in anomaly detection for security/fraud applications\r\n\r\nAdditional Skills\r\n\r\nExcellent English verbal and written communication skills\r\nSelf-motivated personality with positive attitude\r\nCreative approach to solving problems\r\nMust be technical, fast learner, team player\r\n\r\nStages of the interview:\r\n\r\n1) 30-45 min talk with technical specialist in our company Ficus Technologies.\r\n\r\n2) 15 min talk with the CEO\r\n\r\n3) 1.5h tech interview with the tech lead/CTO\r\n\r\n4) 1h interview with 2 team leads (tech + HR)"
        ],
        [
         "20552",
         "Data Engineer",
         "About the project:\r\n\r\nMaster data hub for a big manufacturing company: creating a single source of truth to the entire organization, data consolidation, and standardization between multiple ERP's. \r\n\r\nResponsibilities:\r\nDesign reporting datasets for wide application usages\r\nDesign PL/SQL processes to clean and merge data\r\nBuilding schedule, monitor, and logging system for data refresh.\r\n\r\nRequirements\r\n3+ years of overall experience with ETL, cloud data migration.\r\nProficient knowledge in T-SQL/ PL SQL\r\nStrong understanding of DWH/ETL fundamentals and concepts\r\nExpert knowledge of KPI development (especially with regards to master data)\r\nExperience with Oracle; Experience with development of relational data models\r\nExperience building and optimizing data pipelines, data sets and stored procedures\r\nSAP experience and data visualization skills (esp. Power BI)\r\nData engineering (SQL, data modeling i.e. star, snowflake, vault)\r\nRequirement engineering (translate business data into insights)\r\nIntermediate+ English level (being able to articulate ideas and solutions to stakeholders)\r\n\r\nWe offer:\r\n‚Ä¢ Flexible working format - remote, office-based or flexible\r\n‚Ä¢ A competitive salary and good compensation package\r\n‚Ä¢ Flexible and personalized career growth\r\n‚Ä¢ Professional development tools (mentorship program, tech talks and trainings, centers of excellence, and more)\r\n‚Ä¢ Active tech communities with regular knowledge sharing\r\n‚Ä¢ Education reimbursement\r\n‚Ä¢ Paid vacation days, sick leaves, and days off\r\n‚Ä¢ Healthcare & Sport program\r\n‚Ä¢ Medical insurance\r\n‚Ä¢ Memorable anniversary presents\r\n‚Ä¢ Corporate events and team buildings"
        ],
        [
         "20553",
         "Data Engineer",
         "**About the project:**\r\n\r\nMoneyMade Connect is the only API solution that allow users to seamlessly connect to accounts of all types, all with just one, simple API. \r\n\r\n**Responsibilities:**\r\n\r\nDesign reporting datasets for wide application usages\r\nDesign PL/SQL processes to clean and merge data\r\nBuilding schedule, monitor, and logging system for data refresh.\r\n\r\n**Requirements**\r\n3+ years of overall experience with ETL, cloud data migration.\r\nProficient knowledge in T-SQL/ PL SQL\r\nStrong understanding of DWH/ETL fundamentals and concepts\r\nExpert knowledge of KPI development (especially with regards to master data)\r\nExperience with development of relational data models\r\nExperience building and optimizing data pipelines, data sets and stored procedures\r\nData engineering (SQL, data modeling i.e. star, snowflake, vault)\r\nRequirement engineering (translate business data into insights)\r\nIntermediate+ English level (being able to articulate ideas and solutions to stakeholders)"
        ],
        [
         "20554",
         "Data Engineer",
         "About the Project\r\nOur Client is a US-based technology and analytics service company helping clients solve the world‚Äôs toughest supply chain transformation challenges. The products developed by Client help clients from Aerospace & Defense and other Commercial Industries to optimize their processes through digital transformation, advanced analytics and business intelligence.\r\n¬†\r\nThe Client is looking for hands-on AI Data Scientist / ML Engineer to participate in the design and implementation for strategic client's products.\r\n\r\n‚Äì Work with relational databases and ODBC.¬† Should have good understanding of schemas, views, grants and materialized views\r\n‚Äì Experience with NoSQL databases and knowledge of JSON is a plus\r\n‚Äì Good statistical background to explore data and provide mathematical descriptions\r\n‚Äì Be able to interpolate gaps in data using mathematical and statistical techniques¬†\r\n‚Äì Be able to increase volume and/or anonymize data¬†¬†\r\n‚Äì Using time-series specific algorithms/statistical techniques\r\n‚Äì Be able to use python libraries to generate data\r\n‚Äì Knowledge and use of ML algorithms are a plus\r\n‚Äì ML requirements are using python open-source libraries"
        ],
        [
         "20555",
         "Data Engineer",
         "**About the project:**\r\nOur client is one of the largest American multinational retail corporations that operates a chain of hypermarkets and stores.\r\nOur team is building a solution for data consolidation from the company‚Äôs various sources. The main strategic goal is to create a single point of contact solution for operating with standardized, normalized, and cleaned data for any user.\r\n\r\n**Stack of technologies on the project:** Python, Kafka, Kubernetes, Helm, Airflow, Databricks, Pyspark (+ streaming), Cassandra, Delta lake, Data lake, Azure ( app func, storage, event hub, keyvault, k8s), Azure dev ops ( triggering pipeline, using project management part), Gremlin, Graph database (janusgraph), Elastic search, LDAP, restApi, DB.\r\n\r\n**Responsibilities:**\r\nImplementation of new and support existent ETL pipelines, Data Marts, participation in meetings.\r\n\r\n**Must have:**\r\n- Python\r\n- RDBS (Relational Databases)\r\n- Databricks (Pyspark (+ streaming))\r\n- English level: Intermediate+\r\n\r\n**One or two from the list below have:**\r\n- Elastic search ‚Äî experience\r\n- Cassandra ‚Äî experience\r\n- Airflow\r\n- Kafka\r\n- Kubernetes, Docker\r\n\r\n**Will be a plus experience with such technologies as:**\r\n- Helm\r\n- Delta lake\r\n- Data lake\r\n- Azure ( app func, storage, event hub, keyvault, k8s)\r\n- Azure dev ops ( triggering pipeline, using project management part)\r\n- Gremlin\r\n- Graph database ( janusgraph)\r\n- LDAP\r\n- restApi\r\n\r\n**We offer:**\r\n- Work with really interesting projects;\r\n- Flexible work schedule;\r\n- Friendly and engaging professional team;\r\n- Environment open for professional growth;\r\n- Compensation of sports;\r\n- Medical service;\r\n- PlayStation console and other relaxing activities;\r\n- Regular corporate events;\r\n- Nice office with a beautiful kitchen and a delicious buffet at the business center."
        ],
        [
         "20556",
         "Data Engineer",
         "About the project:\r\n\r\nOur project is AI‚Äôs platform allows everyone to build their own Conversational AI, which is transparent, curated, and protected. We make LLMs better with grounding data, and our more efficient model architecture cuts carbon, energy&water footprints by 100x\r\n\r\nWhat you will need:\r\n‚óè 3+ years of experience with Python;\r\n‚óè Experience with Data processing;\r\n‚óè Good knowledge of Graph Databases;\r\n‚óè Good knowledge of Unstructured data;\r\n‚óè Experience with AWS and other cloud providers;\r\n‚óè Familiarity with asynchronous APIs including FastAPI or Gevent;\r\n‚óè Experience with GIT and branching workflows;\r\n‚óè English: Upper-Intermediate.\r\n\r\nNice to have:\r\n‚óè Experience with StarDog;\r\n‚óè Experience with Neo4j;\r\n‚óè Experience with DVC (Data Version Control);\r\n‚óè Experience with Apache Airflow;\r\n‚óè Experience with Elasticsearch;\r\n‚óè Experience with Multitenancy concepts;\r\n‚óè Experience with AWS CodePipeline;\r\n\r\nWhat we offer:\r\n‚óè Competitive salary rate depending on your experience and skills;\r\n‚óè A greenfield project that can define the process and impact the results;\r\n‚óè A team where your feedback is appreciated;\r\n‚óè Challenging tasks and ability to improve professional knowledge and skills;\r\n‚óè Flexible working hours;\r\n‚óè Paid vacation (24 working days) and sick leaves;\r\n‚óè –°overage of costs for certification and IT conferences;\r\n‚óè Free corporate English classes + speaking club with native speaker.\r\n\r\nAbout Hevelian:\r\nHevelian is an international technology and consulting company with headquarters in the Netherlands and has been providing the highest quality application, software and solution development for more than 20 years. The Software Engineering team is located in Lviv, Ukraine, and is known for its responsible approach, high-quality standards and innovative solutions. Notably we: also, build our own products and frameworks and contribute to open-source projects, including some of our own have many years of experience in Healthcare and Retail domains are familiar with building quality software for leading US vendors follow well-defined coding standards and guidelines use industry-standard development tools and processes"
        ],
        [
         "20557",
         "Data Engineer",
         "**About the project**\r\nThe client is¬†Nutanix¬†‚Äî a¬†leading cloud computing software company that sells hyper-converged infrastructure (HCI) appliances and software-defined storage. Nutanix was announced an¬†MQ¬†Leader in¬†the November 2018 Magic Quadrant for Hyperconverged Infrastructure.\r\nThe solution orchestrates services from a¬†provider without intervention and helps customers change the state of¬†their involved resources using simple instructions. Create BMaaS to¬†work with variety of¬†cloud providers (Azure, Google Cloud etc.)\r\n\r\n**Responsibilities**\r\n- Make architecture for production solutions;\r\n- Build data processing pipelines;\r\n- Review architecture and suggest solutions for improvement;\r\n- Detect and solve performance issues on architectural, design and code levels.\r\n\r\n**Qualifications**\r\n- 4+ years of experience with Python;\r\n- Knowledge and experience with Google Cloud and AWS, Kubernetes;\r\n- Strong knowledge and experience with Docker;\r\n- Strong knowledge and experience with DB design;\r\n- Upper-Intermediate English.\r\n\r\n**We offer**\r\n- Exchange of experience, professional development;\r\n- A strong team, a healthy atmosphere;\r\n- Flexible working time;\r\n- 20 days paid vacation;\r\n- Paid sick leave;\r\n- Paid remote work;\r\n- 8-hour working day and 5-day working week;\r\n- English lessons and massage service in the office (partially paid by the company);\r\n- Opportunity to take part in conferences, meetups etc. (fully or partially paid by the company);\r\n- Regular company events."
        ],
        [
         "20558",
         "Data Engineer",
         "**About the role:**\r\nYou will be responsible for expanding and optimizing our data and data pipeline architecture while ensuring data quality with rigorous testing of data and data-processing code. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.\r\n\r\nSignal Automotive has created a streamlined end-to-end workflow platform and inventory management tool to scale its wholesale business. We believe that rich, high-quality data is a key component in transforming the automotive wholesale industry. We are focused on using AI/ML to better understand the complex market dynamics in the US auto industry and to share the learned insights with our customers so they can operate more efficiently. We have made solid progress here, and a common refrain from customers is ‚ÄòSignal knows my business better than I do‚Äô.\r\n\r\nYou will work with truly awesome Business and Technology teams and will play a key role in surfacing the information hidden in vast amounts of data. Your primary focus will be on transforming tables and streams of data into well-designed data models in a variety of database systems, including Google BigQuery, PostgreSQL, and Elastic search. In addition to typical SQL queries and analytical functions, these transformations also include the application of machine-learning models to enrich the data. As such, candidates with an interest in machine learning are well suited for this opportunity.\r\n\r\n**As a Data Engineer you will:**\r\nCreate and maintain optimal data pipeline architecture\r\nAssemble large, complex data sets that meet functional / non-functional business requirements\r\nIdentify, design, and implement internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability, etc.\r\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python, and Google-Cloud big-data technologies, e.g., BigQuery, GCS, Dataflow/Apache Beam, etc.\r\nContribute to building and maintaining a system for continuous integration and deployment of changes to data systems\r\nBuild analytics tools that utilise the data pipeline to provide actionable insights\r\nWork with stakeholders including the product, operations, and development teams to assist with data-related technical issues and support their data infrastructure needs\r\nCreate data management tools for analysts and data scientists that assist them in building and optimizing our product into an innovative industry leader\r\nWork with data and analytics experts to strive for greater functionality in our data systems\r\n**Preferred candidates have:**\r\nExpert knowledge of SQL and experience optimizing SQL queries in multiple databases\r\nExperience building and optimizing big-data pipelines, architectures, and data sets\r\nExperience delivering real-time analytics and machine learning predictions\r\nA successful history of manipulating, processing, and extracting value from large disconnected datasets\r\nExperience maintaining data quality and data equivalence between ML-model training systems and ML-model serving systems\r\nExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement\r\nProficiency with Python and basic libraries for machine learning\r\nExperience with message queuing technologies such as RabbitMQ, Kafka, and/or Pulsar\r\nExperience with horizontally scalable data warehouse technologies e.g., Google BigQuery, Hadoop+Hive, Snowflake\r\nExperience with various SQL and NoSQL databases, including PostgreSQL and Elastic search\r\nExperience with data pipeline and workflow management tools e.g., Airflow, Dagster, Prefect, Cloud Composer\r\nExperience with stream-processing systems e.g. Spark Streaming, Flink, Apache Beam, Kafka Streams, etc.\r\nStrong understanding of data structures and algorithms\r\nFamiliarity with Linux, Docker, and Kubernetes\r\nExperience with the lifecycle of machine-learning model development\r\nFamiliarity with processes and technical vocabulary working with Agile software teams\r\nExcellent teamwork skills\r\nUniversity degree in Information/Computer Science or related\r\nVery comfortable with English"
        ],
        [
         "20559",
         "Data Engineer",
         "About the Team:\r\n\r\nOur team leverages distributed systems, machine learning, and personalized search to connect listeners to the content they adore, and to derive insights that enable us to deliver flawless user experiences. Help us invent the systems that will power the future of the radio!\r\n\r\nAbout the Roleüí°\r\n\r\nAs a member of our team, you will join us in architecting the future of our data and machine learning platforms. You will leverage technologies such as Apache Airflow, Kafka, and Spark, to build real-time data pipelines capable of processing billions of events across over 200 connected device types. The infrastructure we build will be a core part of our future.\r\n\r\n\r\nWhat We Are Looking Forüîç\r\n-Expert in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink, etc, on large-scale data, sets demonstrated through 5+ years of experience\r\n-Highly proficient in at least one of Java, Python, or Scala\r\n-Comfortable with complex SQL\r\n-Understand the Data Lifecycle and concepts such as lineage, governance, privacy, retention, anonymity, etc\r\n-Conceptually familiar with AWS cloud resources (S3, EC2, RDS, etc)\r\n-Experience with modern deployment and CI/CD practices (Docker, Kubernetes, and Spinnaker)\r\n-Hungry for impact and insatiably curious about new technologies and frameworks\r\n-Ready to build new things without being constrained by technical debt, in a nimble, startup-like environment.\r\n\r\nWhat You Will Do:üìå\r\n-Engineer efficient, adaptable, and scalable data pipelines to process structured and unstructured data\r\n-Implement real-time event aggregation pipelines to power content & user insights, quality monitoring, and experimentation\r\n-Maintain and rethink existing datasets and pipelines to service a wider variety of use cases\r\n-Build scalable infrastructure for rapid deployment of machine learning models in production environments\r\n-Design modern personalization & experimentation systems (A/B Testing, Multi-armed bandits)."
        ],
        [
         "20560",
         "Data Engineer",
         "About the vacancy\r\n\r\nThe client is a large international company that produces smoking substances. The company is headquartered in New York. A new project is about to start. The team will consist approximately of 10 specialists.\r\n\r\nWe hire people not for a project but for the company. If the project (or your work on it) is over you go to another project or to a paid ‚ÄúIdle‚Äù.\r\n\r\nResponsibilities\r\n- Define database engineering roadmap\r\n- Design, code and implement software solutions\r\n- Settle database structural requirements by analyzing customer processes, applications and programming\r\n- Develop database solutions by crafting & modelling the proposed system\r\n- Plan and conduct database/software-related projects\r\n- Work on data analytics development projects requiring external collaboration to deliver needed services and products in line with timelines and quality levels required for RRP development\r\n- Collaborate across sites or functions to generate innovative solutions and ideas for scientific/technical issues and direct vendors/external resources regarding projects or scientific/technical issues\r\n- Design, implement and manage fast-prototyping environments enabling on-the-fly integration and subsequent analysis of a newly required dataset\r\n- Support early detection of issues\r\n\r\nMust have\r\n- Degree in Computer Science, Data Science or Computer Engineering\r\n- Demonstrated ability in Database Engineering\r\n- Good understanding of systems and software development lifecycle\r\n- Master SQL, Python and Git\r\n- Collaboration, agility, strong analytical and problem-solving skills\r\n- Ability to deal with ambiguity and to make technical decisions based on experience and technical/scientific knowledge\r\n- Expertise in developing accurate technical recommendations, alternatives, and improvements\r\n- Proficiency in English, both oral and written\r\n\r\nWould be a plus\r\n- Experience with Scala\r\n- Good knowledge of Docker, Airflow, Snowflake, Jenkins and AWS technologies\r\n\r\nLearn more about our policy of equal opportunities in employment"
        ],
        [
         "20561",
         "Data Engineer",
         "About the vacancy\r\n\r\nThe client is a US-based company that collects, analyzes, organizes, and data mining progress. The project is in the discovery phase and the team will consist of a Data Engineer and two Business Analysts. The project will be focused on data mining processes.\r\n\r\nA Data Engineer Specialist will help build and refine data transformations between a variety of ERP systems (for example SAP) and our analytical software.\r\n\r\nResponsibilities\r\n- Collaborate directly with senior-level executives, process owners, and technical teams belonging to each customer to understand their goals, objectives, and requirements and to translate them into technical requirements\r\n- Connect the platform with the customer‚Äôs on-premise/cloud ERP & IT systems\r\n- Extract and transform customers‚Äô data and load them into the platform\r\n- Design process and customer-specific dashboards, analysis functions, and reports\r\n\r\nMust have\r\n- Expertise in SQL proven by years of experience\r\n- Ability to write performant, scalable, and easy to understand SQL queries\r\n- Ability to assess dependencies within complex systems, quickly transform your thoughts into an accessible prototype and efficiently explain it to diverse stakeholders\r\n- Experience in business intelligence, data engineering, business analytics, or a similar field\r\n- Understanding of the ETL journey, basic event queries creation, MSSQL connection, connector usage, data source identification, and ETL process assessment\r\n- Understanding of ETL jobs, data warehouses/lakes, data modelling, and schema design\r\n- Knowledge of business processes and/or ERP software would be beneficial\r\n- Familiarity with Agile environments and Agile management tools (e.g. JIRA)\r\n\r\nLearn more about our policy of equal opportunities in employment"
        ],
        [
         "20562",
         "Data Engineer",
         "**About **\r\nThis project is a successful lottery and sports betting operator, with a strong presence in more than 16 countries in Africa under 5 different brands with 4 languages. The plan is to extend countries to 21. The company is globally recognized as a start-up specialist for gaming operations in emerging markets. The company is fast growing, has doubled in size over the last 3 years, and has plans for further expansion in Malta. The business has an active online customer base of more than 170k customers with as many as 40k+ new first-time customers per month. The number of Sports bets exceeds 7 million per month.\r\n\r\n**Responsibilities**\r\nDesign a data flow from various 3rd party data sources to data lake for further analysis. Create dashboards for data insights and custom online reports for business stakeholders. Along with DevOps Team maintain onboarding of new data sources, implementing data consistency checks and cost optimization during data processing.\r\nMaintain knowledgebase about the data availability in the system.\r\n\r\n**Job Requirements**\r\n* Solid experience as a BI or Data Engineer for 2+ years\r\n* Cloud, Python, Data Analysis, Databases, Big Data, GCP (Google Cloud Platform)\r\n* AWS\r\n* Knowledge of GCP services: DataFlow, BigQuery, DataStudio\r\n* Experience with data visualization and BI tools\r\n* Python scripting\r\n* Great collaboration and communication skills\r\n* Good speaking and written English"
        ],
        [
         "20563",
         "Data Engineer",
         "**About Us:**\r\nAltamira is a digital transformation company providing consulting services, including innovative strategies and bespoke technology solutions, that unlocks the full potential of Scale-Up organizations across the world. Headquartered in Bratislava (Slovakia) with offices in Ukraine, we are a sought-after business partner with a world-class team of talented professionals. We are proud of our teammates. Among our employees, it‚Äôs easy to find public speakers, technology gurus, certified architects, and a whole host of talented people. We are building empowered, self-organized teams that are focused on personal and professional growth, and who share our customer obsession.\r\n\r\n**About the project:**\r\nGrubTech is customer centric all in one SaaS solution F&B players looking to thrive in their digital evolution.\r\nAs off premise dining grows, F&B players need to adapt their operations to be able to sell more online, while also focusing on staying technologically enabled for their on-premise dining. New business models such as Cloud Kitchens and Virtual Brands are scaling at a fast rate, but unfortunately the technology providers in this space have not pivoted fast enough to capture the demand. Grubtech provides the most comprehensive all in one solution for all players in the F&B landscape relying on technology for efficiency and growth.\r\n\r\n**What they do?**\r\nThey are one of the few companies globally that is purpose built from the ground up to cater to delivery centric restaurants and cloud kitchens. The product suite encompasses the entire end to end operations from on premise ordering and payment solutions, online demand generation and integration into different channels, payment providers and last mile delivery and thorough in-kitchen operations tools. The solution provides a high degree of automation which reduces manpower costs, unlocks digital channel revenues and improves the consumer experience on premise and off premise. Their customers are leading enterprise restaurant groups and cloud kitchen platforms. We power customers in 12 countries across EMEA and SEA have processed over 1.5 million orders. They empower customers to focus on what they do best, making great food while we handle the technology landscape to bring best of breed capabilities to assist in navigating the digital transformation of their sector.\r\n\r\n**Clients Mission & Vision**\r\n**Mission:** Powering the next generation of cloud kitchens and restaurants\r\n**Vision:** Reimagining F&B to continuously satisfy customer tastes\r\n\r\n**Job Overview:**\r\nThe solution addresses a key gap in the market, and we have witnessed significant demand for the product both regionally and globally. The GrubTech team is growing at a significant rate to ensure that we successfully meet that demand, effectively serve of customers, consistently exceed expectations, and continuously innovate and identify new opportunities.\r\n\r\nThe Data Engineer is responsible for collecting, cleansing and manipulating anonymized data using tools and algorithms to generate relevant insights for GrubTech and its clients. Our ideal data engineer candidate is passionate about visualizing data, discovering trends and solutions, has business sense and is adept at defining metrics and building future proof tools to better mine and extract value from large sets of data.\r\n\r\n**Responsibilities and Duties:**\r\n‚Äî Build high quality analysis and prediction systems, e.g. for customer segmentation, recommendation generation, and A/B testing;\r\n‚Äî Hands-on application design and implementation by applying best practices including proof-of-concepts projects;\r\n‚Äî Monitoring systems and troubleshooting performance related issues;\r\n‚Äî Conducting code review process and providing feedback;\r\n‚Äî Collect, cleanse and manipulate large data sets;\r\n‚Äî Ensure the integrity and accuracy of data mined and analyzed;\r\n‚Äî Optimize the data collection and analysis process;\r\n‚Äî Supplement GrubTech data with third party sources, when required;\r\n‚Äî Stay up to date on the latest technology trends;\r\n‚Äî Generate and present insights for internal discussions with relevant teams;\r\n‚Äî Work closely with the product, strategy and engineering teams to understand needs and develop solutions as well as to identify opportunities to leverage data for the creation of new or enhancement of existing business solutions;\r\n‚Äî Coordinate with relevant teams to implement solutions and monitor outcomes;\r\n‚Äî All levels are applicable: mid, senior, lead.\r\n\r\n**Qualifications:**\r\n‚Äî BS or MS in Computer Science or a related fields;\r\n‚Äî Minimum of 1 years of practical experience in data mining and statistical analysis;\r\n‚Äî Minimum of 3 years of practical experience of professional software engineering in designing and implementation backend applications;\r\n‚Äî Experience in design and implementation with Java and Spring Boot\r\nStrong understanding of OOP concepts;\r\n‚Äî Experience with NoSQL databases and cache mechanisms such as MongoDB, Elasticsearch, Redis, Hazelcast;\r\n‚Äî Experience in OLTP/OLAP database systems such as PostgreSQL, MySQL, Apache Druid, Cassandra;\r\n‚Äî Experience in data warehouse and data lake systems such as Redshift, Snowflake, Hadoop Ecosystem;\r\n‚Äî Experience with streaming technologies such as Apache Kafka, Apache Spark Stream, AWS Kinesis;\r\n‚Äî Experience with data processing technologies such as Spark, Airflow;\r\n‚Äî Experience with reporting/analytical tools such as Apache Superset is an added advantage;\r\n‚Äî Experience working with Docker containerization and orchestration tools such as AWS ECS and EKS;\r\n‚Äî Experience in distributed systems such as event-driven, microservice, or serverless architectures;\r\n‚Äî Experience in agile methodologies;\r\n‚Äî Knowledge of AWS cloud services;\r\n‚Äî Strong communication skills in English;\r\n‚Äî Adept at understanding various data structures and methods for data transformation;\r\n‚Äî Experience working with and create data architectures;\r\n‚Äî Capable of using and building a variety of data tools and models to analyze large data sets;\r\n‚Äî Proven ability to analyze data, synthesize relevant insights and drive successful business-related outcomes;\r\n\r\n**We offer:**\r\n‚Äî Competitive salary, room for development and growth;\r\n‚Äî Possibility to work in the Bratislava office or fully remotely;\r\n‚Äî Loyal management, interesting tasks, constant support;\r\n‚Äî Medical insurance;\r\n‚Äî Paid vacations 20 workdays, paid sick leave, regular salary reviews;\r\n‚Äî Flexible schedule and ability to manage your working hours;\r\n‚Äî Support of your personal growth and skills upgrading;\r\n‚Äî The great environment inside the team, support of initiatives, and ability to contribute to the common goal.\r\n\r\nWe are not just building software, we provide our customers with extra services and excellent experience by partnering our team. We value each of our clients and work tirelessly on enhancing the quality of our services and delivering high-grade software products. We are willing to help our customers digitally transform their business by adopting innovative technologies into their workflows among which are Big Data, IoT, AI, machine learning, etc."
        ],
        [
         "20564",
         "Data Engineer",
         "**About us**\r\n\r\n**Are you an agile & result-driven person looking for opportunities in a multicultural, secure & fast-paced work environment?**\r\n\r\nAUTODOC is a multicultural tech-company active in 27 countries and with ~5000 people from over 50 nations where things are going fast forward. We are currently in a transformative phase and looking for innovative, tech-driven and agile people to join us. We are striving to create an environment where people are safe and supported ‚Äî whether it‚Äôs in an office space or work-at-home.\r\n\r\n\r\n**What will you do:**\r\n\r\n Collecting data from different sources (DB, Cloud, files, etc.)\r\n Building data pipelines, ETL processes\r\n Developing data marts\r\n Validating data \r\n\r\n\r\n**Hard/soft skills:‚Äã**\r\n\r\n 2+ year of experience as a Data Engineer\r\n Analytical skills\r\n Strong programming skills on Python\r\n Expert knowledge of SQL\r\n Hands-on experience with Airflow\r\n Experience with Clickhouse, MySQL, (PostgreSQL, MongoDB will be a plus)\r\n Knowledge of the data storage principles (Data Lake, DWH)\r\n\r\n\r\n**As a plus:**\r\n\r\n Experience in Data Validation area\r\n Experience with GCP, Docker, Git\r\n Experience with dbt\r\n Experience with Grafana or another monitoring tool\r\n Knowledge of the BI solutions principles (Power BI).\r\n Intermediate+ English \r\n\r\n\r\n **What do we offer?**\r\n\r\n Competitive salary based on your professional experience\r\n Stable employment in the fast-growing international company\r\n Wide benefit system\r\n Dynamic work environment\r\n Ability to influence business and its results\r\n Professional growth ‚Äî you will attend free external and internal courses\r\n Paid business trips and payment for participation in conferences\r\n Paid corporate language classes (English, German, Polish)\r\n\r\n\r\n **Join us today and let‚Äôs create a success story together!**"
        ],
        [
         "20565",
         "Data Engineer",
         "**About:‚Äã‚Äã‚Äã‚Äã**\r\nWe are a Web3 and Metaverse technology company with the vision to lead the change in Human Interactions and the mission to connect Real Humans. We are building the first Decentralized Social Metaverse and the Digital Identity of humans, which includes building different innovative products using blockchain technology and token standards.‚Äç\r\n \r\n**Description:‚Äç**\r\nAs a Senior Data Engineer, you will write portable and reusable code for data gathering and analysis using Python and REST API frameworks. \r\nIn addition to ensuring the availability of clean, usable data and data services. \r\nYou will get to work closely with Product Owners to implement data pools and services as well as being a source of knowledge and guidance to other members of the development pool.‚Äç\r\n\r\n**Requirements:**\r\n4+ years of experience in data engineering\r\nExperience in writing tests, both code and data with a strong desire to champion those standards.\r\nExperience with a number of differing data storage solutions, SQL and NoSQL databases, data warehouses, data lakes etc.\r\nCloud experience (ideally GCP but transferable skills from other cloud providers is also fine).\r\nExpert in python libraries such as Pandas, Numpy and Tensorflow or Pytorch\r\nKnowledge of asynchronous task libraries, such as Celery.\r\nVery good understanding of blockchain technology, including the Ethereum blockchain and smart contracts\r\n\r\n**Responsibilities**\r\nDevelop new data pools and enhance existing ones\r\nThinking within substantially diversified, established procedures, standards and precedents; generally supervised.\r\nBe one of our gurus on data acquisition and transformation\r\nParticipate in software design\r\nCollaborate with colleagues in a fast-paced environment based on project-oriented virtual teams.\r\n\r\n\r\n**Working conditions**\r\nCompetitive salary;\r\nRemote-first work;\r\nOnline English courses;\r\nOpportunities for professional development and personal growth;\r\nFriendly atmosphere and professional staff."
        ],
        [
         "20566",
         "Data Engineer",
         "ABOUT YOU:\r\n‚Äî 3+ years of experience in Data Engineering / Data Warehousing roles;\r\n‚Äî Expert knowledge of SQL / NoSQL databases: MySQL, MongoDB;\r\n‚Äî Practical experience of Big Data stack operation: Hadoop, Hive, Kafka, Spark, Cassandra;\r\n‚Äî Working experience on AWS: EC2, Redshift, S3, VPC, VPN etc;\r\n‚Äî Extreme attention to detail;\r\n‚Äî Passion for data.\r\n\r\nRESPONSIBILITIES:\r\n‚Äî Set up data warehouse in the company from scratch;\r\n‚Äî Define, design, model, implement, and operate large, evolving, structured and unstructured datasets;\r\n‚Äî Identify ways to automate data pipelines and dashboards;\r\n‚Äî Work with engineering and business stakeholders to understand data requirements.\r\n\r\nWE OFFER:\r\n- Competitive salary. Compensation that will help you focus on your projects and personal development.\r\n- Professional Growth. We offer a possibility to attend internal, external courses, seminars and access to a corporate library. You will be working with a team of professionals to get insights and discuss ideas.\r\n- Comfortable working environment. BetterMe team is located in a spacious office in the Astarta business center within 10 minutes walk from Kontraktova metro station. \r\n- We serve complimentary breakfasts, lunches, snacks, fruits and all necessary equipment for your role. Health&Fitness. We provide employees with 20 days of paid vacation, medical insurance and a variety of sports activities available for employees inside and outside the office.\r\n- Rest. We organize team buildings, parties and various team activities to boost our collaboration."
        ],
        [
         "20567",
         "Data Engineer",
         "**About your key responsibilities and impact:**\r\n\r\n- Assemble and manage large, complex sets of data that meet non-functional and functional business requirements\r\n- Design and evolve data models and data schema based on business and engineering needs\r\n- Build and support ETL pipelines using tools like Hive, Airflow, and SQL technologies\r\n- Implement systems to track data quality and consistency\r\n\r\n**About you:**\r\n\r\n- 2+ years of experience in software engineering, ideally with a focus on Data Engineering\r\n- Technical expertise in data infrastructure, cloud computing, storage systems, and distributed computing frameworks\r\n- Knowledge of modern data/computing infrastructure and frameworks. Today we use S3, Airflow, MongoDB, Kafka, Clickhouse, AWS lambda, and Python. (We do not expect you to know them all but would like for you to be familiar with some)\r\n- Openness to new or different ideas, and the ability to evaluate multiple approaches and choose the best one based on fundamental qualities and supporting data\r\n- Ability to communicate highly technical problems working along with our cross-functional team\r\n- English level Intermediate or higher\r\n\r\n**Will be a plus:**\r\n\r\n- Knowledge of Redis, Node.js\r\n\r\n**What we offer:**\r\n\r\n- **Top rated products.** Our products are reaching top positions in their categories on App Store and Google Play. 96 million people around the world use it.\r\n\r\n- **Remote or hybrid work model.** It‚Äôs completely up to you to decide whether you want to work. You can mix it up, work remotely or in the office.\r\n\r\n- **Professional and personal growth. **Regular performance reviews, English classes, education compensation, access to a corporate library, freedom of suggesting ideas for improvements and action, flexibility.\r\n\r\n- **Comfortable working conditions. **A competitive salary with regular raises, 20 paid vacation days, along with 11 paid UA holidays, 15 days of paid sick leave, a flexible schedule, modern equipment of your choice, up-to-date tools.\r\n\r\n- **Great benefits and relocation support. **100% coverage of the medical insurance, corporate events, stylish merch, full financial and legal support, relocation package.\r\n\r\n- **Highly skilled and friendly team. **Work in a great area of a mature team and cooperation with experts in the social networking niche.\r\n**\r\nHiring process:\r\n**\r\n- Intro call with a Recruiter\r\n- Test task (Optional)\r\n- Interview with the Hiring team: introduction to the team and your potential manager to know each other more\r\n- Offer"
        ],
        [
         "20568",
         "Data Engineer",
         "Academy SMART invites Data Engineer to its team.\n\nRequired skills\r\n4+ years of years as Data Engineer/DBA;\r\nExperience in working with databases at least 1 of PostgreSQL or MySQL, SqlServer / Azure SQL;\r\nExperience in working with RDS/Aurora is a must;\r\nExperience in working with one or more of the following data tools: Redis, MongoDB, Cassandra, Spark, Hadoop, HDFS, Data Lakes, Elasticsearch, Cloud Analytics tools;\r\nProven experience as DBA, solution architect, Big Data & BI architect, or as a cloud solution architect;\r\nExperience working on public cloud (Azure, AWS).\r\n\r\nWill be a plus\r\nExperience with MariaDB, Oracle;\r\nExperience in working in Databricks;\r\nExperience working with Spark;\r\nHands-on experience in one or more of the following languages: Scala, Python, Spark SQL.\r\n\r\nResponsibilities\r\nTake part as a technical expert in presale meetings with potential customers;\r\nDemonstrate our solutions and ideas to solve our customers challenges;\r\nMigrate customers projects to the new modern application world and guide them on cloud and data best practices;\r\nBe a mentor to our customers and lead them to the solution that works best for them;\r\nAssist our customers data scientists and data engineers create the data pipelines and manage them seamlessly.\r\n\r\nWe offer\r\n20 working days of paid vacation per year;\r\nOfficial holidays of Ukraine ‚Äì days off;\r\nModern equipment for work;\r\nCorporate events;\r\nExternal and internal training: conferences, professional events, courses, TechTalks;\r\nEnglish speaking club."
        ],
        [
         "20569",
         "Data Engineer",
         "Academy SMART invites Data Engineer to join our team.\r\n\r\nProject description:\r\nOur client is Irish consulting company specialising in data\r\nanalytics and data science development, consulting, and training. The company was set up in October 2016 and focussed on helping its' clients answer critical business questions and build their organisational data analytics maturity to enable the organisation to make data driven business decisions. After 6 years, the company is seeing growth\r\npotential in several areas including consulting, training services and new product development.\r\n\r\nResponsibilities:\r\n- Work with the consulting team and client team to understand the data that the client has access to, its structure & location;\r\n- Work with the consulting team and client team to understand the software tools used at our clients for managing and extracting data from their systems of records for analysis;\r\n- Work with the consulting team and client team to understand the software tools used to curation, store, govern, prepare, and access data for analytic purposes;\r\n- Completing data management & data analytics tasks as per required client use cases.\r\n\r\nRequirements:\r\n- Work experience with the Microsoft Azure Stack and Azure Data Services such as SSIS / SSAS, Data Factory and Data Pipelines, Azure SQL Datawarehouse, Azure SQL Server, Azure Synapse / Data Fabric data services components;\r\n- At least 3 years professional working experience;\r\n- A keen interest in the field of technology and innovation;\r\n- An ability to learn quickly and work proactively in teams whilst also using your own initiative.\r\n\r\nWe offer:\r\n- 20 working days of paid vacation per year;\r\n- Official holidays of Ukraine ‚Äì days off;\r\n- Modern equipment for work;\r\n- Corporate events;\r\n- External and internal training: conferences, professional events, courses, corporate e-learning platforms;\r\n- English speaking club;\r\n- Work in a respectful and supportive team.\r\n\r\nHiring process:\r\n- Review CV;\r\n- HR interview;\r\n- 2 stages of professional interview.\r\n\r\nWe are looking forward to your application!"
        ],
        [
         "20570",
         "Data Engineer",
         "üöÄ Acropolium is Hiring a Data Engineer! üöÄ\r\n\r\nüìç Location: Remote\r\nüéØ Job Overview: As a Data Engineer at Acropolium, dive deep into our advanced portfolio management solutions, ensuring the seamless integration, management, and analysis of crucial data. Your role is pivotal in supporting clients in deriving actionable insights for informed decision-making in the dynamic world of portfolio management.\r\n\r\nüí™ Responsibilities:\r\n‚Äî Collaborate with cross-functional teams to identify data requirements and implement robust solutions.\r\n‚Äî Develop and refine complex SQL queries for data extraction, transformation, and loading (ETL).\r\n‚Äî Architect and uphold data pipelines for efficient data flow.\r\n‚Äî Harness Python/R to cleanse, preprocess, and analyze vast datasets.\r\n‚Äî Craft insightful visualizations and dashboards with BI tools, promoting data-driven decision-making.\r\n‚Äî Collaborate with ETL tools, especially Fivetran, ensuring precise and timely data amalgamation.\r\n‚Äî Utilize analytical thinking and data mining techniques to extract valuable insights.\r\n‚Äî Elevate our data architecture and modeling strategies.\r\n‚Äî Enhance our offerings by integrating Machine Learning techniques.\r\n\r\nüìö Qualifications:\r\n‚Äî Proven experience as a Data Engineer with a knack for extracting, transforming, and analyzing large datasets.\r\n‚Äî Proficiency in SQL, Python/R, and BI tools.\r\n‚Äî Familiarity with ETL processes, specifically using Fivetran.\r\n‚Äî Solid understanding of data architecture and modeling techniques.\r\n‚Äî An analytical mind capable of unveiling significant insights from data.\r\n\r\n‚ú® Assets (Nice to have):\r\n‚Äî Experience applying Machine Learning to data-centric challenges.\r\n‚Äî Previous collaboration within a startup or VC environment.\r\n‚Äî Proficiency with cloud platforms such as AWS, Google Cloud, or Azure.\r\n‚Äî Experience working with varied and unstructured data sources.\r\n\r\nü•≥ We offer:\r\n\r\nCollaboration with top-notch IT specialists\r\n20 days of paid vacation, additional sick days, paid medical leave\r\nCompensation for courses, conferences and other types of education and self-development\r\nPossibility of business trips abroad\r\nOnline English courses\r\nFlexible working schedule, work from home\r\nSessions with psychologist (if needed)\r\n\r\n‚è∞ Start Date: As soon as possible\r\nüîó Hiring process:\r\n‚Äî Recruitment interview\r\n‚Äî Technical interview\r\n‚Äî Call with Account Manager\r\n‚Äî Client Interview\r\n\r\nJoin Acropolium and be part of a dynamic team that‚Äôs reshaping portfolio management. Apply now!"
        ],
        [
         "20571",
         "Data Engineer",
         "A custom development company is a design and software powerhouse with mature and established practices in Enterprise Web & Mobile Development, Technical Architecture, Human-Centered Design, Cloud & DevOps, Advanced Data –úanagement & Analytics. For our Data & Analytics Center of Excellence (DCOE) we are looking to hire experienced Data Engineers. \r\n\r\nAs a Data Engineer in DCOE, your primary goal will be to offer non-standard solutions and unlock the potential of our clients. Through expert-level data management and analysis, the DCOE team facilitates resource management, database migration to new engine types, data unification, and company mergers. SQL reports optimization, Business Intelligence reports, and troubleshooting of data flows are another significant part of our day-to-day responsibilities. Our software solutions tackle specific tech challenges across several industries. While our roots are in education, nearly half of our current projects are focused on healthcare. We also innovate in finance, real estate, commerce, IoT, and others.\r\n\r\nRequirements:\r\n3+ years of experience with ETL, Data Modeling, and Data Architecture\r\nStrong experience in generating data pipelines from multiple data sources, in collaboration with diverse team members\r\nExperience in operating very large data warehouses or data lakes\r\nUnderstanding of software development best practices, including query optimization, version control, code reviews, and documentation\r\nExperience with building data pipelines and applications to stream and process large datasets at low latencies\r\nEnglish - –í2 (at least)\r\n\r\nA significant advantage would be an experience with:\r\nPython\r\nScala\r\nETL tools like Airflow, Talend, Mattilion, Informatica, ODI, SSIS \r\nAWS/ Azure or OCI\r\nBig Data technologies such as Hadoop/Databricks/Spark/EMR, Oracle, MS SQL Server, MySQL, PostgreSQL, AWS Redshift, Azure Synapse, Snowflake, DynamoDB\r\nCertification of SQL, PL/SQL, T-SQL \r\n\r\nResponsibilities:\r\nDevelop, construct, test, and maintain data pipelines for multiple analytics functions\r\nAlign architecture with business requirements\r\nAnalyze, re-architect, and re-platform data warehouses\r\nData acquisition\r\nIdentify ways to improve data reliability, efficiency, and quality\r\nPrepare data for predictive and prescriptive modeling as well as for classic BI analytics\r\n\r\nRegistration: contract or b2b\r\n\r\nStages of the interview: \r\n1 - hr approximately 40 minutes, \r\n2 - terms of reference \r\n3- with Lead about an hour."
        ],
        [
         "20572",
         "Data Engineer",
         "A good option is an expert who can do Reporting on Microstrategy but is also open to working with Databricks, and picking up these skills.\r\n\r\nResponsibilities/Tasks\r\n\r\n- Gather business requirements, analyze them, join the dots using data and drive the implementation\r\n- Design, develop, monitor and visualize Customer Data Access\r\n- Overhaul data product\r\n- Integrate high-quality datasets for analytical use-cases\r\n- Support in designing incident management process\r\n- Enable other data teams to follow the standards\r\n- Testing (preparation and execution)\r\n- Operations of data pipelines incl. alerting, bug fixing, etc.\r\n\r\n\r\nSKILLSET - Tech\r\n\r\nMandatory\r\n3+ years of hands-on experience in Databricks or similar\r\n3+ years of hands-on experience in MicroStrategy\r\nStrong skills in data visualization and data modeling\r\nGood understanding of ETL concepts\r\nApache Spark, PySpark and Python, SQL\r\nAWS Glue + Amazon S3\r\nGitHub + CI/CD\r\n\r\nNice to have:\r\n\r\nAdvanced Databricks skills like delta, cluster configuration or Databricks APIs\r\nExperience in new technologies like BigQuery, Airflow, Redshift or Apache NiFi\r\n\r\nSKILLSET - Soft skill\r\n\r\nEnglish B2 (is able to communicate fluently with English speaking stakeholders, able to share ideas and provide reasoning)\r\nTeam player (easy & respectful communications, shares responsibilities for the team's overall success)\r\nCommunication skills\r\nOrganizational skills  \r\nMastery in Engineering"
        ],
        [
         "20573",
         "Data Engineer",
         "A large and fast growing work platform. It connects up to 50 million active job seekers with employers in the US and Canada. The mission is to put people in the right fit positions to realize their potential. It gives workers the flexibility of working hours and makes employers sure that every shift\r\n\r\n**About the project:** The platform of hourly work in the US and Canada. At the core of our strategy is Marketplace and at the core of Marketplace is our data. It is the source for hourly jobs that means a lot of data (users, jobs, shifts) As a Data Engineer, your job is to drive the connections between complex data entities and their underlying systems which power our marketplace. Data Engineers work to build and maintain the systems that process massive amounts of generated platform data optimizing ingestion pipelines and database systems that support our data platform\r\n\r\n**Responsibilities:**\r\n\r\nWork on a highly performant data environment that processes 100 million events per day;\r\nShare ownership of a portfolio of applications with a highly collaborative development team that;\r\nincludes Web, API, DevOps, Data Science and QA engineers;\r\nExplore new technologies and frameworks to advance our architecture and processes;\r\nUse Agile practices to focus on engineering craftsmanship, quality and best practices;\r\nTeach and learn with the team;\r\nCome up with your ideas for product enhancement and productivity boosts.\r\n\r\n**Requirements:**\r\n\r\nBachelor‚Äôs degree in Computer Science or equivalent experience;\r\n3+ years of data engineering;\r\n3+ years of writing software in languages such as Python or C# or Java;\r\n3+ years working with relational databases such as Snowflake, Redshift, MSSQL or PostgreSQL;\r\n3+ years building data pipelines/ETL;\r\nA passion for data quality and clarity;\r\nWillingness to collaborate, explore and share;\r\nDesire to build inspiring data centric experiences that thrill our users;\r\nCommitment to remain curious, open and active in your pursuit of the best practices.\r\nWould be a plus:\r\n\r\nGraduate degree is highly desirable;\r\nExperience with Kafka and data streaming technologies;\r\nExperience with NoSQL databases such as MongoDB, Cassandra or Dynamo;\r\nExperience and passion for Data Engineering and Administration.\r\n\r\n**We provide the following for our employees:**\r\n\r\n18 working days of paid vacation\r\n10 working days of sick leave annually (5 days paid at 100% and 5 days at 75% rate of your average monthly salary)\r\nMedical insurance\r\n50% cost compensation for English courses at the office\r\nFlexible work schedule\r\nAdditional days off for special occasions, national holidays off\r\nA competitive and rewarding salary based on performance appraisals/knowledge evaluation\r\nPossibility to share and gain knowledge on regular tech talks\r\nFriendly and professional team\r\nInnovative projects with advanced technologies\r\nCorporate events\r\nRemote work\r\nAccounting service"
        ],
        [
         "20574",
         "Data Engineer",
         "A newly conceptualized Digital Eco System is comprised of set of capabilities including online shop & website, linking online & offline, customization & personalization, engagement & membership, digital product & services main differences.\r\n\r\nMust have:\r\n\r\n - 2 years of experience building data Pipelines with Python\r\n - 3 years of experience with SQL - database design, big data query and query optimization\r\n - Professional experience with data quality pipelines, REST APIs and API Management solutions\r\n\r\nGood to have:\r\n\r\n - Professional experience building data pipelines in Treasure Data\r\n - Professional experience with the DigDag framework/Presto Framework\r\n- English upper-intermediate or advanced"
        ],
        [
         "20575",
         "Data Engineer",
         "An international company is looking for a motivated and experienced Data Engineer.\r\nThe main focus is building a stable engaged audience of players by using modern technologies.\r\n\r\n## Requirements \r\n- 2+ years of hands-on experience with DWH building;\r\n- confident understanding of RedShift\r\n- experience with Airflow / Airbyte, dbt\r\n- strong database knowledge, specifically SQL\r\n- English B1+\r\n\r\n## Nice to have:\r\n- python\r\n- AWS\r\n\r\n## Responsibilities:\r\n - build new ETL pipelines\r\n - build DWH architecture\r\n - gather BI requirements\r\n - building dashboards\r\n - improve stability and scalability\r\n - provide automation and refactoring\r\n\r\n## We offer:\r\n- top-quality working equipment;\r\n- flexible work schedule ‚Äî we expect a full-time commitment but do not track your working hours;"
        ],
        [
         "20576",
         "Data Engineer",
         "An international company requires –∞ Data Engineer. Remote.                   Salary - 9 000 - 11 000 USD per month.\r\n\r\nAn outstanding opportunity to join an A-list team at a cutting-edge innovative stealth mode startup that is disrupting the world of live streaming for video games, a market of tens of millions of monthly active content creators and billions of daily active viewers.\r\nPowered by proprietary Deep learning and Machine learning algorithms, our technology captures, tracks, and analyzes all streams to provide the first search engine for gaming viewers.\r\n\r\nRequirements\r\n‚óè 5+ years hands-on experience as a Data Engineer/Architect and/or Software Engineer (Backend) of a SaaS/Distributed systems.\r\n‚óè 3+ years of experience with development using Python.\r\n‚óè Experience with data pipelines, data manipulation and transformation\r\n‚óè Experience with cloud architectures over cloud (aka AWS/GCP).\r\n‚óè Experience with MLOps - an advantage\r\n‚óè Experience with designing, setting up, or managing different database engines (NoSQL,Rational DB, Data lakes/warehouse) - an advantage\r\n‚óè Proven technical skills and self-learning ability, capable of thoroughly understanding the functional and technical aspects of a complex system.\r\n‚óè Experience with event-driven architecture.\r\n‚óè Experience with Agile/Scrum methodology\r\n‚óè Enthusiastic about code quality, architecture, design, testing (TDD), and performance.\r\n‚óè CI\\CD best practices, tools and proven experience - an advantage.\r\n‚óè You relate to our core Vision and want to work with experts in their respective fields.\r\n‚óè You have strong interpersonal and communication skills.\r\n‚óè You are Innovator by nature. Thinking out of the box.\r\n‚óè You can operate and thrive in a fast paced, dynamic environment.\r\n‚óè You nerd out about AI, how it can be applied, or how you can learn more about it (don‚Äôt worry we‚Äôll help)."
        ],
        [
         "20577",
         "Data Engineer",
         "An Israeli company is looking for a talented Data Engineer with a strong technical background and a passion for technology and quality.\n\nThe project is Transportation Solution with the mission to organize all the best mobility providers in one global platform - optimizing the entire experience from booking and riding to invoicing and analytics, to save businesses time and money. The company works with a third of the Fortune 500 companies and has over 17K active business customers across the world.\r\n\r\n**Bunch Consulting** is an international outsourcing IT company focused on software development and business digital transformation consulting. \r\nHeadquarter is located in Warsaw, Poland, and the main office is based in Kyiv, Ukraine.\r\n\r\n\r\n**Requirements**: \r\n- 2+ years of experience in software development/data engineering/business intelligence.\r\n- Strong experience in data modeling, ETL development, and data warehousing.\r\n- Experience with Python.\r\n- Upper-intermediate English.\r\n\r\n**Responsibilities**:\r\n- Building the next generation of the Data Warehouse, moving from old and legacy models into more robust.\r\n- Building new ETL pipelines and bugfix old ones.\r\n- Improve data quality and ingestion; identify the root cause of data issues and provide resolution ensuring accuracy and trust in everything we build.\r\n- Ensure that the local data needs are taken into account by the global BI team.\r\n- Debug reports or automatic Python scripts and ensure the reporting server infrastructure connects correctly to our main data sources.\r\n- Contribute to pieces of analysis to inform business decisions.\r\n\r\n**Would be a plus**: \r\n- Big data technologies (Spark, Hive, Presto, Airflow).\r\n- Experience working with AWS big data technologies (S3, EC2, EKS).\r\n- Knowledge in containerized environments (Docker, Kubernetes).\r\n- Knowledge of infrastructure and DevOps (CI/CD, Terraform).\r\n\r\n\r\n**We offer you**:\r\n- Continuous growth and development as a professional in terms of Seniority and Tech Leadership in a fast-growing company.\r\n- The decent salary level and revisions depend on your growth in the company and your desires.\r\n- Comfortable working conditions on a remote basis.\r\n- A motivated team.\r\n- Improve your spoken English.\r\n- Be surrounded by people who love what they do and be in the continuous development of new technologies.\r\n\r\n\r\n**Working conditions**: Full-time. Remote. (Poland)\r\n**Project duration**: not limited."
        ],
        [
         "20578",
         "Data Engineer",
         "Apester - is an interactive platform for digital media that includes a set of tools that enable the creation, distribution, and monetization of the interactive, visual, fun content experiences consumers love. The product is being used by top brands and publishers like Telegraph, Time, Rolling Stones, Bundesliga League, and many many more.\r\n \r\nWe work in small KPI-oriented teams while following Agile work methods. We use continuous integration and continuous delivery methodologies to run quickly and efficiently while maintaining a high level of user experience. We need you to help us grow our business and write clean and performant code for our highly scalable systems that support Apester‚Äôs over 400 million monthly users.\r\n\r\n**Requirements:**\r\n- At least 3 years experience as a data engineer\r\n- Expertise in different types of databases and data warehouses, including SQL and NoSQL\r\n- Experience with large data sets and distributed computing tools (Hadoop, Pig, Spark, Beam, etc)\r\n- Experience with a reporting platform like Tableau/Looker/DataStudio\r\n- Analyzing and processing large quantities of data, and use it to give actionable insights\r\n- Being an independent, self-learner who understands business processes and can translate business needs into data model\r\n- Upper-intermediate+ English\r\n\r\n**As a plus:**\r\n\r\n- Experience with using Google Cloud data stack (DataFlow, PubSub, BigQuery, etc)\r\n- Google-Pubsub or Kafka expertise\r\n- Having run models in production\r\n\r\n**Previous Experience:**\r\n- Being responsible for designing, implementing and maintaining data pipelines from different sources\r\n- Owning the data development process end-to-end, including business understanding, methodology, QA, and maintenance\r\n- Working closely with the head of data and VP of R&D to define goals and objectives"
        ],
        [
         "20579",
         "Data Engineer",
         "Areas of Responsibility:\r\nBuilding the bulk of data integration in AWS Cloud utilizing the vendors API package to push data to their SaaS solution\r\nETL design and development of data flows between on-premise and cloud systems and regular delta processing\r\nDesign and implementation of backup strategy\r\nPerformance optimization\r\nTroubleshooting critical incidents and problems\r\nCooperation with DevOps team\r\n\r\nQualifications:\r\n2+ years of Python experience\r\nWillingness to work with AWS Cloud services\r\nThorough understanding of relational database concepts and SQL\r\nEnglish: Intermediate level and above\r\nIt will be an advantage\r\nOracle PL/SQL\r\nExperience with AWS services is a plus (AWS Glue, AWS Lambda, AWS Step Functions, Amazon Redshift, AWS S3, Spark/PySpark)\r\nExperience with Azure Cloud services is a plus\r\nETL development experience in Big Data projects (RDBMS/non-RDBMS, on-premise/cloud)"
        ],
        [
         "20580",
         "Data Engineer",
         "Are you an innovative & creative self-starter who is amazing to work with? If yes, this job could be for you!\r\n\r\n As a Senior Data Engineer, you will be a key factor in developing our data solution. You‚Äôll need to come up with solutions to complex problems that should maintain performance in scale. You'll be responsible for driving exciting innovations around data and AI that will help the company grow faster and wiser. You‚Äôll work closely with devs, analysts, and business stakeholders to automatically generate predictive models that utilize our collected data and empower our system to make decisions in real-time. As part of the job, you will be a focal point for all things related to data, which includes creating a tech roadmap for pipe-lines performance, data architecture, managing storage, assessing performance and budget limitations, and much more.\r\n\r\n Technical must experience:\r\n‚Ä¢ 5+ years of hands-on experience as a Software Engineer \r\n‚Ä¢ 3+ years of hands-on experience as a Data Engineer \r\n‚Ä¢ 2+ years of hands-on experience in Machine Learning and Data Science \r\n‚Ä¢ Intimate familiarity with a variety of ML disciplines and algorithms \r\n‚Ä¢ Experience with data related cloud-based technologies like S3, parquet, EMR, AirFlow, Kinesis, BigQuery. \r\n‚Ä¢ Previous Python experience \r\n‚Ä¢ Excellent business understanding and communication skills \r\n‚Ä¢ Data enthusiast and a team player\r\n\r\nResponsibilities: \r\n‚Ä¢ Taking full ownership of designing, implementing, deploying, and maintaining existing and new data pipelines by using cloud-based tools in a cloud-based infrastructure. \r\n‚Ä¢ Work with different stakeholders to design and develop Machine Learning algorithms that optimize and make an immediate business impact on KPIs. \r\n‚Ä¢ Build, test, and deploy custom ML/AI models and algorithms on large datasets, and develop processes for monitoring and analyzing their performance in production environments. \r\n‚Ä¢ Hands-on work on our core data infrastructure, tools, and automation. \r\n‚Ä¢ Take part in POCs and innovation for new technologies, databases, tools, and services that can significantly push the division goals."
        ],
        [
         "20581",
         "Data Engineer",
         "As a Data Engineer at 1010data, you will design, build, maintain and optimize large-scale automated ELT processes. You will work closely with our data scientists and analysts to create efficient and reliable jobs that support 1010data's data products and our clients' data warehousing needs. Your toolbox: industry-standard data orchestration tools including Apache Airflow; proprietary scheduling and automation tools; proprietary query transformation language and your own Python and ELT design skills. As we incorporate more cloud technologies into our processes, you will be at the forefront of exploring and defining best practices, and helping us transition our products to be more scalable.\r\n\r\nWhat you will take on:\r\n- Coordinating with the systems, core, data science, and analytics teams to build and maintain data products and custom solutions for our clients;\r\n- Designing and writing automated scripts to preprocess terabytes of data from our partners/clients;\r\n- Designing and writing new enterprise-scale ELT/ETL workflows from scratch in Python using Airflow, Docker, Kubernetes, AWS, etc.;\r\n- Ensuring quality, reliability and uptime for critical automated processes;\r\n- Migrating our products and ELT/ETL processes into the cloud while drastically reducing our in-house data center footprint.\r\n\r\nWhat you will bring:\r\n- At least 1-2 years of professional experience programming in Python\r\nExposure to ETL/ELT pipeline automation\r\nExposure to basic database concepts\r\n\r\nPreferred Skills:\r\n- Good understanding of Data Engineering, NoSQL databases and database design, distributed systems and/or information retrieval;\r\n- Experience with Airflow and Cloud Technologies;\r\n- Familiarity with functional/vector programming;\r\n- Experience with organising data and creating efficient data transformation process for optimised client data analysis;\r\n- Strong communication skills, ability to work seamlessly with team members with different areas of technical expertise.\r\n\r\nEducation:\r\n- STEM Bachelor‚Äôs preferred, Masters degree or Math/Statistics background is a big plus;\r\n- Data Engineering Bootcamp or equivalent.\r\n\r\nIn exchange for your skills we offer:\r\n- Friendly work atmosphere, in a young and international team;\r\n- Dog-friendly office in the center of historical Krak√≥w;\r\n- Attractive compensation and benefits incl MultiKafeteria, Generali, Luxmed,... ;\r\n- Sport and other events, including, weekly running, squash, teamlunch;\r\n- Free tea, coffee and all-you-can-eat fruits in the office.\r\n\r\nAs our client is based in the US, we normally start at 11 AM.\r\nRemote position is possible only within GDPR zone."
        ],
        [
         "20582",
         "Data Engineer",
         "As a Data Engineer, you will be given challenging data to handle at a massive scale, build our data pipeline and lead every aspect regarding the ETLs.\n\nData Science team will also need your help to make their models production-ready. No rest for the wicked, though: after all of that is done, you‚Äôll deal with the results while transforming them into actionable items for our clients and other internal stakeholders. If you got this far, and you‚Äôre not really scared, you really should apply.\r\nYou will work with a plethora of storage and processing technologies on top of cutting-edge application frameworks and infrastructure, bridging the gap between Data Science and Engineering.\r\n\r\n**REQUIREMENTS**\r\n\r\n- Excellent proficiency in SQL at least 5 years: Complex queries, SQL scripting, performance tuning.\r\n- Background working with one of these MPP databases (in that order): Snowflake, redshift, big query, vertica.\r\n- Excellent python development capabilities at least 5 years: Working with dataframes, data processing, data management.\r\n- Experience working with SparkSQL & RDDs is a big advantage.\r\n- Develop data pipelines and ETL using Airflow - must\r\n- Infra, experience working with AWS data services at least 3 years: S3, EMR, Athena, Redshift, EC2, RDS, DMS, kineses, Lambda, SQS.\r\n- A techie person who is passionate about expanding the knowledge in data technologies and always willing to learn more: NoSQL, Haddop, big data, kubernetes, docker and more\r\n- Working with reporting tools such as: Tableau, sisense, looker\r\n- Team player"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4443
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Long Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20533</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>1. Project description\\r\\nClient is in the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20534</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>**8allocate** is a global provider of end-to-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>8allocate is a global provider of end-to-end c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20536</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>**8allocate** is a global provider of end-to-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20537</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>**About Datassential**\\r\\n\\r\\nDatassential is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97069</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–≤—ã–∫–∏\\r\\n* Strong experience in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97070</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>–ü—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è,  –∫–æ—Ç–æ—Ä–∞—è –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è —Ä–∞–∑—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97071</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è\\r\\n‚Ä¢ At least 2 years of experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97072</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –æ–ø—ã—Ç –≤ –±–µ–∫–µ–Ω–¥ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –æ–ø—ã—Ç ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97073</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>–®—É–∫–∞—î–º–æ –¥–æ—Å–≤—ñ–¥—á–µ–Ω–æ–≥–æ **QA Engineer** –≤ –∫–æ–º–∞–Ω–¥—É...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4443 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position                                   Long Description\n",
       "20533  Data Engineer  1. Project description\\r\\nClient is in the pro...\n",
       "20534  Data Engineer  **8allocate** is a global provider of end-to-e...\n",
       "20535  Data Engineer  8allocate is a global provider of end-to-end c...\n",
       "20536  Data Engineer  **8allocate** is a global provider of end-to-e...\n",
       "20537  Data Engineer  **About Datassential**\\r\\n\\r\\nDatassential is ...\n",
       "...              ...                                                ...\n",
       "97069    QA Engineer  –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–≤—ã–∫–∏\\r\\n* Strong experience in m...\n",
       "97070    QA Engineer  –ü—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è,  –∫–æ—Ç–æ—Ä–∞—è –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è —Ä–∞–∑—Ä...\n",
       "97071    QA Engineer  –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è\\r\\n‚Ä¢ At least 2 years of experience...\n",
       "97072    QA Engineer  –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –æ–ø—ã—Ç –≤ –±–µ–∫–µ–Ω–¥ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –æ–ø—ã—Ç ...\n",
       "97073    QA Engineer  –®—É–∫–∞—î–º–æ –¥–æ—Å–≤—ñ–¥—á–µ–Ω–æ–≥–æ **QA Engineer** –≤ –∫–æ–º–∞–Ω–¥—É...\n",
       "\n",
       "[4443 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e049c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"devops_engineer_jobs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df5dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage_kpit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
